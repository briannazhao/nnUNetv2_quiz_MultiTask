{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3yeHBA5IcIhb",
      "metadata": {
        "id": "3yeHBA5IcIhb"
      },
      "source": [
        "# Pancreas Segmentation (nnU-Net v2 ResEnc M) + Subtype Classification\n",
        "\n",
        "This notebook follows the quiz requirements:\n",
        "- nnU-Net v2 (ResEnc **M**) for **segmentation**.\n",
        "- Adds a **classification** component using a separate lightweight 3D CNN trained on the same training images (subtype0/1/2).\n",
        "- Packaging: produces `quiz_*.nii.gz` masks and a `subtype_results.csv` with `Names,Subtype`.\n",
        "\n",
        "It also:\n",
        "- Persists preprocessed data & results to Google Drive (so you don't lose work on Colab).\n",
        "- Uses `--disable_tta` to achieve ≥10% inference speed-up while maintaining accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YyJKILQMaL59",
      "metadata": {
        "id": "YyJKILQMaL59"
      },
      "source": [
        "## Manual backup/restore saved data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19YB1VOtpsf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19YB1VOtpsf9",
        "outputId": "f67abf7c-1e39-4224-b2eb-1717438ffc13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Copied DIR: /content/submission_outputs -> /content/drive/MyDrive/submission_outputs\n",
            "\n",
            "Done! Saved to: /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# --- Save nnU-Net + classification outputs to Drive ---\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# 1) Mount Drive (safe to run multiple times)\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# 2) Where to save\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "# 3) What to save (edit as needed)\n",
        "to_save = {\n",
        "  # nnU-Net stuff\n",
        "  # 'preprocessed': '/content/nnUNet_preprocessed/Dataset500_PancreasCancer',\n",
        "  # 'results': '/content/nnUNet_results',\n",
        "  'submission_outputs': '/content/submission_outputs',\n",
        "\n",
        "  # \"splits_final.json\": '/content/nnUNet_preprocessed/Dataset500_PancreasCancer/splits_final.json',\n",
        "  #'raw_dataset': '/content/nnUNet_raw',\n",
        "}\n",
        "\n",
        "def copy_any(src, dst):\n",
        "  if os.path.isdir(src):\n",
        "    if os.path.exists(dst): shutil.rmtree(dst)\n",
        "    shutil.copytree(src, dst)\n",
        "    print(f\"✅ Copied DIR: {src} -> {dst}\")\n",
        "  elif os.path.isfile(src):\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    shutil.copy2(src, dst)\n",
        "    print(f\"✅ Copied FILE: {src} -> {dst}\")\n",
        "  else:\n",
        "    print(f\"⚠️ Missing (skip): {src}\")\n",
        "\n",
        "for name, src in to_save.items():\n",
        "  dst = os.path.join(DRIVE_ROOT, os.path.basename(src))\n",
        "  copy_any(src, dst)\n",
        "\n",
        "print(\"\\nDone! Saved to:\", DRIVE_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Mv3Ka25sp4QU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv3Ka25sp4QU",
        "outputId": "8ef42da2-5559-48c1-d699-11ec7e70f343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "⬇️ Restored DIR: /content/drive/MyDrive/nnUNet_results not very ideal -> /content/nnUNet_results\n",
            "\n",
            "Ready! Restored from: /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# --- Load/restore artifacts from Drive into current Colab session ---\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# 1) Mount Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# 2) Source on Drive (must match the save cell)\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "\n",
        "# 3) Where to restore locally\n",
        "restore_map = {\n",
        "  # os.path.join(DRIVE_ROOT, 'nnUNet_preprocessed'): '/content/nnUNet_preprocessed',\n",
        "  os.path.join(DRIVE_ROOT, 'nnUNet_results not very ideal'): '/content/nnUNet_results',\n",
        "  # os.path.join(DRIVE_ROOT, 'nnUNet_predictions'): '/content/predictions',\n",
        "  # os.path.join(DRIVE_ROOT, 'case_subtype_mapping.csv'): '/content/case_subtype_mapping.csv',\n",
        "  # os.path.join(DRIVE_ROOT, 'subtype_results.csv'): '/content/subtype_results.csv',\n",
        "  # os.path.join(DRIVE_ROOT, 'nnUNet_raw'): '/content/nnUNet_raw',\n",
        "  # os.path.join(DRIVE_ROOT, \"splits_final.json\"): '/content/nnUNet_preprocessed/Dataset500_PancreasCancer/splits_final.json',\n",
        "}\n",
        "\n",
        "def restore_any(src, dst):\n",
        "  if os.path.isdir(src):\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    if os.path.exists(dst): shutil.rmtree(dst)\n",
        "    shutil.copytree(src, dst)\n",
        "    print(f\"⬇️ Restored DIR: {src} -> {dst}\")\n",
        "  elif os.path.isfile(src):\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    shutil.copy2(src, dst)\n",
        "    print(f\"⬇️ Restored FILE: {src} -> {dst}\")\n",
        "  else:\n",
        "    print(f\"⚠️ Not found on Drive (skip): {src}\")\n",
        "\n",
        "for src, dst in restore_map.items():\n",
        "  restore_any(src, dst)\n",
        "\n",
        "print(\"\\nReady! Restored from:\", DRIVE_ROOT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i4IC5wgscIhe",
      "metadata": {
        "id": "i4IC5wgscIhe"
      },
      "source": [
        "## Mount Google Drive and install nnUNetv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YQbxMm7LcIhf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQbxMm7LcIhf",
        "outputId": "83c1e637-1b37-4b5c-eb7a-c3b02e111aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlBXeej8IiYf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SlBXeej8IiYf",
        "outputId": "c04c53b4-68b9-4dd0-f1d6-261f4b821b8c"
      },
      "outputs": [],
      "source": [
        "# Install nnU-Net v2 (ResEnc M) and CLI tools\n",
        "%cd /content\n",
        "!git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
        "\n",
        "%cd nnUNet\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "edfabc6c",
      "metadata": {
        "id": "edfabc6c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set nnU-Net environment paths\n",
        "os.environ['nnUNet_raw'] = '/content/nnUNet_raw'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "os.environ['nnUNet_results'] = '/content/nnUNet_results'\n",
        "\n",
        "dataset = 'Dataset500_PancreasCancer'\n",
        "root = os.path.join(os.environ['nnUNet_raw'], dataset)\n",
        "for sub in ['imagesTr', 'labelsTr', 'imagesTs']:\n",
        "    os.makedirs(os.path.join(root, sub), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2SrcksZHcIhg",
      "metadata": {
        "id": "2SrcksZHcIhg"
      },
      "source": [
        "## Data augmentation: convert data to nnU-Net layout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QqvQhN8icIhg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqvQhN8icIhg",
        "outputId": "ea81b37a-97b4-4893-fdcf-cdc75aad9592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved classification mapping to: /content/nnUNet_raw/Dataset500_PancreasCancer/classification_labels.json and /content/nnUNet_raw/Dataset500_PancreasCancer/classification_labels.csv\n"
          ]
        }
      ],
      "source": [
        "# Convert & rename ML-Quiz-3DMedImg data into nnU-Net format\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "source = '/content/drive/MyDrive/ML-Quiz-3DMedImg/data'  # USE YOUR OWN PATH\n",
        "target = root  # from previous cell\n",
        "counter = 0\n",
        "\n",
        "def copy_case(img, lbl):\n",
        "    global counter\n",
        "    cid = f\"pancreas_{counter:03d}\"\n",
        "    # Copy training image\n",
        "    shutil.copy(img, os.path.join(target, 'imagesTr', f'{cid}_0000.nii.gz'))\n",
        "    # Load, fix label, and save (from float to int)\n",
        "    data = nib.load(lbl)\n",
        "    arr = np.rint(data.get_fdata()).astype(np.int16)\n",
        "    nib.save(nib.Nifti1Image(arr, data.affine, data.header),\n",
        "             os.path.join(target, 'labelsTr', f'{cid}.nii.gz'))\n",
        "    counter += 1\n",
        "\n",
        "# Training data only (exclude validation folder)\n",
        "for subtype in ['subtype0', 'subtype1', 'subtype2']:\n",
        "    folder = f\"{source}/train/{subtype}\"\n",
        "    for img in sorted(glob(f\"{folder}/*_0000.nii.gz\")):\n",
        "        lbl = img.replace('_0000.nii.gz', '.nii.gz')\n",
        "        if os.path.exists(lbl):\n",
        "            copy_case(img, lbl)\n",
        "\n",
        "# Test images\n",
        "for img in sorted(glob(f\"{source}/test/*.nii.gz\")):\n",
        "    shutil.copy(img, os.path.join(target, 'imagesTs', os.path.basename(img)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Fqr7q8EcIhj",
      "metadata": {
        "id": "1Fqr7q8EcIhj"
      },
      "source": [
        "## Create the case-subtype mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jBfNQ-y-cfOA",
      "metadata": {
        "id": "jBfNQ-y-cfOA"
      },
      "outputs": [],
      "source": [
        "# --- Check mapping coverage and, if needed, rebuild it to include all imagesTr ---\n",
        "import os, re, hashlib\n",
        "from pathlib import Path\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Where your original dataset with subtype folders lives (adjust if needed)\n",
        "ORIG_ROOTS_TRY = [\n",
        "    \"/content/drive/MyDrive/ML-Quiz-3DMedImg/data\",  # must contain train/subtype0..2 and validation/subtype0..2\n",
        "]\n",
        "ORIG_ROOT = None\n",
        "for cand in ORIG_ROOTS_TRY:\n",
        "    p = Path(cand)\n",
        "    if (p/\"train\").exists() and (p/\"validation\").exists():\n",
        "        ORIG_ROOT = p\n",
        "        break\n",
        "assert ORIG_ROOT is not None, \"Set ORIG_ROOT to the folder containing train/subtype*/ and validation/subtype*/\"\n",
        "\n",
        "DATASET_ID   = \"500\"\n",
        "RAW_ROOT     = Path(f\"/content/nnUNet_raw/Dataset{DATASET_ID}_PancreasCancer\")\n",
        "PREP_ROOT    = Path(f\"/content/nnUNet_preprocessed/Dataset{DATASET_ID}_PancreasCancer\")\n",
        "IM_TR        = RAW_ROOT / \"imagesTr\"\n",
        "MAPPING_CSV  = Path(\"/content/case_subtype_mapping.csv\")\n",
        "\n",
        "assert IM_TR.exists(), f\"{IM_TR} not found\"\n",
        "\n",
        "# quick, robust fingerprint so we can match originals to nnUNet files\n",
        "def quick_fp(img_path, stride=2000):\n",
        "    img = nib.load(str(img_path))\n",
        "    arr = img.get_fdata(dtype=np.float32)\n",
        "    shp = tuple(arr.shape)\n",
        "    sample = arr.ravel()[::max(1, min(arr.size, stride))]\n",
        "    h = hashlib.md5(sample.tobytes()).hexdigest()\n",
        "    return (str(arr.dtype), shp, h)\n",
        "\n",
        "def scan_originals(root):\n",
        "    fp_to_meta = {}\n",
        "    for split in [\"train\", \"validation\"]:\n",
        "        for subdir in (root/split).glob(\"subtype*\"):\n",
        "            if not subdir.is_dir():\n",
        "                continue\n",
        "            m = re.search(r\"subtype(\\d+)\", subdir.name)\n",
        "            if not m:\n",
        "                continue\n",
        "            subtype = int(m.group(1))\n",
        "            for img_path in sorted(subdir.rglob(\"*_0000.nii*\")):\n",
        "                try:\n",
        "                    fp = quick_fp(img_path)\n",
        "                    fp_to_meta[fp] = {\"orig_path\": str(img_path), \"subtype\": subtype}\n",
        "                except Exception as e:\n",
        "                    print(\"Skip\", img_path, \"->\", e)\n",
        "    return fp_to_meta\n",
        "\n",
        "def scan_imagesTr(nnunet_im_tr):\n",
        "    case_to_fp = {}\n",
        "    for p in sorted(nnunet_im_tr.glob(\"*_0000.nii*\")):\n",
        "        case_id = p.name.replace(\"_0000.nii.gz\", \"\").replace(\"_0000.nii\", \"\")\n",
        "        try:\n",
        "            fp = quick_fp(p)\n",
        "            case_to_fp[case_id] = (p, fp)\n",
        "        except Exception as e:\n",
        "            print(\"Skip\", p, \"->\", e)\n",
        "    return case_to_fp\n",
        "\n",
        "print(\"Scanning originals...\")\n",
        "orig_fp = scan_originals(ORIG_ROOT)\n",
        "print(\"Scanning imagesTr...\")\n",
        "case_to_fp = scan_imagesTr(IM_TR)\n",
        "\n",
        "rows, missing = [], []\n",
        "for cid, (p, fp) in case_to_fp.items():\n",
        "    meta = orig_fp.get(fp)\n",
        "    if meta is None:\n",
        "        missing.append(cid)\n",
        "        continue\n",
        "    rows.append({\"case_id\": cid, \"subtype\": int(meta[\"subtype\"])})\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"case_id\")\n",
        "df.to_csv(MAPPING_CSV, index=False)\n",
        "print(f\"\\n✅ Wrote {MAPPING_CSV} with {len(df)} rows\")\n",
        "if missing:\n",
        "    print(f\"⚠️ {len(missing)} imagesTr did not match any original by fingerprint. Examples: {missing[:8]}\")\n",
        "\n",
        "# Coverage vs nnUNet split (so you can see train & val presence)\n",
        "with open(PREP_ROOT/\"splits_final.json\") as f:\n",
        "    split = json.load(f)[0]  # fold 0\n",
        "train_ids = set(split[\"train\"])\n",
        "val_ids   = set(split[\"val\"])\n",
        "\n",
        "have = set(df[\"case_id\"].astype(str))\n",
        "print(f\"Coverage: mapping covers {len(have)} / {len(list(IM_TR.glob('*_0000.nii*')))} imagesTr\")\n",
        "print(f\"  train covered: {len(train_ids & have)} / {len(train_ids)}\")\n",
        "print(f\"  val   covered: {len(val_ids   & have)} / {len(val_ids)}\")\n",
        "\n",
        "print(\"\\nCounts per subtype in mapping:\")\n",
        "print(df[\"subtype\"].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ilh9xoY6cIhh",
      "metadata": {
        "id": "Ilh9xoY6cIhh"
      },
      "source": [
        "## Generate dataset.json for nnU-Net (integer labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w4xMFA5NcIhh",
      "metadata": {
        "id": "w4xMFA5NcIhh"
      },
      "outputs": [],
      "source": [
        "#cell 9: Write dataset.json\n",
        "import json\n",
        "\n",
        "tr_imgs = sorted(glob(f'{target}/imagesTr/*.nii.gz'))\n",
        "train_entries = []\n",
        "for p in tr_imgs:\n",
        "    cid = os.path.basename(p).replace('_0000.nii.gz', '')\n",
        "    train_entries.append({\n",
        "        'image': f'./imagesTr/{cid}_0000.nii.gz',\n",
        "        'label': f'./labelsTr/{cid}.nii.gz'\n",
        "    })\n",
        "\n",
        "ts_imgs = sorted(glob(f'{target}/imagesTs/*.nii.gz'))\n",
        "test_entries = [f'./imagesTs/{os.path.basename(x)}' for x in ts_imgs]\n",
        "\n",
        "ds = {\n",
        "    'name': 'PancreasCancer',\n",
        "    'description': 'Multi-task pancreas segmentation + classification',\n",
        "    'tensorImageSize': '3D',\n",
        "    'channel_names': {'0': 'CT'},\n",
        "    'labels': {'background':'0','pancreas':'1','lesion':'2'},\n",
        "    'numTraining': len(train_entries),\n",
        "    'file_ending': '.nii.gz',\n",
        "}\n",
        "\n",
        "with open(f'{target}/dataset.json', 'w') as f:\n",
        "    json.dump(ds, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kzmT-I27cIhi",
      "metadata": {
        "id": "kzmT-I27cIhi"
      },
      "source": [
        "## Preprocess (plan & preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "urLqlS3SbdBP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "urLqlS3SbdBP",
        "outputId": "65dfd136-6980-4562-927f-a3c2972c4b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset500_PancreasCancer\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "100% 252/252 [00:50<00:00,  4.97it/s]\n"
          ]
        }
      ],
      "source": [
        "!nnUNetv2_extract_fingerprint -d 500 --verify_dataset_integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UnG8xMl8qNEe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UnG8xMl8qNEe",
        "outputId": "e248bec5-e5c0-43f9-9ee5-4e8759821509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59. 118. 181.], 3d_lowres: [59, 118, 181]\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 134, 'patch_size': (np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([118., 181.]), 'spacing': array([0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([ 59., 118., 181.]), 'spacing': array([2.        , 0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/nnUNet_preprocessed/Dataset500_PancreasCancer/nnUNetResEncUNetMPlans.json\n"
          ]
        }
      ],
      "source": [
        "!nnUNetv2_plan_experiment -d 500 -pl nnUNetPlannerResEncM # you can choose M/L/XL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c005a5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9c005a5a",
        "outputId": "0367bb81-c6e1-42ff-a2df-009951707a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing dataset Dataset500_PancreasCancer\n",
            "Configuration: 2d...\n",
            "100% 252/252 [13:03<00:00,  3.11s/it]\n",
            "Configuration: 3d_fullres...\n",
            "100% 252/252 [07:41<00:00,  1.83s/it]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetResEncUNetMPlans.json of dataset Dataset500_PancreasCancer. Skipping.\n"
          ]
        }
      ],
      "source": [
        "!nnUNetv2_preprocess -d 500 -p nnUNetResEncUNetMPlans # Change nnUNetResEncUNetXPlans with X=M/L/XL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a7XJSmrcIhj",
      "metadata": {
        "id": "9a7XJSmrcIhj"
      },
      "source": [
        "## Autosync (when training while I sleep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KB2_L6HZwCi0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB2_L6HZwCi0",
        "outputId": "b4c2f050-ea09-407d-93c4-773d055cc1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# --- Configure autosync targets & mount Drive ---\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1) Mount (safe to run multiple times)\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# 2) Where to put backups on Drive\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "# 3) What to sync (add/remove as you like)\n",
        "SYNC_DIRS = [\n",
        "    '/content/nnUNet_results',                                 # models, logs, checkpoints  <-- important\n",
        "    # '/content/nnUNet_preprocessed/Dataset500_PancreasCancer/splits_final.json'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYXXd2_lwWrZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYXXd2_lwWrZ",
        "outputId": "9ce9820b-50a2-4eb7-ef44-4df85f84a8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Autosync completed at 2025-08-15 10:19:06\n",
            "✅ Autosync started. Will run every 10 minutes.\n"
          ]
        }
      ],
      "source": [
        "# --- Start background autosync thread ---\n",
        "import threading, time, subprocess, datetime, shutil\n",
        "\n",
        "SYNC_EVERY_SEC = 10 * 60\n",
        "\n",
        "def _rsync_dir(src, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    # trailing slashes so it syncs *contents* of src into dst\n",
        "    cmd = ['rsync', '-a', '--delete', src.rstrip('/') + '/', dst.rstrip('/') + '/']\n",
        "    subprocess.run(cmd, check=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "_autosync_stop = threading.Event()\n",
        "\n",
        "def _sync_loop():\n",
        "    while not _autosync_stop.is_set():\n",
        "        started = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        for src in SYNC_DIRS:\n",
        "            if os.path.exists(src):\n",
        "                dst = os.path.join(DRIVE_ROOT, os.path.basename(src))\n",
        "                _rsync_dir(src, dst)\n",
        "        print(f\"💾 Autosync completed at {started}\")\n",
        "        # Wait, but allow fast stop\n",
        "        _autosync_stop.wait(SYNC_EVERY_SEC)\n",
        "\n",
        "# Launch the background thread (daemon so it doesn't block runtime shutdown)\n",
        "if '_autosync_thread' in globals() and _autosync_thread.is_alive():\n",
        "    print(\"Autosync already running.\")\n",
        "else:\n",
        "    _autosync_stop.clear()\n",
        "    _autosync_thread = threading.Thread(target=_sync_loop, daemon=True)\n",
        "    _autosync_thread.start()\n",
        "    print(\"✅ Autosync started. Will run every\", SYNC_EVERY_SEC//60, \"minutes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lsANC87Kz825",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsANC87Kz825",
        "outputId": "b50fc4d7-21df-447d-d239-1bd757cb4913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🛑 Stopping autosync…\n"
          ]
        }
      ],
      "source": [
        "# --- Stop background autosync ---\n",
        "try:\n",
        "    _autosync_stop.set()\n",
        "    print(\"🛑 Stopping autosync…\")\n",
        "except NameError:\n",
        "    print(\"Autosync was not running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60LGYJi9cIhj",
      "metadata": {
        "id": "60LGYJi9cIhj"
      },
      "source": [
        "## Install and create the multi-task network files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vVRcr5dAZOsj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vVRcr5dAZOsj",
        "outputId": "e0a7179d-1b20-4e67-8583-906ea78fdbbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: nnunetv2 2.6.2\n",
            "Uninstalling nnunetv2-2.6.2:\n",
            "  Successfully uninstalled nnunetv2-2.6.2\n",
            "\u001b[33mWARNING: Skipping nnunet as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/MIC-DKFZ/nnUNet.git@master\n",
            "  Cloning https://github.com/MIC-DKFZ/nnUNet.git (to revision master) to /tmp/pip-req-build-d4e3lnv1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MIC-DKFZ/nnUNet.git /tmp/pip-req-build-d4e3lnv1\n",
            "  Resolved https://github.com/MIC-DKFZ/nnUNet.git to commit f1851fbaf2c53dcb51b079b60a01de528a7d0c17\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: acvl-utils<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.2.5)\n",
            "Requirement already satisfied: dynamic-network-architectures<0.5,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.16.1)\n",
            "Requirement already satisfied: batchgenerators>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.2)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.21)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2025.6.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.13.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2025.8.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.1.8)\n",
            "Requirement already satisfied: batchgeneratorsv2>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.6.1)\n",
            "Requirement already satisfied: connected-components-3d in /usr/local/lib/python3.11/dist-packages (from acvl-utils<0.3,>=0.2.3->nnunetv2==2.6.2) (3.24.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (11.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (3.6.0)\n",
            "Requirement already satisfied: fft-conv-pytorch in /usr/local/lib/python3.11/dist-packages (from batchgeneratorsv2>=0.3.0->nnunetv2==2.6.2) (1.2.0)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.10.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.1.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (4.3.8)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (2.11.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (9.0.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.0.19)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2==2.6.2) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2==2.6.2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2==2.6.2) (1.5.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2==2.6.2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.2) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.21.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.34.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.6.1)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.11/dist-packages (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.1.7)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.11/dist-packages (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: nnunetv2\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-py3-none-any.whl size=285149 sha256=b65cfcd2394d394cd43db675a0c1c80962cbe4b8485093a24fa23fa1b50d9393\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7om_d6nw/wheels/74/b5/93/b29a5db83df049bae2f24d213a91375ed1250440290ab96c6f\n",
            "Successfully built nnunetv2\n",
            "Installing collected packages: argparse, nnunetv2\n",
            "Successfully installed argparse-1.4.0 nnunetv2-2.6.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3a52ff084dd0493aa6556efb44034616",
              "pip_warning": {
                "packages": [
                  "argparse",
                  "nnunetv2"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "Obtaining file:///content/nnUNet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: acvl-utils<0.3,>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.2.5)\n",
            "Requirement already satisfied: dynamic-network-architectures<0.5,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.16.1)\n",
            "Requirement already satisfied: batchgenerators>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.2)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.21)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2025.6.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.13.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2025.8.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.1.8)\n",
            "Requirement already satisfied: batchgeneratorsv2>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.6.1)\n",
            "Requirement already satisfied: connected-components-3d in /usr/local/lib/python3.11/dist-packages (from acvl-utils<0.3,>=0.2.3->nnunetv2==2.6.2) (3.24.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (11.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (3.6.0)\n",
            "Requirement already satisfied: fft-conv-pytorch in /usr/local/lib/python3.11/dist-packages (from batchgeneratorsv2>=0.3.0->nnunetv2==2.6.2) (1.2.0)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.10.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.1.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (4.3.8)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (2.11.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (9.0.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.0.19)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2==2.6.2) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2==2.6.2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2==2.6.2) (1.5.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2==2.6.2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.2) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.21.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.34.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.6.1)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.11/dist-packages (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.1.7)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.11/dist-packages (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: nnunetv2\n",
            "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-0.editable-py3-none-any.whl size=16742 sha256=f1ef438baabe53a86620efab12f00b0b88742bc620d7f1b949f91b2dc4fe919a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xzp4v8bb/wheels/2a/a6/3a/a708be8093b6d70dcfceb5de9867bfa2a75ecf91e22d90b1fc\n",
            "Successfully built nnunetv2\n",
            "Installing collected packages: argparse, nnunetv2\n",
            "  Attempting uninstall: nnunetv2\n",
            "    Found existing installation: nnunetv2 2.6.2\n",
            "    Uninstalling nnunetv2-2.6.2:\n",
            "      Successfully uninstalled nnunetv2-2.6.2\n",
            "Successfully installed argparse-1.4.0 nnunetv2-2.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y nnunetv2 nnunet\n",
        "!pip install --no-cache-dir \"git+https://github.com/MIC-DKFZ/nnUNet.git@master\"\n",
        "# if you cloned the repo to /content/nnUNet and are using it in editable mode:\n",
        "!cd /content/nnUNet && git pull && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "-ArX_9bJHBXH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ArX_9bJHBXH",
        "outputId": "1578903a-f64f-4feb-90cb-4b3a15740250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing /content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainer.py\n",
        "import os, math, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from importlib import import_module\n",
        "\n",
        "from nnunetv2.utilities.helpers import dummy_context\n",
        "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
        "from nnunetv2.training.loss.dice import get_tp_fp_fn_tn\n",
        "\n",
        "from dynamic_network_architectures.architectures.unet import ResidualEncoderUNet\n",
        "from dynamic_network_architectures.building_blocks.residual import BasicBlockD\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "#   Network with ROI-masked GeM pooling for cls head (NaN-safe)\n",
        "# -------------------------\n",
        "class MultiTaskResEnc(nn.Module):\n",
        "    \"\"\"Shared encoder + Segmentation decoder + Classification head\"\"\"\n",
        "\n",
        "    @property\n",
        "    def decoder(self):\n",
        "        return self.segmentation_net.decoder\n",
        "\n",
        "    def __init__(self, input_channels, n_stages, features_per_stage, conv_op,\n",
        "                 kernel_sizes, strides, n_blocks_per_stage, num_segmentation_classes,\n",
        "                 num_classification_classes=3, n_conv_per_stage_decoder=None,\n",
        "                 conv_bias=False, norm_op=None, norm_op_kwargs=None,\n",
        "                 dropout_op=None, dropout_op_kwargs=None, nonlin=None,\n",
        "                 nonlin_kwargs=None, deep_supervision=False, block=None,\n",
        "                 cls_stopgrad_through_encoder=True):\n",
        "        super().__init__()\n",
        "        block = block or BasicBlockD\n",
        "\n",
        "        self.segmentation_net = ResidualEncoderUNet(\n",
        "            input_channels=input_channels,\n",
        "            n_stages=n_stages,\n",
        "            features_per_stage=features_per_stage,\n",
        "            conv_op=conv_op,\n",
        "            kernel_sizes=kernel_sizes,\n",
        "            strides=strides,\n",
        "            n_blocks_per_stage=n_blocks_per_stage,\n",
        "            num_classes=num_segmentation_classes,\n",
        "            n_conv_per_stage_decoder=n_conv_per_stage_decoder,\n",
        "            conv_bias=conv_bias,\n",
        "            norm_op=norm_op,\n",
        "            norm_op_kwargs=norm_op_kwargs,\n",
        "            dropout_op=dropout_op,\n",
        "            dropout_op_kwargs=dropout_op_kwargs,\n",
        "            nonlin=nonlin,\n",
        "            nonlin_kwargs=nonlin_kwargs,\n",
        "            deep_supervision=deep_supervision,\n",
        "            block=block\n",
        "        )\n",
        "\n",
        "        bottleneck_features = features_per_stage[-1] if isinstance(features_per_stage, (list, tuple)) else features_per_stage\n",
        "        self.cls_stopgrad_through_encoder = cls_stopgrad_through_encoder\n",
        "\n",
        "        # GeM pooling exponent for masked pooling\n",
        "        self.gem_p = nn.Parameter(torch.tensor(3.0))\n",
        "\n",
        "        # Fallback GAP (3D)\n",
        "        self.global_pool = nn.AdaptiveAvgPool3d(1) if conv_op == nn.Conv3d else nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(bottleneck_features, 256), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.Linear(128, num_classification_classes)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _nan_to_num(x, lim=1e6):\n",
        "        # replace NaN/Inf and clamp to avoid overflow in downstream losses\n",
        "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        return x.clamp(min=-lim, max=lim)\n",
        "\n",
        "    def _masked_gem_pool(self, bottleneck, seg_logits, eps=1e-6, tiny_roi_frac=5e-4):\n",
        "        \"\"\"\n",
        "        bottleneck: [B, C, d, h, w]\n",
        "        seg_logits: [B, Cseg, D, H, W] (main head resolution)\n",
        "        Returns pooled: [B, C, 1, 1, 1]\n",
        "        \"\"\"\n",
        "        seg_logits = self._nan_to_num(seg_logits)\n",
        "        # soft foreground prob\n",
        "        if seg_logits.shape[1] > 1:\n",
        "            fg_prob = torch.softmax(seg_logits, dim=1)[:, 1:, ...].max(1, keepdim=True)[0]\n",
        "        else:\n",
        "            fg_prob = torch.sigmoid(seg_logits)\n",
        "\n",
        "        fg_prob = self._nan_to_num(fg_prob).clamp(0, 1)\n",
        "\n",
        "        # downsample mask to bottleneck size\n",
        "        if fg_prob.shape[2:] != bottleneck.shape[2:]:\n",
        "            fg_prob = F.adaptive_avg_pool3d(fg_prob, bottleneck.shape[2:])\n",
        "            fg_prob = self._nan_to_num(fg_prob).clamp(0, 1)\n",
        "\n",
        "        # safe dtype math in fp32, cast back at end\n",
        "        orig_dtype = bottleneck.dtype\n",
        "        x = self._nan_to_num(bottleneck.float())\n",
        "        m = fg_prob.float()\n",
        "\n",
        "        # tiny ROI -> fall back to GAP\n",
        "        valid = m.sum(dim=(2, 3, 4), keepdim=True)\n",
        "        total = float(np.prod(bottleneck.shape[2:]))\n",
        "        tiny = (valid / (total + eps)) < tiny_roi_frac  # [B,1,1,1,1] boolean\n",
        "\n",
        "        # GeM over ROI\n",
        "        p = torch.clamp(self.gem_p, 1.0, 6.0)\n",
        "        x_pos = x.clamp_min(0)\n",
        "        num = ((x_pos ** p) * m).sum(dim=(2, 3, 4), keepdim=True)\n",
        "        den = valid.clamp_min(1.0)\n",
        "        gem_roi = (num / den).clamp_min(eps) ** (1.0 / p)\n",
        "\n",
        "        # GAP fallback\n",
        "        gap = F.adaptive_avg_pool3d(x, 1)\n",
        "\n",
        "        pooled = torch.where(tiny, gap, gem_roi).to(orig_dtype)\n",
        "        return self._nan_to_num(pooled)\n",
        "\n",
        "    def forward(self, x, return_both: bool = False):\n",
        "        seg_logits = self.segmentation_net(x)\n",
        "        seg_logits_main = seg_logits[0] if isinstance(seg_logits, (list, tuple)) else seg_logits\n",
        "        seg_logits_main = self._nan_to_num(seg_logits_main)\n",
        "\n",
        "        # encoder features\n",
        "        enc_out = self.segmentation_net.encoder(x)\n",
        "        bottleneck = enc_out[-1] if isinstance(enc_out, (list, tuple)) else enc_out\n",
        "\n",
        "        # stop-grad for cls path (optional)\n",
        "        bn_for_cls = bottleneck.detach() if self.cls_stopgrad_through_encoder else bottleneck\n",
        "\n",
        "        pooled = self._masked_gem_pool(bn_for_cls, seg_logits_main)  # [B,C,1,1,1]\n",
        "        cls_logits = self.classification_head(pooled.view(pooled.size(0), -1))\n",
        "        cls_logits = self._nan_to_num(cls_logits)\n",
        "\n",
        "        if return_both or self.training:\n",
        "            return seg_logits, cls_logits\n",
        "\n",
        "        # Predictor expects segmentation only\n",
        "        return seg_logits\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "#   Trainer\n",
        "# -------------------------\n",
        "class MultiTaskTrainer(nnUNetTrainer):\n",
        "    def __init__(self, plans, configuration, fold, dataset_json,\n",
        "                 device=torch.device('cuda')):\n",
        "        super().__init__(plans, configuration, fold, dataset_json, device)\n",
        "\n",
        "        # ---- classification weight ramps up ----\n",
        "        self.cls_weight_start = 0.10\n",
        "        self.cls_weight_end   = 0.55\n",
        "        self.cls_weight_ramp_epochs = 25  # linear ramp\n",
        "\n",
        "        # ---- classification loss knobs ----\n",
        "        self.cls_label_smoothing = 0.05\n",
        "        self.cls_logit_adj_tau   = 1.0\n",
        "\n",
        "        # mapping & priors\n",
        "        self.case_to_subtype = self._load_classification_labels()\n",
        "        print(f\"Loaded {len(self.case_to_subtype)} classification labels\")\n",
        "\n",
        "        counts = np.bincount(list(self.case_to_subtype.values()), minlength=3)\n",
        "        priors = counts / max(1, counts.sum())\n",
        "        inv = 1.0 / np.clip(counts, 1, None)\n",
        "        inv = inv / inv.mean() if inv.sum() > 0 else np.ones_like(inv, dtype=float)\n",
        "\n",
        "        self.cls_class_weights = torch.tensor(inv, dtype=torch.float32, device=self.device)\n",
        "        self.cls_log_prior     = torch.log(torch.tensor(np.clip(priors, 1e-8, 1.0), dtype=torch.float32, device=self.device))\n",
        "\n",
        "        self.classification_loss = nn.CrossEntropyLoss(\n",
        "            weight=self.cls_class_weights, label_smoothing=self.cls_label_smoothing\n",
        "        )\n",
        "\n",
        "        # keep DS off: we feed only the main seg map to the loss\n",
        "        self.enable_deep_supervision = False\n",
        "\n",
        "        # bookkeeping\n",
        "        self.classification_metrics = {'train_acc': [], 'val_acc': []}\n",
        "        self._epoch_idx = -1\n",
        "        self._val_cls_acc_epoch = []\n",
        "        self.best_val_cls_acc = -1.0\n",
        "        self.best_cls_head_path = os.path.join(self.output_folder, \"checkpoint_best_cls_head.pth\")\n",
        "\n",
        "        # stability: warm-up in fp32 for a few steps to avoid AMP NaNs at start\n",
        "        self._train_step_count = 0\n",
        "        self._fp32_warmup_steps = 6\n",
        "\n",
        "    @staticmethod\n",
        "    def build_network_architecture(architecture_class_name: str,\n",
        "                                   arch_init_kwargs: dict,\n",
        "                                   arch_init_kwargs_req_import: Union[List[str], Tuple[str, ...]],\n",
        "                                   num_input_channels: int,\n",
        "                                   num_output_channels: int,\n",
        "                                   enable_deep_supervision: bool = True) -> nn.Module:\n",
        "        kwargs = dict(arch_init_kwargs)\n",
        "        if arch_init_kwargs_req_import:\n",
        "            for k in arch_init_kwargs_req_import:\n",
        "                v = kwargs.get(k)\n",
        "                if isinstance(v, str):\n",
        "                    mod, attr = v.rsplit('.', 1)\n",
        "                    kwargs[k] = getattr(import_module(mod), attr)\n",
        "\n",
        "        return MultiTaskResEnc(\n",
        "            input_channels=num_input_channels,\n",
        "            n_stages=kwargs['n_stages'],\n",
        "            features_per_stage=kwargs['features_per_stage'],\n",
        "            conv_op=kwargs['conv_op'],\n",
        "            kernel_sizes=kwargs['kernel_sizes'],\n",
        "            strides=kwargs['strides'],\n",
        "            n_blocks_per_stage=kwargs['n_blocks_per_stage'],\n",
        "            num_segmentation_classes=num_output_channels,\n",
        "            num_classification_classes=3,\n",
        "            n_conv_per_stage_decoder=kwargs['n_conv_per_stage_decoder'],\n",
        "            conv_bias=kwargs['conv_bias'],\n",
        "            norm_op=kwargs['norm_op'],\n",
        "            norm_op_kwargs=kwargs['norm_op_kwargs'],\n",
        "            dropout_op=kwargs.get('dropout_op'),\n",
        "            dropout_op_kwargs=kwargs.get('dropout_op_kwargs'),\n",
        "            nonlin=kwargs['nonlin'],\n",
        "            nonlin_kwargs=kwargs['nonlin_kwargs'],\n",
        "            deep_supervision=enable_deep_supervision,\n",
        "            cls_stopgrad_through_encoder=True\n",
        "        )\n",
        "\n",
        "    def _load_classification_labels(self):\n",
        "        try:\n",
        "            df = pd.read_csv('/content/case_subtype_mapping.csv')\n",
        "            col = 'case_id' if 'case_id' in df.columns else ('case' if 'case' in df.columns else None)\n",
        "            assert col is not None, f\"Mapping CSV must have case_id or case; got columns {df.columns.tolist()}\"\n",
        "            df[col] = df[col].astype(str)\n",
        "            df['subtype'] = df['subtype'].astype(int)\n",
        "            return dict(zip(df[col], df['subtype']))\n",
        "        except Exception as e:\n",
        "            print(\"Warning: Could not load case_subtype_mapping.csv; falling back to dummy mapping.\", e)\n",
        "            return {f\"case_{i:04d}\": i % 3 for i in range(300)}\n",
        "\n",
        "    def get_network(self):\n",
        "        return self.build_network_architecture(\n",
        "            architecture_class_name=self.network_arch_class_name,\n",
        "            arch_init_kwargs=self.network_arch_init_kwargs,\n",
        "            arch_init_kwargs_req_import=self.network_arch_init_kwargs_req_import,\n",
        "            num_input_channels=self.num_input_channels,\n",
        "            num_output_channels=self.label_manager.num_segmentation_heads,\n",
        "            enable_deep_supervision=self.enable_deep_supervision\n",
        "        )\n",
        "\n",
        "    def on_train_start(self):\n",
        "        super().on_train_start()\n",
        "        # ensure tensors are on the right device\n",
        "        self.cls_class_weights = self.cls_class_weights.to(self.device)\n",
        "        self.cls_log_prior = self.cls_log_prior.to(self.device)\n",
        "        if isinstance(getattr(self.classification_loss, \"weight\", None), torch.Tensor):\n",
        "            self.classification_loss.weight = self.cls_class_weights.to(self.device)\n",
        "\n",
        "    def on_epoch_start(self):\n",
        "        super().on_epoch_start()\n",
        "        self._epoch_idx += 1\n",
        "        self._val_cls_acc_epoch = []\n",
        "\n",
        "    # ---------- helpers ----------\n",
        "    @staticmethod\n",
        "    def _nan_to_num(x, lim=1e6):\n",
        "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        return x.clamp(min=-lim, max=lim)\n",
        "\n",
        "    def _align_target_to_output(self, target, seg_logits: torch.Tensor) -> torch.Tensor:\n",
        "        t = target[0] if isinstance(target, (list, tuple)) else target\n",
        "        if not torch.is_tensor(t):\n",
        "            t = torch.as_tensor(t)\n",
        "        t = t.to(device=seg_logits.device, non_blocking=True)\n",
        "\n",
        "        # squeeze extra singletons\n",
        "        while t.ndim > seg_logits.ndim:\n",
        "            reduced = False\n",
        "            for dim in (1, 2, 0):\n",
        "                if dim < t.ndim and t.shape[dim] == 1:\n",
        "                    t = t.squeeze(dim); reduced = True; break\n",
        "            if not reduced:\n",
        "                for dim in range(t.ndim):\n",
        "                    if t.shape[dim] == 1:\n",
        "                        t = t.squeeze(dim); reduced = True; break\n",
        "            if not reduced:\n",
        "                break\n",
        "\n",
        "        # add channel if missing\n",
        "        if t.ndim == seg_logits.ndim - 1:\n",
        "            t = t.unsqueeze(1)\n",
        "\n",
        "        # clamp labels into valid range (defensive)\n",
        "        num_classes = seg_logits.shape[1]\n",
        "        t = t.long().clamp(min=0, max=max(0, num_classes - 1))\n",
        "\n",
        "        if t.ndim != seg_logits.ndim:\n",
        "            raise RuntimeError(f\"Target rank {t.ndim} mismatches output rank {seg_logits.ndim}. \"\n",
        "                               f\"target {tuple(t.shape)} vs output {tuple(seg_logits.shape)}\")\n",
        "        return t\n",
        "\n",
        "    def _ensure_bc_first(self, seg_logits: torch.Tensor, data: torch.Tensor) -> torch.Tensor:\n",
        "        if seg_logits.ndim >= 2:\n",
        "            B_data = data.shape[0]\n",
        "            if seg_logits.shape[0] != B_data and seg_logits.shape[1] == B_data:\n",
        "                perm = list(range(seg_logits.ndim))\n",
        "                perm[0], perm[1] = 1, 0\n",
        "                seg_logits = seg_logits.permute(*perm).contiguous()\n",
        "        return seg_logits\n",
        "\n",
        "    def _cls_targets_and_mask(self, batch):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          cls_target: LongTensor [B] with -1 where the label is unknown\n",
        "          mask:       BoolTensor [B] True where label is known\n",
        "        \"\"\"\n",
        "        bs = batch['data'].shape[0]\n",
        "        if 'keys' in batch:\n",
        "            keys = list(batch['keys'])\n",
        "            t = []\n",
        "            for k in keys:\n",
        "                t.append(self.case_to_subtype[k] if k in self.case_to_subtype else -1)\n",
        "            tgt = torch.as_tensor(t, dtype=torch.long, device=self.device)\n",
        "        else:\n",
        "            tgt = torch.full((bs,), -1, dtype=torch.long, device=self.device)\n",
        "        mask = tgt >= 0\n",
        "        return tgt, mask\n",
        "\n",
        "    def _cls_weight_schedule(self) -> float:\n",
        "        e = max(0, self._epoch_idx)\n",
        "        if self.cls_weight_ramp_epochs <= 0:\n",
        "            return float(self.cls_weight_end)\n",
        "        frac = min(1.0, e / float(self.cls_weight_ramp_epochs))\n",
        "        return float(self.cls_weight_start + frac * (self.cls_weight_end - self.cls_weight_start))\n",
        "\n",
        "    # ---------- train/val ----------\n",
        "    def train_step(self, batch):\n",
        "        data = batch['data'].to(self.device, non_blocking=True)\n",
        "\n",
        "        self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # FP32 warmup for first few steps (avoid AMP NaNs at start)\n",
        "        use_amp = (self.device.type == 'cuda') and (self._train_step_count >= self._fp32_warmup_steps)\n",
        "        ctx = autocast(self.device.type, enabled=use_amp) if use_amp else dummy_context()\n",
        "\n",
        "        with ctx:\n",
        "            seg_out, cls_out = self.network(data, return_both=True)\n",
        "            seg_logits = seg_out[0] if isinstance(seg_out, (list, tuple)) else seg_out\n",
        "            seg_logits = self._nan_to_num(self._ensure_bc_first(seg_logits, data))\n",
        "            target = self._align_target_to_output(batch['target'], seg_logits)\n",
        "\n",
        "            # sanitize cls logits too\n",
        "            cls_out = self._nan_to_num(cls_out)\n",
        "\n",
        "            seg_loss = self.loss(seg_logits, target)\n",
        "\n",
        "            # classification (masked) + logit adjustment\n",
        "            cls_target, cls_mask = self._cls_targets_and_mask(batch)\n",
        "            if cls_mask.any():\n",
        "                cls_logits_adj = cls_out - (self.cls_log_prior.to(cls_out.dtype))[None, :] * self.cls_logit_adj_tau\n",
        "                cls_logits_adj = self._nan_to_num(cls_logits_adj)\n",
        "                cls_loss = self.classification_loss(cls_logits_adj[cls_mask], cls_target[cls_mask])\n",
        "                cls_acc  = (torch.argmax(cls_logits_adj[cls_mask], dim=1) == cls_target[cls_mask]).float().mean().item()\n",
        "            else:\n",
        "                cls_loss = torch.zeros((), device=self.device)\n",
        "                cls_acc  = float('nan')\n",
        "\n",
        "            total_loss = seg_loss + self._cls_weight_schedule() * cls_loss\n",
        "\n",
        "        # if NaN/Inf slipped through, try a last-chance FP32 recompute\n",
        "        if not torch.isfinite(total_loss):\n",
        "            print(\"⚠️ Non-finite loss encountered. Retrying batch in FP32 fall-back.\")\n",
        "            with dummy_context():\n",
        "                seg_out, cls_out = self.network(data, return_both=True)\n",
        "                seg_logits = seg_out[0] if isinstance(seg_out, (list, tuple)) else seg_out\n",
        "                seg_logits = self._nan_to_num(self._ensure_bc_first(seg_logits, data).float())\n",
        "                target = self._align_target_to_output(batch['target'], seg_logits)\n",
        "                cls_out = self._nan_to_num(cls_out.float())\n",
        "\n",
        "                seg_loss = self.loss(seg_logits, target)\n",
        "                cls_target, cls_mask = self._cls_targets_and_mask(batch)\n",
        "                if cls_mask.any():\n",
        "                    cls_logits_adj = self._nan_to_num(cls_out - (self.cls_log_prior.to(cls_out.dtype))[None, :] * self.cls_logit_adj_tau)\n",
        "                    cls_loss = self.classification_loss(cls_logits_adj[cls_mask], cls_target[cls_mask])\n",
        "                    cls_acc  = (torch.argmax(cls_logits_adj[cls_mask], dim=1) == cls_target[cls_mask]).float().mean().item()\n",
        "                else:\n",
        "                    cls_loss = torch.zeros((), device=self.device)\n",
        "                    cls_acc  = float('nan')\n",
        "                total_loss = seg_loss + self._cls_weight_schedule() * cls_loss\n",
        "\n",
        "        if not torch.isfinite(total_loss):\n",
        "            print(\"⚠️ Non-finite loss persists. Skipping batch.\")\n",
        "            return {'loss': np.array(float('nan'))}\n",
        "\n",
        "        if self.grad_scaler is not None and use_amp:\n",
        "            self.grad_scaler.scale(total_loss).backward()\n",
        "            self.grad_scaler.unscale_(self.optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
        "            self.grad_scaler.step(self.optimizer)\n",
        "            self.grad_scaler.update()\n",
        "        else:\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
        "            self.optimizer.step()\n",
        "\n",
        "        self._train_step_count += 1\n",
        "\n",
        "        if not np.isnan(cls_acc):\n",
        "            self.classification_metrics['train_acc'].append(cls_acc)\n",
        "\n",
        "        return {\n",
        "            'loss': total_loss.detach().cpu().numpy(),\n",
        "            'seg_loss': seg_loss.detach().cpu().numpy(),\n",
        "            'cls_loss': cls_loss.detach().cpu().numpy(),\n",
        "            'cls_acc': cls_acc,\n",
        "        }\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        data = batch['data'].to(self.device, non_blocking=True)\n",
        "        with torch.no_grad():\n",
        "            seg_out, cls_out = self.network(data, return_both=True)\n",
        "            seg_logits = seg_out[0] if isinstance(seg_out, (list, tuple)) else seg_out\n",
        "            seg_logits = self._nan_to_num(self._ensure_bc_first(seg_logits, data))\n",
        "            target = self._align_target_to_output(batch['target'], seg_logits)\n",
        "            target_for_metrics = target\n",
        "\n",
        "            cls_out = self._nan_to_num(cls_out)\n",
        "\n",
        "            seg_loss = self.loss(seg_logits, target)\n",
        "\n",
        "            # classification (masked) + logit adjustment\n",
        "            cls_target, cls_mask = self._cls_targets_and_mask(batch)\n",
        "            if cls_mask.any():\n",
        "                cls_logits_adj = self._nan_to_num(cls_out - (self.cls_log_prior.to(cls_out.dtype))[None, :] * self.cls_logit_adj_tau)\n",
        "                cls_loss = self.classification_loss(cls_logits_adj[cls_mask], cls_target[cls_mask])\n",
        "                cls_preds = torch.argmax(cls_logits_adj[cls_mask], dim=1)\n",
        "                cls_acc = (cls_preds == cls_target[cls_mask]).float().mean().item()\n",
        "                self.classification_metrics['val_acc'].append(cls_acc)\n",
        "                self._val_cls_acc_epoch.append(cls_acc)\n",
        "            else:\n",
        "                cls_loss = torch.zeros((), device=self.device)\n",
        "                cls_acc = float('nan')\n",
        "\n",
        "            total_loss = seg_loss + self._cls_weight_schedule() * cls_loss\n",
        "\n",
        "            # dice bookkeeping as in nnU-Net\n",
        "            if self.label_manager.has_regions:\n",
        "                predicted_segmentation_onehot = (torch.sigmoid(seg_logits) > 0.5).long()\n",
        "            else:\n",
        "                output_seg = seg_logits.argmax(1)[:, None]\n",
        "                predicted_segmentation_onehot = torch.zeros(\n",
        "                    seg_logits.shape, device=seg_logits.device, dtype=torch.float32\n",
        "                )\n",
        "                predicted_segmentation_onehot.scatter_(1, output_seg, 1)\n",
        "                del output_seg\n",
        "\n",
        "            if self.label_manager.has_ignore_label:\n",
        "                if not self.label_manager.has_regions:\n",
        "                    mask = (target_for_metrics != self.label_manager.ignore_label).float()\n",
        "                    target_for_metrics = target_for_metrics.clone()\n",
        "                    target_for_metrics[target_for_metrics == self.label_manager.ignore_label] = 0\n",
        "                else:\n",
        "                    if target_for_metrics.dtype == torch.bool:\n",
        "                        mask = ~target_for_metrics[:, -1:]\n",
        "                    else:\n",
        "                        mask = 1 - target_for_metrics[:, -1:]\n",
        "                    target_for_metrics = target_for_metrics[:, :-1]\n",
        "            else:\n",
        "                mask = None\n",
        "\n",
        "            axes = [0] + list(range(2, seg_logits.ndim))\n",
        "            tp, fp, fn, _ = get_tp_fp_fn_tn(predicted_segmentation_onehot,\n",
        "                                            target_for_metrics, axes=axes, mask=mask)\n",
        "            tp_hard = tp.detach().cpu().numpy()\n",
        "            fp_hard = fp.detach().cpu().numpy()\n",
        "            fn_hard = fn.detach().cpu().numpy()\n",
        "            if not self.label_manager.has_regions:\n",
        "                tp_hard, fp_hard, fn_hard = tp_hard[1:], fp_hard[1:], fn_hard[1:]\n",
        "\n",
        "        return {\n",
        "            'loss': total_loss.detach().cpu().numpy(),\n",
        "            'tp_hard': tp_hard,\n",
        "            'fp_hard': fp_hard,\n",
        "            'fn_hard': fn_hard,\n",
        "            'seg_loss': seg_loss.detach().cpu().numpy(),\n",
        "            'cls_loss': cls_loss.detach().cpu().numpy(),\n",
        "            'cls_acc': cls_acc,\n",
        "        }\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        super().on_epoch_end()\n",
        "        if self.classification_metrics['train_acc']:\n",
        "            train_acc = float(np.mean(self.classification_metrics['train_acc'][-min(50, len(self.classification_metrics['train_acc'])):]))\n",
        "            print(f\"Classification Train Acc: {train_acc:.4f}\")\n",
        "        if self.classification_metrics['val_acc']:\n",
        "            val_acc_hist = float(np.mean(self.classification_metrics['val_acc'][-min(50, len(self.classification_metrics['val_acc'])):]))\n",
        "            print(f\"Classification Val Acc: {val_acc_hist:.4f}\")\n",
        "\n",
        "        if self._val_cls_acc_epoch:\n",
        "            epoch_val_acc = float(np.mean(self._val_cls_acc_epoch))\n",
        "            print(f\"(cls) epoch val acc: {epoch_val_acc:.3f}\")\n",
        "            if epoch_val_acc > self.best_val_cls_acc + 1e-6:\n",
        "                self.best_val_cls_acc = epoch_val_acc\n",
        "                try:\n",
        "                    torch.save(self.network.classification_head.state_dict(), self.best_cls_head_path)\n",
        "                    print(f\"  ↳ saved best classification head → {self.best_cls_head_path}\")\n",
        "                except Exception as e:\n",
        "                    print(\"  ↳ failed to save best classification head:\", e)\n",
        "\n",
        "    def initialize_val_metrics(self):\n",
        "        if not hasattr(self, 'val_metrics'):\n",
        "            self.val_metrics = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XbsGtfF8cIhk",
      "metadata": {
        "id": "XbsGtfF8cIhk"
      },
      "source": [
        "## Training function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "l_dzY-jD_8O-",
      "metadata": {
        "id": "l_dzY-jD_8O-"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "import sys, os, json, torch\n",
        "sys.path.append('/content/nnUNet')\n",
        "\n",
        "from nnunetv2.training.nnUNetTrainer.MultiTaskTrainer import MultiTaskTrainer\n",
        "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "import json\n",
        "\n",
        "def train_multitask_model():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "\n",
        "    print(\"=== Starting Multi-task nnUNet Training ===\")\n",
        "\n",
        "    # Parameters\n",
        "    dataset_id = 500\n",
        "    configuration = \"3d_fullres\"\n",
        "    fold = 0\n",
        "    plans_identifier = \"nnUNetResEncUNetMPlans\"\n",
        "\n",
        "    # Paths\n",
        "    dataset_name = f\"Dataset{dataset_id:03d}_PancreasCancer\"\n",
        "    plans_path = f\"/content/nnUNet_preprocessed/{dataset_name}/{plans_identifier}.json\"\n",
        "    dataset_json_path = f\"/content/nnUNet_raw/{dataset_name}/dataset.json\"\n",
        "\n",
        "    print(f\"Loading plans from: {plans_path}\")\n",
        "    print(f\"Loading dataset.json from: {dataset_json_path}\")\n",
        "\n",
        "    # Load plans\n",
        "    with open(plans_path, 'r') as f:\n",
        "        plans = json.load(f)\n",
        "\n",
        "    # Load dataset.json\n",
        "    with open(dataset_json_path, 'r') as f:\n",
        "        dataset_json = json.load(f)\n",
        "\n",
        "    # Initialize trainer\n",
        "    print(\"Initializing multi-task trainer...\")\n",
        "    trainer = MultiTaskTrainer(\n",
        "        plans=plans,\n",
        "        configuration=configuration,\n",
        "        fold=fold,\n",
        "        dataset_json=dataset_json,\n",
        "        # unpack_dataset=True,\n",
        "        device=torch.device('cuda')\n",
        "    )\n",
        "\n",
        "    # Set reduced number of epochs for Colab\n",
        "    trainer.num_epochs = 250  # Reduced from default 1000\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.run_training()\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XDV7A9KAABwP",
      "metadata": {
        "id": "XDV7A9KAABwP"
      },
      "source": [
        "## Execute training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pB1s8pH7WENl",
      "metadata": {
        "id": "pB1s8pH7WENl"
      },
      "outputs": [],
      "source": [
        "# Run this after patching MultiTaskTrainer\n",
        "from importlib import reload\n",
        "import nnunetv2.training.nnUNetTrainer.MultiTaskTrainer as mt\n",
        "reload(mt)\n",
        "from nnunetv2.training.nnUNetTrainer.MultiTaskTrainer import MultiTaskTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kpm0q-iZ1_H9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kpm0q-iZ1_H9",
        "outputId": "d3517985-1cc1-4b05-f7e2-7118166633f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Starting Multi-task nnUNet Training ===\n",
            "Loading plans from: /content/nnUNet_preprocessed/Dataset500_PancreasCancer/nnUNetResEncUNetMPlans.json\n",
            "Loading dataset.json from: /content/nnUNet_raw/Dataset500_PancreasCancer/dataset.json\n",
            "Initializing multi-task trainer...\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "Loaded 252 classification labels\n",
            "Starting training...\n",
            "2025-08-15 12:44:31.751993: do_dummy_2d_data_aug: False\n",
            "2025-08-15 12:44:31.753348: Using splits from existing split file: /content/nnUNet_preprocessed/Dataset500_PancreasCancer/splits_final.json\n",
            "2025-08-15 12:44:31.753706: The split file contains 5 splits.\n",
            "2025-08-15 12:44:31.753770: Desired fold for training: 0\n",
            "2025-08-15 12:44:31.753815: This split has 201 training and 51 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 192], 'median_image_size_in_voxels': [59.0, 118.0, 181.0], 'spacing': [2.0, 0.73046875, 0.73046875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset500_PancreasCancer', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [2.0, 0.73046875, 0.73046875], 'original_median_shape_after_transp': [64, 119, 178], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1929.0, 'mean': 74.89202880859375, 'median': 78.01163482666016, 'min': -319.0, 'percentile_00_5': -55.99610900878906, 'percentile_99_5': 179.97802734375, 'std': 44.09819030761719}}} \n",
            "\n",
            "2025-08-15 12:44:35.785370: Unable to plot network architecture:\n",
            "2025-08-15 12:44:35.791919: No module named 'hiddenlayer'\n",
            "2025-08-15 12:44:35.881535: \n",
            "2025-08-15 12:44:35.884183: Epoch 0\n",
            "2025-08-15 12:44:35.889414: Current learning rate: 0.01\n",
            "2025-08-15 12:45:50.154262: train_loss 0.2455\n",
            "2025-08-15 12:45:50.154620: val_loss 0.2571\n",
            "2025-08-15 12:45:50.155202: Pseudo dice [np.float32(0.1313), np.float32(0.0)]\n",
            "2025-08-15 12:45:50.155354: Epoch time: 74.3 s\n",
            "2025-08-15 12:45:50.155430: Yayy! New best EMA pseudo Dice: 0.06560000032186508\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "  ↳ saved best classification head → /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/checkpoint_best_cls_head.pth\n",
            "2025-08-15 12:45:52.654652: \n",
            "2025-08-15 12:45:52.655113: Epoch 1\n",
            "2025-08-15 12:45:52.655246: Current learning rate: 0.00996\n",
            "2025-08-15 12:46:54.242623: train_loss 0.1236\n",
            "2025-08-15 12:46:54.242947: val_loss 0.0669\n",
            "2025-08-15 12:46:54.243298: Pseudo dice [np.float32(0.4451), np.float32(0.0)]\n",
            "2025-08-15 12:46:54.243395: Epoch time: 61.59 s\n",
            "2025-08-15 12:46:54.243541: Yayy! New best EMA pseudo Dice: 0.08129999786615372\n",
            "Classification Train Acc: 0.3300\n",
            "Classification Val Acc: 0.4800\n",
            "(cls) epoch val acc: 0.480\n",
            "  ↳ saved best classification head → /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/checkpoint_best_cls_head.pth\n",
            "2025-08-15 12:46:56.934894: \n",
            "2025-08-15 12:46:56.935252: Epoch 2\n",
            "2025-08-15 12:46:56.935423: Current learning rate: 0.00993\n",
            "2025-08-15 12:47:58.562538: train_loss 0.0467\n",
            "2025-08-15 12:47:58.562845: val_loss 0.0487\n",
            "2025-08-15 12:47:58.563221: Pseudo dice [np.float32(0.4736), np.float32(0.0)]\n",
            "2025-08-15 12:47:58.563322: Epoch time: 61.63 s\n",
            "2025-08-15 12:47:58.563392: Yayy! New best EMA pseudo Dice: 0.09690000116825104\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.5300\n",
            "(cls) epoch val acc: 0.530\n",
            "  ↳ saved best classification head → /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/checkpoint_best_cls_head.pth\n",
            "2025-08-15 12:48:01.254769: \n",
            "2025-08-15 12:48:01.255099: Epoch 3\n",
            "2025-08-15 12:48:01.255228: Current learning rate: 0.00989\n",
            "2025-08-15 12:49:02.754340: train_loss -0.0012\n",
            "2025-08-15 12:49:02.754664: val_loss -0.0182\n",
            "2025-08-15 12:49:02.755100: Pseudo dice [np.float32(0.5657), np.float32(0.2454)]\n",
            "2025-08-15 12:49:02.755198: Epoch time: 61.5 s\n",
            "2025-08-15 12:49:02.755278: Yayy! New best EMA pseudo Dice: 0.12770000100135803\n",
            "Classification Train Acc: 0.4400\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 12:49:05.431236: \n",
            "2025-08-15 12:49:05.431751: Epoch 4\n",
            "2025-08-15 12:49:05.431889: Current learning rate: 0.00986\n",
            "2025-08-15 12:50:06.922714: train_loss -0.0136\n",
            "2025-08-15 12:50:06.923039: val_loss -0.0194\n",
            "2025-08-15 12:50:06.923617: Pseudo dice [np.float32(0.5588), np.float32(0.3224)]\n",
            "2025-08-15 12:50:06.923874: Epoch time: 61.5 s\n",
            "2025-08-15 12:50:06.924045: Yayy! New best EMA pseudo Dice: 0.1589999943971634\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4500\n",
            "(cls) epoch val acc: 0.450\n",
            "2025-08-15 12:50:09.610500: \n",
            "2025-08-15 12:50:09.611072: Epoch 5\n",
            "2025-08-15 12:50:09.611229: Current learning rate: 0.00982\n",
            "2025-08-15 12:51:11.087896: train_loss -0.012\n",
            "2025-08-15 12:51:11.088212: val_loss 0.0081\n",
            "2025-08-15 12:51:11.088593: Pseudo dice [np.float32(0.5661), np.float32(0.3381)]\n",
            "2025-08-15 12:51:11.088698: Epoch time: 61.48 s\n",
            "2025-08-15 12:51:11.088812: Yayy! New best EMA pseudo Dice: 0.1882999986410141\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.3000\n",
            "(cls) epoch val acc: 0.300\n",
            "2025-08-15 12:51:13.754001: \n",
            "2025-08-15 12:51:13.754322: Epoch 6\n",
            "2025-08-15 12:51:13.754435: Current learning rate: 0.00978\n",
            "2025-08-15 12:52:15.293885: train_loss -0.0383\n",
            "2025-08-15 12:52:15.294232: val_loss 0.0096\n",
            "2025-08-15 12:52:15.294588: Pseudo dice [np.float32(0.6365), np.float32(0.2692)]\n",
            "2025-08-15 12:52:15.294741: Epoch time: 61.54 s\n",
            "2025-08-15 12:52:15.294818: Yayy! New best EMA pseudo Dice: 0.21480000019073486\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.3200\n",
            "(cls) epoch val acc: 0.320\n",
            "2025-08-15 12:52:17.867592: \n",
            "2025-08-15 12:52:17.868081: Epoch 7\n",
            "2025-08-15 12:52:17.868321: Current learning rate: 0.00975\n",
            "2025-08-15 12:53:19.387811: train_loss -0.072\n",
            "2025-08-15 12:53:19.388150: val_loss -0.0612\n",
            "2025-08-15 12:53:19.388631: Pseudo dice [np.float32(0.6793), np.float32(0.3529)]\n",
            "2025-08-15 12:53:19.388746: Epoch time: 61.52 s\n",
            "2025-08-15 12:53:19.388822: Yayy! New best EMA pseudo Dice: 0.24490000307559967\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 12:53:22.063407: \n",
            "2025-08-15 12:53:22.064093: Epoch 8\n",
            "2025-08-15 12:53:22.064216: Current learning rate: 0.00971\n",
            "2025-08-15 12:54:23.509492: train_loss -0.0231\n",
            "2025-08-15 12:54:23.509799: val_loss 0.0041\n",
            "2025-08-15 12:54:23.510199: Pseudo dice [np.float32(0.6812), np.float32(0.2405)]\n",
            "2025-08-15 12:54:23.510295: Epoch time: 61.45 s\n",
            "2025-08-15 12:54:23.510365: Yayy! New best EMA pseudo Dice: 0.26649999618530273\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 12:54:26.124115: \n",
            "2025-08-15 12:54:26.124674: Epoch 9\n",
            "2025-08-15 12:54:26.124792: Current learning rate: 0.00968\n",
            "2025-08-15 12:55:27.634089: train_loss -0.0991\n",
            "2025-08-15 12:55:27.634425: val_loss 0.0293\n",
            "2025-08-15 12:55:27.634798: Pseudo dice [np.float32(0.6481), np.float32(0.2779)]\n",
            "2025-08-15 12:55:27.634896: Epoch time: 61.51 s\n",
            "2025-08-15 12:55:27.634969: Yayy! New best EMA pseudo Dice: 0.28619998693466187\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.5300\n",
            "(cls) epoch val acc: 0.530\n",
            "2025-08-15 12:55:30.479229: \n",
            "2025-08-15 12:55:30.479813: Epoch 10\n",
            "2025-08-15 12:55:30.479940: Current learning rate: 0.00964\n",
            "2025-08-15 12:56:32.003630: train_loss -0.0705\n",
            "2025-08-15 12:56:32.003953: val_loss -0.0465\n",
            "2025-08-15 12:56:32.004313: Pseudo dice [np.float32(0.6925), np.float32(0.3638)]\n",
            "2025-08-15 12:56:32.004405: Epoch time: 61.53 s\n",
            "2025-08-15 12:56:32.004481: Yayy! New best EMA pseudo Dice: 0.31040000915527344\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 12:56:34.625688: \n",
            "2025-08-15 12:56:34.626251: Epoch 11\n",
            "2025-08-15 12:56:34.626368: Current learning rate: 0.0096\n",
            "2025-08-15 12:57:36.073763: train_loss -0.048\n",
            "2025-08-15 12:57:36.074144: val_loss 0.043\n",
            "2025-08-15 12:57:36.074560: Pseudo dice [np.float32(0.6848), np.float32(0.2517)]\n",
            "2025-08-15 12:57:36.074664: Epoch time: 61.45 s\n",
            "2025-08-15 12:57:36.074738: Yayy! New best EMA pseudo Dice: 0.3260999917984009\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.3100\n",
            "(cls) epoch val acc: 0.310\n",
            "2025-08-15 12:57:38.666857: \n",
            "2025-08-15 12:57:38.667638: Epoch 12\n",
            "2025-08-15 12:57:38.667775: Current learning rate: 0.00957\n",
            "2025-08-15 12:58:40.140683: train_loss -0.0146\n",
            "2025-08-15 12:58:40.141054: val_loss -0.0137\n",
            "2025-08-15 12:58:40.141571: Pseudo dice [np.float32(0.7014), np.float32(0.3301)]\n",
            "2025-08-15 12:58:40.141680: Epoch time: 61.48 s\n",
            "2025-08-15 12:58:40.141767: Yayy! New best EMA pseudo Dice: 0.3450999855995178\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 12:58:42.760495: \n",
            "2025-08-15 12:58:42.761208: Epoch 13\n",
            "2025-08-15 12:58:42.761367: Current learning rate: 0.00953\n",
            "2025-08-15 12:59:44.214934: train_loss -0.0438\n",
            "2025-08-15 12:59:44.215294: val_loss 0.0168\n",
            "2025-08-15 12:59:44.215685: Pseudo dice [np.float32(0.7207), np.float32(0.4084)]\n",
            "2025-08-15 12:59:44.215799: Epoch time: 61.46 s\n",
            "2025-08-15 12:59:44.215914: Yayy! New best EMA pseudo Dice: 0.3671000003814697\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.3700\n",
            "(cls) epoch val acc: 0.370\n",
            "2025-08-15 12:59:48.673901: \n",
            "2025-08-15 12:59:48.674234: Epoch 14\n",
            "2025-08-15 12:59:48.674357: Current learning rate: 0.00949\n",
            "2025-08-15 13:00:50.156428: train_loss -0.0349\n",
            "2025-08-15 13:00:50.156774: val_loss -0.0022\n",
            "2025-08-15 13:00:50.157222: Pseudo dice [np.float32(0.7318), np.float32(0.3991)]\n",
            "2025-08-15 13:00:50.157359: Epoch time: 61.49 s\n",
            "2025-08-15 13:00:50.157434: Yayy! New best EMA pseudo Dice: 0.38690000772476196\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 13:00:52.768035: \n",
            "2025-08-15 13:00:52.768575: Epoch 15\n",
            "2025-08-15 13:00:52.768693: Current learning rate: 0.00946\n",
            "2025-08-15 13:01:54.247397: train_loss -0.0256\n",
            "2025-08-15 13:01:54.247730: val_loss 0.0431\n",
            "2025-08-15 13:01:54.248200: Pseudo dice [np.float32(0.7149), np.float32(0.3616)]\n",
            "2025-08-15 13:01:54.248367: Epoch time: 61.48 s\n",
            "2025-08-15 13:01:54.248441: Yayy! New best EMA pseudo Dice: 0.4020000100135803\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.3100\n",
            "(cls) epoch val acc: 0.310\n",
            "2025-08-15 13:01:56.812839: \n",
            "2025-08-15 13:01:56.813381: Epoch 16\n",
            "2025-08-15 13:01:56.813503: Current learning rate: 0.00942\n",
            "2025-08-15 13:02:58.307949: train_loss -0.0167\n",
            "2025-08-15 13:02:58.308399: val_loss 0.0618\n",
            "2025-08-15 13:02:58.308835: Pseudo dice [np.float32(0.7349), np.float32(0.4101)]\n",
            "2025-08-15 13:02:58.308954: Epoch time: 61.5 s\n",
            "2025-08-15 13:02:58.309073: Yayy! New best EMA pseudo Dice: 0.41909998655319214\n",
            "Classification Train Acc: 0.3500\n",
            "Classification Val Acc: 0.2300\n",
            "(cls) epoch val acc: 0.230\n",
            "2025-08-15 13:03:00.931360: \n",
            "2025-08-15 13:03:00.931922: Epoch 17\n",
            "2025-08-15 13:03:00.932152: Current learning rate: 0.00939\n",
            "2025-08-15 13:04:02.337803: train_loss 0.0035\n",
            "2025-08-15 13:04:02.338145: val_loss 0.1137\n",
            "2025-08-15 13:04:02.338529: Pseudo dice [np.float32(0.7191), np.float32(0.2914)]\n",
            "2025-08-15 13:04:02.338722: Epoch time: 61.41 s\n",
            "2025-08-15 13:04:02.338910: Yayy! New best EMA pseudo Dice: 0.427700012922287\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 13:04:05.007524: \n",
            "2025-08-15 13:04:05.008162: Epoch 18\n",
            "2025-08-15 13:04:05.008281: Current learning rate: 0.00935\n",
            "2025-08-15 13:05:06.544959: train_loss 0.0042\n",
            "2025-08-15 13:05:06.545373: val_loss 0.133\n",
            "2025-08-15 13:05:06.545818: Pseudo dice [np.float32(0.7061), np.float32(0.3418)]\n",
            "2025-08-15 13:05:06.546004: Epoch time: 61.54 s\n",
            "2025-08-15 13:05:06.546116: Yayy! New best EMA pseudo Dice: 0.4372999966144562\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 13:05:09.207214: \n",
            "2025-08-15 13:05:09.207850: Epoch 19\n",
            "2025-08-15 13:05:09.207970: Current learning rate: 0.00931\n",
            "2025-08-15 13:06:10.648381: train_loss 0.0359\n",
            "2025-08-15 13:06:10.648689: val_loss 0.0951\n",
            "2025-08-15 13:06:10.649167: Pseudo dice [np.float32(0.7295), np.float32(0.4146)]\n",
            "2025-08-15 13:06:10.649339: Epoch time: 61.44 s\n",
            "2025-08-15 13:06:10.649415: Yayy! New best EMA pseudo Dice: 0.45080000162124634\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.4600\n",
            "(cls) epoch val acc: 0.460\n",
            "2025-08-15 13:06:13.274150: \n",
            "2025-08-15 13:06:13.274715: Epoch 20\n",
            "2025-08-15 13:06:13.274834: Current learning rate: 0.00928\n",
            "2025-08-15 13:07:14.745999: train_loss 0.0327\n",
            "2025-08-15 13:07:14.746299: val_loss 0.0669\n",
            "2025-08-15 13:07:14.746818: Pseudo dice [np.float32(0.7588), np.float32(0.4128)]\n",
            "2025-08-15 13:07:14.747064: Epoch time: 61.48 s\n",
            "2025-08-15 13:07:14.747166: Yayy! New best EMA pseudo Dice: 0.4643000066280365\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 13:07:17.392319: \n",
            "2025-08-15 13:07:17.392711: Epoch 21\n",
            "2025-08-15 13:07:17.392842: Current learning rate: 0.00924\n",
            "2025-08-15 13:08:18.982115: train_loss 0.0339\n",
            "2025-08-15 13:08:18.982403: val_loss 0.0425\n",
            "2025-08-15 13:08:18.982770: Pseudo dice [np.float32(0.7766), np.float32(0.5546)]\n",
            "2025-08-15 13:08:18.982871: Epoch time: 61.59 s\n",
            "2025-08-15 13:08:18.982939: Yayy! New best EMA pseudo Dice: 0.4844000041484833\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.2900\n",
            "(cls) epoch val acc: 0.290\n",
            "2025-08-15 13:08:21.551451: \n",
            "2025-08-15 13:08:21.552093: Epoch 22\n",
            "2025-08-15 13:08:21.552208: Current learning rate: 0.0092\n",
            "2025-08-15 13:09:23.072809: train_loss 0.0538\n",
            "2025-08-15 13:09:23.073160: val_loss 0.1314\n",
            "2025-08-15 13:09:23.073519: Pseudo dice [np.float32(0.7585), np.float32(0.4424)]\n",
            "2025-08-15 13:09:23.073610: Epoch time: 61.53 s\n",
            "2025-08-15 13:09:23.073677: Yayy! New best EMA pseudo Dice: 0.4959999918937683\n",
            "Classification Train Acc: 0.4700\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 13:09:25.710908: \n",
            "2025-08-15 13:09:25.711413: Epoch 23\n",
            "2025-08-15 13:09:25.711539: Current learning rate: 0.00917\n",
            "2025-08-15 13:10:27.252128: train_loss 0.0598\n",
            "2025-08-15 13:10:27.252444: val_loss 0.1232\n",
            "2025-08-15 13:10:27.252858: Pseudo dice [np.float32(0.7517), np.float32(0.4204)]\n",
            "2025-08-15 13:10:27.252950: Epoch time: 61.54 s\n",
            "2025-08-15 13:10:27.253053: Yayy! New best EMA pseudo Dice: 0.5049999952316284\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 13:10:29.866393: \n",
            "2025-08-15 13:10:29.867044: Epoch 24\n",
            "2025-08-15 13:10:29.867162: Current learning rate: 0.00913\n",
            "2025-08-15 13:11:31.338856: train_loss 0.1136\n",
            "2025-08-15 13:11:31.339222: val_loss 0.209\n",
            "2025-08-15 13:11:31.339672: Pseudo dice [np.float32(0.7288), np.float32(0.3945)]\n",
            "2025-08-15 13:11:31.339822: Epoch time: 61.48 s\n",
            "2025-08-15 13:11:31.339970: Yayy! New best EMA pseudo Dice: 0.510699987411499\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.3100\n",
            "(cls) epoch val acc: 0.310\n",
            "2025-08-15 13:11:33.942527: \n",
            "2025-08-15 13:11:33.943045: Epoch 25\n",
            "2025-08-15 13:11:33.943167: Current learning rate: 0.0091\n",
            "2025-08-15 13:12:35.423258: train_loss 0.0901\n",
            "2025-08-15 13:12:35.423528: val_loss 0.202\n",
            "2025-08-15 13:12:35.423894: Pseudo dice [np.float32(0.77), np.float32(0.3894)]\n",
            "2025-08-15 13:12:35.424012: Epoch time: 61.48 s\n",
            "2025-08-15 13:12:35.424107: Yayy! New best EMA pseudo Dice: 0.5175999999046326\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.2300\n",
            "(cls) epoch val acc: 0.230\n",
            "2025-08-15 13:12:37.984200: \n",
            "2025-08-15 13:12:37.984736: Epoch 26\n",
            "2025-08-15 13:12:37.984853: Current learning rate: 0.00906\n",
            "2025-08-15 13:13:39.463752: train_loss 0.13\n",
            "2025-08-15 13:13:39.464052: val_loss 0.168\n",
            "2025-08-15 13:13:39.464694: Pseudo dice [np.float32(0.7789), np.float32(0.5035)]\n",
            "2025-08-15 13:13:39.464808: Epoch time: 61.48 s\n",
            "2025-08-15 13:13:39.464892: Yayy! New best EMA pseudo Dice: 0.5299000144004822\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 13:13:42.047533: \n",
            "2025-08-15 13:13:42.048068: Epoch 27\n",
            "2025-08-15 13:13:42.048192: Current learning rate: 0.00902\n",
            "2025-08-15 13:14:43.582390: train_loss 2.1118\n",
            "2025-08-15 13:14:43.582757: val_loss 0.1687\n",
            "2025-08-15 13:14:43.583140: Pseudo dice [np.float32(0.7788), np.float32(0.4877)]\n",
            "2025-08-15 13:14:43.583232: Epoch time: 61.54 s\n",
            "2025-08-15 13:14:43.583301: Yayy! New best EMA pseudo Dice: 0.5403000116348267\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 13:14:46.098493: \n",
            "2025-08-15 13:14:46.099022: Epoch 28\n",
            "2025-08-15 13:14:46.099136: Current learning rate: 0.00899\n",
            "2025-08-15 13:15:47.659750: train_loss 0.1087\n",
            "2025-08-15 13:15:47.660134: val_loss 0.2217\n",
            "2025-08-15 13:15:47.660552: Pseudo dice [np.float32(0.7442), np.float32(0.4224)]\n",
            "2025-08-15 13:15:47.660646: Epoch time: 61.56 s\n",
            "2025-08-15 13:15:47.660714: Yayy! New best EMA pseudo Dice: 0.5446000099182129\n",
            "Classification Train Acc: 0.5000\n",
            "Classification Val Acc: 0.4500\n",
            "(cls) epoch val acc: 0.450\n",
            "2025-08-15 13:15:50.186580: \n",
            "2025-08-15 13:15:50.187270: Epoch 29\n",
            "2025-08-15 13:15:50.187393: Current learning rate: 0.00895\n",
            "2025-08-15 13:16:51.697425: train_loss 0.0725\n",
            "2025-08-15 13:16:51.697751: val_loss 0.1821\n",
            "2025-08-15 13:16:51.698131: Pseudo dice [np.float32(0.7658), np.float32(0.4107)]\n",
            "2025-08-15 13:16:51.698236: Epoch time: 61.51 s\n",
            "2025-08-15 13:16:51.698318: Yayy! New best EMA pseudo Dice: 0.5489000082015991\n",
            "Classification Train Acc: 0.3300\n",
            "Classification Val Acc: 0.1900\n",
            "(cls) epoch val acc: 0.190\n",
            "2025-08-15 13:16:54.263457: \n",
            "2025-08-15 13:16:54.263993: Epoch 30\n",
            "2025-08-15 13:16:54.264110: Current learning rate: 0.00891\n",
            "2025-08-15 13:17:55.759208: train_loss 0.0609\n",
            "2025-08-15 13:17:55.759499: val_loss 0.1851\n",
            "2025-08-15 13:17:55.759921: Pseudo dice [np.float32(0.7769), np.float32(0.3232)]\n",
            "2025-08-15 13:17:55.760094: Epoch time: 61.5 s\n",
            "2025-08-15 13:17:55.760199: Yayy! New best EMA pseudo Dice: 0.5490999817848206\n",
            "Classification Train Acc: 0.2800\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 13:17:58.298037: \n",
            "2025-08-15 13:17:58.298545: Epoch 31\n",
            "2025-08-15 13:17:58.298659: Current learning rate: 0.00888\n",
            "2025-08-15 13:18:59.806246: train_loss 0.1029\n",
            "2025-08-15 13:18:59.806533: val_loss 0.1609\n",
            "2025-08-15 13:18:59.806916: Pseudo dice [np.float32(0.7505), np.float32(0.4475)]\n",
            "2025-08-15 13:18:59.807206: Epoch time: 61.51 s\n",
            "2025-08-15 13:18:59.807393: Yayy! New best EMA pseudo Dice: 0.5540000200271606\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 13:19:02.361308: \n",
            "2025-08-15 13:19:02.361843: Epoch 32\n",
            "2025-08-15 13:19:02.361956: Current learning rate: 0.00884\n",
            "2025-08-15 13:20:03.940613: train_loss 0.0737\n",
            "2025-08-15 13:20:03.940921: val_loss 0.1379\n",
            "2025-08-15 13:20:03.941350: Pseudo dice [np.float32(0.7796), np.float32(0.5094)]\n",
            "2025-08-15 13:20:03.941446: Epoch time: 61.58 s\n",
            "2025-08-15 13:20:03.941561: Yayy! New best EMA pseudo Dice: 0.5630999803543091\n",
            "Classification Train Acc: 0.5600\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 13:20:06.515831: \n",
            "2025-08-15 13:20:06.516416: Epoch 33\n",
            "2025-08-15 13:20:06.516558: Current learning rate: 0.0088\n",
            "2025-08-15 13:21:08.088769: train_loss 0.0821\n",
            "2025-08-15 13:21:08.089069: val_loss 0.0829\n",
            "2025-08-15 13:21:08.089471: Pseudo dice [np.float32(0.7792), np.float32(0.5775)]\n",
            "2025-08-15 13:21:08.089570: Epoch time: 61.58 s\n",
            "2025-08-15 13:21:08.089643: Yayy! New best EMA pseudo Dice: 0.5745999813079834\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 13:21:10.667280: \n",
            "2025-08-15 13:21:10.668023: Epoch 34\n",
            "2025-08-15 13:21:10.668160: Current learning rate: 0.00877\n",
            "2025-08-15 13:22:12.161181: train_loss 0.0427\n",
            "2025-08-15 13:22:12.161512: val_loss 0.1748\n",
            "2025-08-15 13:22:12.161896: Pseudo dice [np.float32(0.7574), np.float32(0.4677)]\n",
            "2025-08-15 13:22:12.162041: Epoch time: 61.5 s\n",
            "2025-08-15 13:22:12.162140: Yayy! New best EMA pseudo Dice: 0.5784000158309937\n",
            "Classification Train Acc: 0.2900\n",
            "Classification Val Acc: 0.2700\n",
            "(cls) epoch val acc: 0.270\n",
            "2025-08-15 13:22:14.755670: \n",
            "2025-08-15 13:22:14.755926: Epoch 35\n",
            "2025-08-15 13:22:14.756048: Current learning rate: 0.00873\n",
            "2025-08-15 13:23:16.241429: train_loss 0.0735\n",
            "2025-08-15 13:23:16.241729: val_loss 0.1269\n",
            "2025-08-15 13:23:16.242194: Pseudo dice [np.float32(0.7921), np.float32(0.444)]\n",
            "2025-08-15 13:23:16.242290: Epoch time: 61.49 s\n",
            "2025-08-15 13:23:16.242358: Yayy! New best EMA pseudo Dice: 0.5824000239372253\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 13:23:18.823833: \n",
            "2025-08-15 13:23:18.824379: Epoch 36\n",
            "2025-08-15 13:23:18.824497: Current learning rate: 0.00869\n",
            "2025-08-15 13:24:20.405917: train_loss 0.0753\n",
            "2025-08-15 13:24:20.406305: val_loss 0.13\n",
            "2025-08-15 13:24:20.406683: Pseudo dice [np.float32(0.8052), np.float32(0.4791)]\n",
            "2025-08-15 13:24:20.406779: Epoch time: 61.59 s\n",
            "2025-08-15 13:24:20.406846: Yayy! New best EMA pseudo Dice: 0.5884000062942505\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 13:24:23.025151: \n",
            "2025-08-15 13:24:23.025513: Epoch 37\n",
            "2025-08-15 13:24:23.025879: Current learning rate: 0.00866\n",
            "2025-08-15 13:25:24.609769: train_loss 0.8655\n",
            "2025-08-15 13:25:24.610280: val_loss 0.2052\n",
            "2025-08-15 13:25:24.610684: Pseudo dice [np.float32(0.7415), np.float32(0.3838)]\n",
            "2025-08-15 13:25:24.610784: Epoch time: 61.59 s\n",
            "Classification Train Acc: 0.2900\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 13:25:25.964220: \n",
            "2025-08-15 13:25:25.964811: Epoch 38\n",
            "2025-08-15 13:25:25.964937: Current learning rate: 0.00862\n",
            "2025-08-15 13:26:27.517695: train_loss 0.0552\n",
            "2025-08-15 13:26:27.518021: val_loss 0.2167\n",
            "2025-08-15 13:26:27.518530: Pseudo dice [np.float32(0.7848), np.float32(0.4362)]\n",
            "2025-08-15 13:26:27.518640: Epoch time: 61.56 s\n",
            "Classification Train Acc: 0.2500\n",
            "Classification Val Acc: 0.2000\n",
            "(cls) epoch val acc: 0.200\n",
            "2025-08-15 13:26:28.872762: \n",
            "2025-08-15 13:26:28.873366: Epoch 39\n",
            "2025-08-15 13:26:28.873503: Current learning rate: 0.00858\n",
            "2025-08-15 13:27:30.408840: train_loss 0.0637\n",
            "2025-08-15 13:27:30.409228: val_loss 0.2172\n",
            "2025-08-15 13:27:30.409600: Pseudo dice [np.float32(0.7779), np.float32(0.4512)]\n",
            "2025-08-15 13:27:30.409693: Epoch time: 61.54 s\n",
            "2025-08-15 13:27:30.409775: Yayy! New best EMA pseudo Dice: 0.5909000039100647\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 13:27:33.052788: \n",
            "2025-08-15 13:27:33.053497: Epoch 40\n",
            "2025-08-15 13:27:33.053658: Current learning rate: 0.00855\n",
            "2025-08-15 13:28:34.593944: train_loss 0.0285\n",
            "2025-08-15 13:28:34.594393: val_loss 0.1251\n",
            "2025-08-15 13:28:34.594778: Pseudo dice [np.float32(0.8076), np.float32(0.4543)]\n",
            "2025-08-15 13:28:34.594887: Epoch time: 61.54 s\n",
            "2025-08-15 13:28:34.594959: Yayy! New best EMA pseudo Dice: 0.5949000120162964\n",
            "Classification Train Acc: 0.2300\n",
            "Classification Val Acc: 0.3400\n",
            "(cls) epoch val acc: 0.340\n",
            "2025-08-15 13:28:37.217262: \n",
            "2025-08-15 13:28:37.217791: Epoch 41\n",
            "2025-08-15 13:28:37.217961: Current learning rate: 0.00851\n",
            "2025-08-15 13:29:38.780199: train_loss 0.0292\n",
            "2025-08-15 13:29:38.780584: val_loss 0.0974\n",
            "2025-08-15 13:29:38.781070: Pseudo dice [np.float32(0.8137), np.float32(0.5385)]\n",
            "2025-08-15 13:29:38.781223: Epoch time: 61.57 s\n",
            "2025-08-15 13:29:38.781305: Yayy! New best EMA pseudo Dice: 0.6029999852180481\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 13:29:41.368752: \n",
            "2025-08-15 13:29:41.369374: Epoch 42\n",
            "2025-08-15 13:29:41.369572: Current learning rate: 0.00847\n",
            "2025-08-15 13:30:42.902808: train_loss 0.0502\n",
            "2025-08-15 13:30:42.903157: val_loss 0.1002\n",
            "2025-08-15 13:30:42.903506: Pseudo dice [np.float32(0.8023), np.float32(0.4946)]\n",
            "2025-08-15 13:30:42.903659: Epoch time: 61.54 s\n",
            "2025-08-15 13:30:42.903755: Yayy! New best EMA pseudo Dice: 0.6075999736785889\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 13:30:45.455946: \n",
            "2025-08-15 13:30:45.456510: Epoch 43\n",
            "2025-08-15 13:30:45.456632: Current learning rate: 0.00844\n",
            "2025-08-15 13:31:46.976068: train_loss 0.0287\n",
            "2025-08-15 13:31:46.976394: val_loss 0.082\n",
            "2025-08-15 13:31:46.976871: Pseudo dice [np.float32(0.8063), np.float32(0.5707)]\n",
            "2025-08-15 13:31:46.977013: Epoch time: 61.52 s\n",
            "2025-08-15 13:31:46.977097: Yayy! New best EMA pseudo Dice: 0.6157000064849854\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 13:31:49.584082: \n",
            "2025-08-15 13:31:49.584694: Epoch 44\n",
            "2025-08-15 13:31:49.584820: Current learning rate: 0.0084\n",
            "2025-08-15 13:32:51.188226: train_loss 0.0515\n",
            "2025-08-15 13:32:51.188659: val_loss 0.1505\n",
            "2025-08-15 13:32:51.189013: Pseudo dice [np.float32(0.7787), np.float32(0.5068)]\n",
            "2025-08-15 13:32:51.189109: Epoch time: 61.61 s\n",
            "2025-08-15 13:32:51.189176: Yayy! New best EMA pseudo Dice: 0.618399977684021\n",
            "Classification Train Acc: 0.4900\n",
            "Classification Val Acc: 0.4500\n",
            "(cls) epoch val acc: 0.450\n",
            "2025-08-15 13:32:54.407934: \n",
            "2025-08-15 13:32:54.408444: Epoch 45\n",
            "2025-08-15 13:32:54.408580: Current learning rate: 0.00836\n",
            "2025-08-15 13:33:55.950130: train_loss 0.0611\n",
            "2025-08-15 13:33:55.950611: val_loss 0.0991\n",
            "2025-08-15 13:33:55.951020: Pseudo dice [np.float32(0.8089), np.float32(0.4674)]\n",
            "2025-08-15 13:33:55.951118: Epoch time: 61.55 s\n",
            "2025-08-15 13:33:55.951187: Yayy! New best EMA pseudo Dice: 0.6202999949455261\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 13:33:58.500385: \n",
            "2025-08-15 13:33:58.500916: Epoch 46\n",
            "2025-08-15 13:33:58.501044: Current learning rate: 0.00833\n",
            "2025-08-15 13:35:00.119099: train_loss 0.0108\n",
            "2025-08-15 13:35:00.119580: val_loss 0.0373\n",
            "2025-08-15 13:35:00.120039: Pseudo dice [np.float32(0.8271), np.float32(0.6565)]\n",
            "2025-08-15 13:35:00.120150: Epoch time: 61.62 s\n",
            "2025-08-15 13:35:00.120221: Yayy! New best EMA pseudo Dice: 0.6324999928474426\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 13:35:02.674901: \n",
            "2025-08-15 13:35:02.675426: Epoch 47\n",
            "2025-08-15 13:35:02.675568: Current learning rate: 0.00829\n",
            "2025-08-15 13:36:04.270768: train_loss 0.0072\n",
            "2025-08-15 13:36:04.271113: val_loss 0.1317\n",
            "2025-08-15 13:36:04.271563: Pseudo dice [np.float32(0.781), np.float32(0.4555)]\n",
            "2025-08-15 13:36:04.271654: Epoch time: 61.6 s\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.4300\n",
            "(cls) epoch val acc: 0.430\n",
            "2025-08-15 13:36:05.564725: \n",
            "2025-08-15 13:36:05.565351: Epoch 48\n",
            "2025-08-15 13:36:05.565471: Current learning rate: 0.00825\n",
            "2025-08-15 13:37:07.067735: train_loss 0.0287\n",
            "2025-08-15 13:37:07.068200: val_loss 0.2431\n",
            "2025-08-15 13:37:07.068529: Pseudo dice [np.float32(0.8021), np.float32(0.3126)]\n",
            "2025-08-15 13:37:07.068623: Epoch time: 61.51 s\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 13:37:08.409267: \n",
            "2025-08-15 13:37:08.409778: Epoch 49\n",
            "2025-08-15 13:37:08.409917: Current learning rate: 0.00822\n",
            "2025-08-15 13:38:09.936195: train_loss 0.0226\n",
            "2025-08-15 13:38:09.936551: val_loss 0.0915\n",
            "2025-08-15 13:38:09.937099: Pseudo dice [np.float32(0.81), np.float32(0.5713)]\n",
            "2025-08-15 13:38:09.937238: Epoch time: 61.53 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 13:38:12.321716: \n",
            "2025-08-15 13:38:12.322299: Epoch 50\n",
            "2025-08-15 13:38:12.322418: Current learning rate: 0.00818\n",
            "2025-08-15 13:39:13.913671: train_loss 0.0046\n",
            "2025-08-15 13:39:13.914113: val_loss 0.1224\n",
            "2025-08-15 13:39:13.914477: Pseudo dice [np.float32(0.7996), np.float32(0.4202)]\n",
            "2025-08-15 13:39:13.914573: Epoch time: 61.6 s\n",
            "Classification Train Acc: 0.5000\n",
            "Classification Val Acc: 0.4600\n",
            "(cls) epoch val acc: 0.460\n",
            "2025-08-15 13:39:15.217021: \n",
            "2025-08-15 13:39:15.217557: Epoch 51\n",
            "2025-08-15 13:39:15.217670: Current learning rate: 0.00814\n",
            "2025-08-15 13:40:16.734338: train_loss 0.0014\n",
            "2025-08-15 13:40:16.734695: val_loss 0.1163\n",
            "2025-08-15 13:40:16.735228: Pseudo dice [np.float32(0.8194), np.float32(0.4877)]\n",
            "2025-08-15 13:40:16.735394: Epoch time: 61.52 s\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 13:40:18.040846: \n",
            "2025-08-15 13:40:18.041366: Epoch 52\n",
            "2025-08-15 13:40:18.041480: Current learning rate: 0.00811\n",
            "2025-08-15 13:41:19.458877: train_loss -0.0005\n",
            "2025-08-15 13:41:19.459178: val_loss 0.0536\n",
            "2025-08-15 13:41:19.459733: Pseudo dice [np.float32(0.8316), np.float32(0.6305)]\n",
            "2025-08-15 13:41:19.459883: Epoch time: 61.42 s\n",
            "2025-08-15 13:41:19.459960: Yayy! New best EMA pseudo Dice: 0.6409000158309937\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 13:41:21.958859: \n",
            "2025-08-15 13:41:21.959358: Epoch 53\n",
            "2025-08-15 13:41:21.959480: Current learning rate: 0.00807\n",
            "2025-08-15 13:42:23.531670: train_loss 0.0111\n",
            "2025-08-15 13:42:23.532019: val_loss 0.0198\n",
            "2025-08-15 13:42:23.532383: Pseudo dice [np.float32(0.828), np.float32(0.6101)]\n",
            "2025-08-15 13:42:23.532482: Epoch time: 61.58 s\n",
            "2025-08-15 13:42:23.532553: Yayy! New best EMA pseudo Dice: 0.6486999988555908\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.5200\n",
            "(cls) epoch val acc: 0.520\n",
            "2025-08-15 13:42:26.078108: \n",
            "2025-08-15 13:42:26.078633: Epoch 54\n",
            "2025-08-15 13:42:26.078764: Current learning rate: 0.00803\n",
            "2025-08-15 13:43:27.605376: train_loss -0.0128\n",
            "2025-08-15 13:43:27.605782: val_loss 0.0581\n",
            "2025-08-15 13:43:27.606174: Pseudo dice [np.float32(0.8062), np.float32(0.6036)]\n",
            "2025-08-15 13:43:27.606270: Epoch time: 61.53 s\n",
            "2025-08-15 13:43:27.606339: Yayy! New best EMA pseudo Dice: 0.6542999744415283\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 13:43:30.176216: \n",
            "2025-08-15 13:43:30.176799: Epoch 55\n",
            "2025-08-15 13:43:30.176922: Current learning rate: 0.008\n",
            "2025-08-15 13:44:31.675096: train_loss 0.0005\n",
            "2025-08-15 13:44:31.675401: val_loss 0.1335\n",
            "2025-08-15 13:44:31.675737: Pseudo dice [np.float32(0.8057), np.float32(0.4625)]\n",
            "2025-08-15 13:44:31.675836: Epoch time: 61.5 s\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.5000\n",
            "(cls) epoch val acc: 0.500\n",
            "2025-08-15 13:44:32.983268: \n",
            "2025-08-15 13:44:32.983751: Epoch 56\n",
            "2025-08-15 13:44:32.983864: Current learning rate: 0.00796\n",
            "2025-08-15 13:45:34.463314: train_loss 0.0186\n",
            "2025-08-15 13:45:34.463615: val_loss 0.2224\n",
            "2025-08-15 13:45:34.464011: Pseudo dice [np.float32(0.8083), np.float32(0.4013)]\n",
            "2025-08-15 13:45:34.464126: Epoch time: 61.48 s\n",
            "Classification Train Acc: 0.3500\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 13:45:35.800298: \n",
            "2025-08-15 13:45:35.800888: Epoch 57\n",
            "2025-08-15 13:45:35.801069: Current learning rate: 0.00792\n",
            "2025-08-15 13:46:37.235755: train_loss -0.0053\n",
            "2025-08-15 13:46:37.236049: val_loss 0.1248\n",
            "2025-08-15 13:46:37.236467: Pseudo dice [np.float32(0.783), np.float32(0.4935)]\n",
            "2025-08-15 13:46:37.236564: Epoch time: 61.44 s\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.2400\n",
            "(cls) epoch val acc: 0.240\n",
            "2025-08-15 13:46:38.507361: \n",
            "2025-08-15 13:46:38.507823: Epoch 58\n",
            "2025-08-15 13:46:38.507936: Current learning rate: 0.00789\n",
            "2025-08-15 13:47:39.900790: train_loss -0.0193\n",
            "2025-08-15 13:47:39.901107: val_loss 0.0499\n",
            "2025-08-15 13:47:39.901431: Pseudo dice [np.float32(0.816), np.float32(0.5045)]\n",
            "2025-08-15 13:47:39.901530: Epoch time: 61.4 s\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.4100\n",
            "(cls) epoch val acc: 0.410\n",
            "2025-08-15 13:47:41.182643: \n",
            "2025-08-15 13:47:41.183133: Epoch 59\n",
            "2025-08-15 13:47:41.183247: Current learning rate: 0.00785\n",
            "2025-08-15 13:48:42.629803: train_loss -0.028\n",
            "2025-08-15 13:48:42.630112: val_loss 0.0864\n",
            "2025-08-15 13:48:42.630583: Pseudo dice [np.float32(0.8202), np.float32(0.5228)]\n",
            "2025-08-15 13:48:42.630770: Epoch time: 61.45 s\n",
            "Classification Train Acc: 0.2200\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 13:48:43.923557: \n",
            "2025-08-15 13:48:43.924087: Epoch 60\n",
            "2025-08-15 13:48:43.924203: Current learning rate: 0.00781\n",
            "2025-08-15 13:49:45.349374: train_loss -0.0389\n",
            "2025-08-15 13:49:45.349650: val_loss -0.001\n",
            "2025-08-15 13:49:45.349977: Pseudo dice [np.float32(0.8233), np.float32(0.6743)]\n",
            "2025-08-15 13:49:45.350111: Epoch time: 61.43 s\n",
            "2025-08-15 13:49:45.350185: Yayy! New best EMA pseudo Dice: 0.6601999998092651\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 13:49:47.876458: \n",
            "2025-08-15 13:49:47.877017: Epoch 61\n",
            "2025-08-15 13:49:47.877146: Current learning rate: 0.00777\n",
            "2025-08-15 13:50:49.272340: train_loss -0.0256\n",
            "2025-08-15 13:50:49.272710: val_loss 0.0657\n",
            "2025-08-15 13:50:49.273134: Pseudo dice [np.float32(0.8289), np.float32(0.5721)]\n",
            "2025-08-15 13:50:49.273253: Epoch time: 61.4 s\n",
            "2025-08-15 13:50:49.273352: Yayy! New best EMA pseudo Dice: 0.6642000079154968\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.2800\n",
            "(cls) epoch val acc: 0.280\n",
            "2025-08-15 13:50:51.778540: \n",
            "2025-08-15 13:50:51.778916: Epoch 62\n",
            "2025-08-15 13:50:51.779047: Current learning rate: 0.00774\n",
            "2025-08-15 13:51:53.242826: train_loss -0.016\n",
            "2025-08-15 13:51:53.243146: val_loss 0.1668\n",
            "2025-08-15 13:51:53.243579: Pseudo dice [np.float32(0.824), np.float32(0.4508)]\n",
            "2025-08-15 13:51:53.243677: Epoch time: 61.47 s\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.2200\n",
            "(cls) epoch val acc: 0.220\n",
            "2025-08-15 13:51:54.543026: \n",
            "2025-08-15 13:51:54.543504: Epoch 63\n",
            "2025-08-15 13:51:54.543622: Current learning rate: 0.0077\n",
            "2025-08-15 13:52:55.946884: train_loss -0.004\n",
            "2025-08-15 13:52:55.947269: val_loss 0.0613\n",
            "2025-08-15 13:52:55.947629: Pseudo dice [np.float32(0.8331), np.float32(0.6739)]\n",
            "2025-08-15 13:52:55.947738: Epoch time: 61.41 s\n",
            "2025-08-15 13:52:55.947843: Yayy! New best EMA pseudo Dice: 0.6707000136375427\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.4100\n",
            "(cls) epoch val acc: 0.410\n",
            "2025-08-15 13:52:58.433220: \n",
            "2025-08-15 13:52:58.433749: Epoch 64\n",
            "2025-08-15 13:52:58.433867: Current learning rate: 0.00766\n",
            "2025-08-15 13:53:59.912241: train_loss 0.0147\n",
            "2025-08-15 13:53:59.912558: val_loss 0.0032\n",
            "2025-08-15 13:53:59.912915: Pseudo dice [np.float32(0.8449), np.float32(0.6635)]\n",
            "2025-08-15 13:53:59.913027: Epoch time: 61.48 s\n",
            "2025-08-15 13:53:59.913101: Yayy! New best EMA pseudo Dice: 0.679099977016449\n",
            "Classification Train Acc: 0.2400\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 13:54:02.399614: \n",
            "2025-08-15 13:54:02.400141: Epoch 65\n",
            "2025-08-15 13:54:02.400278: Current learning rate: 0.00763\n",
            "2025-08-15 13:55:03.803838: train_loss -0.0216\n",
            "2025-08-15 13:55:03.804460: val_loss 0.0564\n",
            "2025-08-15 13:55:03.804711: Pseudo dice [np.float32(0.854), np.float32(0.5988)]\n",
            "2025-08-15 13:55:03.804813: Epoch time: 61.41 s\n",
            "2025-08-15 13:55:03.804889: Yayy! New best EMA pseudo Dice: 0.6837999820709229\n",
            "Classification Train Acc: 0.3300\n",
            "Classification Val Acc: 0.2300\n",
            "(cls) epoch val acc: 0.230\n",
            "2025-08-15 13:55:06.324788: \n",
            "2025-08-15 13:55:06.325248: Epoch 66\n",
            "2025-08-15 13:55:06.325361: Current learning rate: 0.00759\n",
            "2025-08-15 13:56:07.889513: train_loss -0.0004\n",
            "2025-08-15 13:56:07.889973: val_loss 0.1731\n",
            "2025-08-15 13:56:07.890417: Pseudo dice [np.float32(0.8206), np.float32(0.5124)]\n",
            "2025-08-15 13:56:07.890530: Epoch time: 61.57 s\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.3700\n",
            "(cls) epoch val acc: 0.370\n",
            "2025-08-15 13:56:09.237284: \n",
            "2025-08-15 13:56:09.237902: Epoch 67\n",
            "2025-08-15 13:56:09.238061: Current learning rate: 0.00755\n",
            "2025-08-15 13:57:10.796212: train_loss -0.0106\n",
            "2025-08-15 13:57:10.796540: val_loss 0.0793\n",
            "2025-08-15 13:57:10.797111: Pseudo dice [np.float32(0.8349), np.float32(0.4803)]\n",
            "2025-08-15 13:57:10.797279: Epoch time: 61.56 s\n",
            "Classification Train Acc: 0.2300\n",
            "Classification Val Acc: 0.3200\n",
            "(cls) epoch val acc: 0.320\n",
            "2025-08-15 13:57:12.130055: \n",
            "2025-08-15 13:57:12.130541: Epoch 68\n",
            "2025-08-15 13:57:12.130694: Current learning rate: 0.00751\n",
            "2025-08-15 13:58:13.677040: train_loss -0.0395\n",
            "2025-08-15 13:58:13.677371: val_loss 0.137\n",
            "2025-08-15 13:58:13.677867: Pseudo dice [np.float32(0.8361), np.float32(0.4541)]\n",
            "2025-08-15 13:58:13.677973: Epoch time: 61.55 s\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.1900\n",
            "(cls) epoch val acc: 0.190\n",
            "2025-08-15 13:58:15.011767: \n",
            "2025-08-15 13:58:15.012347: Epoch 69\n",
            "2025-08-15 13:58:15.012509: Current learning rate: 0.00748\n",
            "2025-08-15 13:59:16.609426: train_loss -0.028\n",
            "2025-08-15 13:59:16.609870: val_loss 0.0619\n",
            "2025-08-15 13:59:16.610324: Pseudo dice [np.float32(0.8378), np.float32(0.5609)]\n",
            "2025-08-15 13:59:16.610435: Epoch time: 61.6 s\n",
            "Classification Train Acc: 0.3500\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 13:59:17.958874: \n",
            "2025-08-15 13:59:17.959428: Epoch 70\n",
            "2025-08-15 13:59:17.959560: Current learning rate: 0.00744\n",
            "2025-08-15 14:00:19.514559: train_loss -0.0224\n",
            "2025-08-15 14:00:19.514941: val_loss 0.0623\n",
            "2025-08-15 14:00:19.515446: Pseudo dice [np.float32(0.8208), np.float32(0.586)]\n",
            "2025-08-15 14:00:19.515576: Epoch time: 61.56 s\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.5000\n",
            "(cls) epoch val acc: 0.500\n",
            "2025-08-15 14:00:20.833318: \n",
            "2025-08-15 14:00:20.833826: Epoch 71\n",
            "2025-08-15 14:00:20.833944: Current learning rate: 0.0074\n",
            "2025-08-15 14:01:22.340377: train_loss -0.0394\n",
            "2025-08-15 14:01:22.340813: val_loss -0.0134\n",
            "2025-08-15 14:01:22.341211: Pseudo dice [np.float32(0.8622), np.float32(0.7088)]\n",
            "2025-08-15 14:01:22.341308: Epoch time: 61.51 s\n",
            "2025-08-15 14:01:22.341421: Yayy! New best EMA pseudo Dice: 0.6913999915122986\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 14:01:24.999144: \n",
            "2025-08-15 14:01:24.999808: Epoch 72\n",
            "2025-08-15 14:01:24.999952: Current learning rate: 0.00737\n",
            "2025-08-15 14:02:26.593136: train_loss -0.031\n",
            "2025-08-15 14:02:26.593482: val_loss 0.1267\n",
            "2025-08-15 14:02:26.593947: Pseudo dice [np.float32(0.7902), np.float32(0.4523)]\n",
            "2025-08-15 14:02:26.594080: Epoch time: 61.6 s\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 14:02:27.924154: \n",
            "2025-08-15 14:02:27.924629: Epoch 73\n",
            "2025-08-15 14:02:27.924744: Current learning rate: 0.00733\n",
            "2025-08-15 14:03:29.472551: train_loss -0.0317\n",
            "2025-08-15 14:03:29.472915: val_loss 0.1053\n",
            "2025-08-15 14:03:29.473330: Pseudo dice [np.float32(0.8061), np.float32(0.5827)]\n",
            "2025-08-15 14:03:29.473468: Epoch time: 61.55 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 14:03:30.785735: \n",
            "2025-08-15 14:03:30.786279: Epoch 74\n",
            "2025-08-15 14:03:30.786418: Current learning rate: 0.00729\n",
            "2025-08-15 14:04:32.281453: train_loss -0.0459\n",
            "2025-08-15 14:04:32.281873: val_loss 0.0278\n",
            "2025-08-15 14:04:32.282351: Pseudo dice [np.float32(0.8445), np.float32(0.5554)]\n",
            "2025-08-15 14:04:32.282489: Epoch time: 61.5 s\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.2700\n",
            "(cls) epoch val acc: 0.270\n",
            "2025-08-15 14:04:33.618057: \n",
            "2025-08-15 14:04:33.618600: Epoch 75\n",
            "2025-08-15 14:04:33.618736: Current learning rate: 0.00725\n",
            "2025-08-15 14:05:35.163934: train_loss -0.0376\n",
            "2025-08-15 14:05:35.164366: val_loss -0.0235\n",
            "2025-08-15 14:05:35.164838: Pseudo dice [np.float32(0.8451), np.float32(0.7076)]\n",
            "2025-08-15 14:05:35.164939: Epoch time: 61.55 s\n",
            "2025-08-15 14:05:35.165040: Yayy! New best EMA pseudo Dice: 0.6958000063896179\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.5000\n",
            "(cls) epoch val acc: 0.500\n",
            "2025-08-15 14:05:37.811759: \n",
            "2025-08-15 14:05:37.812391: Epoch 76\n",
            "2025-08-15 14:05:37.812519: Current learning rate: 0.00722\n",
            "2025-08-15 14:06:39.390215: train_loss -0.0206\n",
            "2025-08-15 14:06:39.390625: val_loss 0.0998\n",
            "2025-08-15 14:06:39.391133: Pseudo dice [np.float32(0.8232), np.float32(0.5637)]\n",
            "2025-08-15 14:06:39.391244: Epoch time: 61.58 s\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 14:06:40.762614: \n",
            "2025-08-15 14:06:40.763320: Epoch 77\n",
            "2025-08-15 14:06:40.763505: Current learning rate: 0.00718\n",
            "2025-08-15 14:07:42.369542: train_loss -0.0668\n",
            "2025-08-15 14:07:42.369861: val_loss -0.005\n",
            "2025-08-15 14:07:42.370241: Pseudo dice [np.float32(0.843), np.float32(0.6407)]\n",
            "2025-08-15 14:07:42.370333: Epoch time: 61.61 s\n",
            "2025-08-15 14:07:42.370440: Yayy! New best EMA pseudo Dice: 0.7002000212669373\n",
            "Classification Train Acc: 0.4700\n",
            "Classification Val Acc: 0.4800\n",
            "(cls) epoch val acc: 0.480\n",
            "2025-08-15 14:07:45.063978: \n",
            "2025-08-15 14:07:45.064547: Epoch 78\n",
            "2025-08-15 14:07:45.064673: Current learning rate: 0.00714\n",
            "2025-08-15 14:08:46.676804: train_loss -0.0577\n",
            "2025-08-15 14:08:46.677174: val_loss -0.034\n",
            "2025-08-15 14:08:46.677603: Pseudo dice [np.float32(0.8523), np.float32(0.6803)]\n",
            "2025-08-15 14:08:46.677726: Epoch time: 61.62 s\n",
            "2025-08-15 14:08:46.677804: Yayy! New best EMA pseudo Dice: 0.7067999839782715\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.5300\n",
            "(cls) epoch val acc: 0.530\n",
            "2025-08-15 14:08:49.276208: \n",
            "2025-08-15 14:08:49.276743: Epoch 79\n",
            "2025-08-15 14:08:49.276861: Current learning rate: 0.0071\n",
            "2025-08-15 14:09:50.861480: train_loss -0.0541\n",
            "2025-08-15 14:09:50.861888: val_loss 0.0295\n",
            "2025-08-15 14:09:50.862321: Pseudo dice [np.float32(0.8326), np.float32(0.6074)]\n",
            "2025-08-15 14:09:50.862428: Epoch time: 61.59 s\n",
            "2025-08-15 14:09:50.862521: Yayy! New best EMA pseudo Dice: 0.7081000208854675\n",
            "Classification Train Acc: 0.4300\n",
            "Classification Val Acc: 0.5100\n",
            "(cls) epoch val acc: 0.510\n",
            "2025-08-15 14:09:53.496478: \n",
            "2025-08-15 14:09:53.496969: Epoch 80\n",
            "2025-08-15 14:09:53.497097: Current learning rate: 0.00707\n",
            "2025-08-15 14:10:55.091043: train_loss -0.0559\n",
            "2025-08-15 14:10:55.091415: val_loss 0.0906\n",
            "2025-08-15 14:10:55.091793: Pseudo dice [np.float32(0.8389), np.float32(0.5046)]\n",
            "2025-08-15 14:10:55.091885: Epoch time: 61.6 s\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 14:10:56.433503: \n",
            "2025-08-15 14:10:56.434030: Epoch 81\n",
            "2025-08-15 14:10:56.434156: Current learning rate: 0.00703\n",
            "2025-08-15 14:11:57.930327: train_loss -0.0451\n",
            "2025-08-15 14:11:57.930674: val_loss 0.1286\n",
            "2025-08-15 14:11:57.931156: Pseudo dice [np.float32(0.8385), np.float32(0.5372)]\n",
            "2025-08-15 14:11:57.931388: Epoch time: 61.5 s\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 14:11:59.369154: \n",
            "2025-08-15 14:11:59.369717: Epoch 82\n",
            "2025-08-15 14:11:59.369838: Current learning rate: 0.00699\n",
            "2025-08-15 14:13:00.820160: train_loss -0.0474\n",
            "2025-08-15 14:13:00.820523: val_loss 0.1156\n",
            "2025-08-15 14:13:00.820976: Pseudo dice [np.float32(0.8109), np.float32(0.4789)]\n",
            "2025-08-15 14:13:00.821105: Epoch time: 61.45 s\n",
            "Classification Train Acc: 0.4900\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 14:13:02.167902: \n",
            "2025-08-15 14:13:02.168548: Epoch 83\n",
            "2025-08-15 14:13:02.168676: Current learning rate: 0.00696\n",
            "2025-08-15 14:14:03.636371: train_loss -0.0478\n",
            "2025-08-15 14:14:03.636698: val_loss 0.0121\n",
            "2025-08-15 14:14:03.637160: Pseudo dice [np.float32(0.855), np.float32(0.6332)]\n",
            "2025-08-15 14:14:03.637278: Epoch time: 61.47 s\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 14:14:04.959271: \n",
            "2025-08-15 14:14:04.959830: Epoch 84\n",
            "2025-08-15 14:14:04.959951: Current learning rate: 0.00692\n",
            "2025-08-15 14:15:06.472848: train_loss -0.0532\n",
            "2025-08-15 14:15:06.473181: val_loss 0.109\n",
            "2025-08-15 14:15:06.473597: Pseudo dice [np.float32(0.8336), np.float32(0.5727)]\n",
            "2025-08-15 14:15:06.473693: Epoch time: 61.52 s\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 14:15:07.801306: \n",
            "2025-08-15 14:15:07.801699: Epoch 85\n",
            "2025-08-15 14:15:07.801867: Current learning rate: 0.00688\n",
            "2025-08-15 14:16:09.319321: train_loss -0.0449\n",
            "2025-08-15 14:16:09.319662: val_loss 0.0357\n",
            "2025-08-15 14:16:09.320017: Pseudo dice [np.float32(0.857), np.float32(0.6035)]\n",
            "2025-08-15 14:16:09.320118: Epoch time: 61.52 s\n",
            "Classification Train Acc: 0.2700\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 14:16:16.557973: \n",
            "2025-08-15 14:16:16.558542: Epoch 86\n",
            "2025-08-15 14:16:16.558755: Current learning rate: 0.00684\n",
            "2025-08-15 14:17:18.391237: train_loss -0.0659\n",
            "2025-08-15 14:17:18.391588: val_loss 0.0432\n",
            "2025-08-15 14:17:18.392096: Pseudo dice [np.float32(0.8666), np.float32(0.554)]\n",
            "2025-08-15 14:17:18.392236: Epoch time: 61.84 s\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.2700\n",
            "(cls) epoch val acc: 0.270\n",
            "2025-08-15 14:17:19.717925: \n",
            "2025-08-15 14:17:19.718525: Epoch 87\n",
            "2025-08-15 14:17:19.718671: Current learning rate: 0.0068\n",
            "2025-08-15 14:18:21.503062: train_loss -0.0616\n",
            "2025-08-15 14:18:21.503445: val_loss 0.038\n",
            "2025-08-15 14:18:21.503817: Pseudo dice [np.float32(0.8532), np.float32(0.6241)]\n",
            "2025-08-15 14:18:21.503941: Epoch time: 61.79 s\n",
            "2025-08-15 14:18:21.504043: Yayy! New best EMA pseudo Dice: 0.7085999846458435\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.4100\n",
            "(cls) epoch val acc: 0.410\n",
            "2025-08-15 14:18:24.023542: \n",
            "2025-08-15 14:18:24.024175: Epoch 88\n",
            "2025-08-15 14:18:24.024292: Current learning rate: 0.00677\n",
            "2025-08-15 14:19:25.761914: train_loss -0.0871\n",
            "2025-08-15 14:19:25.762276: val_loss 0.0388\n",
            "2025-08-15 14:19:25.762702: Pseudo dice [np.float32(0.8716), np.float32(0.5759)]\n",
            "2025-08-15 14:19:25.762812: Epoch time: 61.74 s\n",
            "2025-08-15 14:19:25.762884: Yayy! New best EMA pseudo Dice: 0.710099995136261\n",
            "Classification Train Acc: 0.2500\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 14:19:28.260522: \n",
            "2025-08-15 14:19:28.261058: Epoch 89\n",
            "2025-08-15 14:19:28.261173: Current learning rate: 0.00673\n",
            "2025-08-15 14:20:29.970798: train_loss -0.0678\n",
            "2025-08-15 14:20:29.971112: val_loss -0.0098\n",
            "2025-08-15 14:20:29.971602: Pseudo dice [np.float32(0.852), np.float32(0.6959)]\n",
            "2025-08-15 14:20:29.971767: Epoch time: 61.71 s\n",
            "2025-08-15 14:20:29.971853: Yayy! New best EMA pseudo Dice: 0.7164999842643738\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.2800\n",
            "(cls) epoch val acc: 0.280\n",
            "2025-08-15 14:20:32.481011: \n",
            "2025-08-15 14:20:32.481613: Epoch 90\n",
            "2025-08-15 14:20:32.481741: Current learning rate: 0.00669\n",
            "2025-08-15 14:21:34.312603: train_loss -0.0761\n",
            "2025-08-15 14:21:34.312969: val_loss 0.037\n",
            "2025-08-15 14:21:34.313464: Pseudo dice [np.float32(0.8614), np.float32(0.5815)]\n",
            "2025-08-15 14:21:34.313575: Epoch time: 61.84 s\n",
            "2025-08-15 14:21:34.313650: Yayy! New best EMA pseudo Dice: 0.7170000076293945\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 14:21:36.848094: \n",
            "2025-08-15 14:21:36.848716: Epoch 91\n",
            "2025-08-15 14:21:36.848862: Current learning rate: 0.00665\n",
            "2025-08-15 14:22:38.716778: train_loss -0.0731\n",
            "2025-08-15 14:22:38.717136: val_loss -0.0103\n",
            "2025-08-15 14:22:38.717496: Pseudo dice [np.float32(0.8622), np.float32(0.7336)]\n",
            "2025-08-15 14:22:38.717608: Epoch time: 61.87 s\n",
            "2025-08-15 14:22:38.717683: Yayy! New best EMA pseudo Dice: 0.7250999808311462\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 14:22:41.219286: \n",
            "2025-08-15 14:22:41.219938: Epoch 92\n",
            "2025-08-15 14:22:41.220082: Current learning rate: 0.00662\n",
            "2025-08-15 14:23:43.098968: train_loss -0.0794\n",
            "2025-08-15 14:23:43.099443: val_loss 0.0777\n",
            "2025-08-15 14:23:43.099861: Pseudo dice [np.float32(0.8491), np.float32(0.4841)]\n",
            "2025-08-15 14:23:43.100014: Epoch time: 61.88 s\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.2900\n",
            "(cls) epoch val acc: 0.290\n",
            "2025-08-15 14:23:44.418056: \n",
            "2025-08-15 14:23:44.418388: Epoch 93\n",
            "2025-08-15 14:23:44.418505: Current learning rate: 0.00658\n",
            "2025-08-15 14:24:46.151760: train_loss -0.0597\n",
            "2025-08-15 14:24:46.152069: val_loss 0.0175\n",
            "2025-08-15 14:24:46.152465: Pseudo dice [np.float32(0.8361), np.float32(0.5863)]\n",
            "2025-08-15 14:24:46.152750: Epoch time: 61.74 s\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.5200\n",
            "(cls) epoch val acc: 0.520\n",
            "2025-08-15 14:24:47.473748: \n",
            "2025-08-15 14:24:47.474092: Epoch 94\n",
            "2025-08-15 14:24:47.474206: Current learning rate: 0.00654\n",
            "2025-08-15 14:25:49.258753: train_loss -0.0712\n",
            "2025-08-15 14:25:49.259159: val_loss 0.0174\n",
            "2025-08-15 14:25:49.259598: Pseudo dice [np.float32(0.864), np.float32(0.7119)]\n",
            "2025-08-15 14:25:49.259704: Epoch time: 61.79 s\n",
            "2025-08-15 14:25:49.259794: Yayy! New best EMA pseudo Dice: 0.7253999710083008\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.2900\n",
            "(cls) epoch val acc: 0.290\n",
            "2025-08-15 14:25:51.764441: \n",
            "2025-08-15 14:25:51.765021: Epoch 95\n",
            "2025-08-15 14:25:51.765172: Current learning rate: 0.0065\n",
            "2025-08-15 14:26:53.559917: train_loss -0.0875\n",
            "2025-08-15 14:26:53.560359: val_loss 0.0325\n",
            "2025-08-15 14:26:53.560795: Pseudo dice [np.float32(0.8605), np.float32(0.619)]\n",
            "2025-08-15 14:26:53.560898: Epoch time: 61.8 s\n",
            "2025-08-15 14:26:53.560968: Yayy! New best EMA pseudo Dice: 0.7268000245094299\n",
            "Classification Train Acc: 0.2400\n",
            "Classification Val Acc: 0.2500\n",
            "(cls) epoch val acc: 0.250\n",
            "2025-08-15 14:26:56.131897: \n",
            "2025-08-15 14:26:56.132508: Epoch 96\n",
            "2025-08-15 14:26:56.132639: Current learning rate: 0.00647\n",
            "2025-08-15 14:27:57.896091: train_loss -0.0858\n",
            "2025-08-15 14:27:57.896482: val_loss 0.0198\n",
            "2025-08-15 14:27:57.896824: Pseudo dice [np.float32(0.8658), np.float32(0.601)]\n",
            "2025-08-15 14:27:57.896919: Epoch time: 61.77 s\n",
            "2025-08-15 14:27:57.897006: Yayy! New best EMA pseudo Dice: 0.7275000214576721\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 14:28:00.429542: \n",
            "2025-08-15 14:28:00.430141: Epoch 97\n",
            "2025-08-15 14:28:00.430262: Current learning rate: 0.00643\n",
            "2025-08-15 14:29:02.230909: train_loss -0.0907\n",
            "2025-08-15 14:29:02.231239: val_loss -0.0341\n",
            "2025-08-15 14:29:02.231875: Pseudo dice [np.float32(0.8718), np.float32(0.6716)]\n",
            "2025-08-15 14:29:02.232003: Epoch time: 61.8 s\n",
            "2025-08-15 14:29:02.232084: Yayy! New best EMA pseudo Dice: 0.7318999767303467\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4500\n",
            "(cls) epoch val acc: 0.450\n",
            "2025-08-15 14:29:04.843260: \n",
            "2025-08-15 14:29:04.844018: Epoch 98\n",
            "2025-08-15 14:29:04.844165: Current learning rate: 0.00639\n",
            "2025-08-15 14:30:06.683286: train_loss -0.1042\n",
            "2025-08-15 14:30:06.683645: val_loss 0.1782\n",
            "2025-08-15 14:30:06.684062: Pseudo dice [np.float32(0.8426), np.float32(0.4791)]\n",
            "2025-08-15 14:30:06.684175: Epoch time: 61.84 s\n",
            "Classification Train Acc: 0.4400\n",
            "Classification Val Acc: 0.3000\n",
            "(cls) epoch val acc: 0.300\n",
            "2025-08-15 14:30:08.018049: \n",
            "2025-08-15 14:30:08.018652: Epoch 99\n",
            "2025-08-15 14:30:08.018790: Current learning rate: 0.00635\n",
            "2025-08-15 14:31:09.844618: train_loss -0.076\n",
            "2025-08-15 14:31:09.845127: val_loss 0.1188\n",
            "2025-08-15 14:31:09.845482: Pseudo dice [np.float32(0.8378), np.float32(0.4782)]\n",
            "2025-08-15 14:31:09.845577: Epoch time: 61.83 s\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 14:31:12.387693: \n",
            "2025-08-15 14:31:12.388263: Epoch 100\n",
            "2025-08-15 14:31:12.388383: Current learning rate: 0.00631\n",
            "2025-08-15 14:32:14.225269: train_loss -0.0794\n",
            "2025-08-15 14:32:14.225615: val_loss 0.0342\n",
            "2025-08-15 14:32:14.226064: Pseudo dice [np.float32(0.866), np.float32(0.5337)]\n",
            "2025-08-15 14:32:14.226202: Epoch time: 61.84 s\n",
            "Classification Train Acc: 0.3500\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 14:32:15.548112: \n",
            "2025-08-15 14:32:15.548717: Epoch 101\n",
            "2025-08-15 14:32:15.548844: Current learning rate: 0.00628\n",
            "2025-08-15 14:33:17.326456: train_loss -0.0826\n",
            "2025-08-15 14:33:17.326842: val_loss 0.1231\n",
            "2025-08-15 14:33:17.327277: Pseudo dice [np.float32(0.8137), np.float32(0.4668)]\n",
            "2025-08-15 14:33:17.327383: Epoch time: 61.78 s\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.5000\n",
            "(cls) epoch val acc: 0.500\n",
            "2025-08-15 14:33:18.661543: \n",
            "2025-08-15 14:33:18.662209: Epoch 102\n",
            "2025-08-15 14:33:18.662333: Current learning rate: 0.00624\n",
            "2025-08-15 14:34:20.430211: train_loss -0.0955\n",
            "2025-08-15 14:34:20.430712: val_loss 0.0576\n",
            "2025-08-15 14:34:20.431120: Pseudo dice [np.float32(0.8581), np.float32(0.5531)]\n",
            "2025-08-15 14:34:20.431216: Epoch time: 61.77 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3600\n",
            "(cls) epoch val acc: 0.360\n",
            "2025-08-15 14:34:21.766944: \n",
            "2025-08-15 14:34:21.767547: Epoch 103\n",
            "2025-08-15 14:34:21.767671: Current learning rate: 0.0062\n",
            "2025-08-15 14:35:23.506782: train_loss -0.1009\n",
            "2025-08-15 14:35:23.507145: val_loss 0.1489\n",
            "2025-08-15 14:35:23.507613: Pseudo dice [np.float32(0.8275), np.float32(0.4338)]\n",
            "2025-08-15 14:35:23.507725: Epoch time: 61.74 s\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 14:35:24.808301: \n",
            "2025-08-15 14:35:24.808865: Epoch 104\n",
            "2025-08-15 14:35:24.808997: Current learning rate: 0.00616\n",
            "2025-08-15 14:36:26.535245: train_loss -0.1001\n",
            "2025-08-15 14:36:26.535562: val_loss 0.0327\n",
            "2025-08-15 14:36:26.536005: Pseudo dice [np.float32(0.8705), np.float32(0.5846)]\n",
            "2025-08-15 14:36:26.536165: Epoch time: 61.73 s\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 14:36:27.865814: \n",
            "2025-08-15 14:36:27.866382: Epoch 105\n",
            "2025-08-15 14:36:27.866507: Current learning rate: 0.00612\n",
            "2025-08-15 14:37:29.691212: train_loss -0.1\n",
            "2025-08-15 14:37:29.691537: val_loss 0.0417\n",
            "2025-08-15 14:37:29.691918: Pseudo dice [np.float32(0.8542), np.float32(0.6093)]\n",
            "2025-08-15 14:37:29.692066: Epoch time: 61.83 s\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.3700\n",
            "(cls) epoch val acc: 0.370\n",
            "2025-08-15 14:37:31.034311: \n",
            "2025-08-15 14:37:31.034918: Epoch 106\n",
            "2025-08-15 14:37:31.035058: Current learning rate: 0.00609\n",
            "2025-08-15 14:38:32.727878: train_loss -0.0968\n",
            "2025-08-15 14:38:32.728251: val_loss 0.1251\n",
            "2025-08-15 14:38:32.728688: Pseudo dice [np.float32(0.8501), np.float32(0.506)]\n",
            "2025-08-15 14:38:32.728791: Epoch time: 61.7 s\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 14:38:34.063520: \n",
            "2025-08-15 14:38:34.064043: Epoch 107\n",
            "2025-08-15 14:38:34.064155: Current learning rate: 0.00605\n",
            "2025-08-15 14:39:35.689133: train_loss -0.0866\n",
            "2025-08-15 14:39:35.689490: val_loss 0.0767\n",
            "2025-08-15 14:39:35.689905: Pseudo dice [np.float32(0.8373), np.float32(0.6168)]\n",
            "2025-08-15 14:39:35.690100: Epoch time: 61.63 s\n",
            "Classification Train Acc: 0.2700\n",
            "Classification Val Acc: 0.2900\n",
            "(cls) epoch val acc: 0.290\n",
            "2025-08-15 14:39:37.063844: \n",
            "2025-08-15 14:39:37.064413: Epoch 108\n",
            "2025-08-15 14:39:37.064535: Current learning rate: 0.00601\n",
            "2025-08-15 14:40:38.847042: train_loss -0.0718\n",
            "2025-08-15 14:40:38.847316: val_loss 0.0101\n",
            "2025-08-15 14:40:38.847822: Pseudo dice [np.float32(0.8557), np.float32(0.639)]\n",
            "2025-08-15 14:40:38.847928: Epoch time: 61.79 s\n",
            "Classification Train Acc: 0.2900\n",
            "Classification Val Acc: 0.3500\n",
            "(cls) epoch val acc: 0.350\n",
            "2025-08-15 14:40:40.155169: \n",
            "2025-08-15 14:40:40.155779: Epoch 109\n",
            "2025-08-15 14:40:40.155927: Current learning rate: 0.00597\n",
            "2025-08-15 14:41:41.845936: train_loss -0.0825\n",
            "2025-08-15 14:41:41.846308: val_loss 0.0589\n",
            "2025-08-15 14:41:41.846876: Pseudo dice [np.float32(0.8586), np.float32(0.6065)]\n",
            "2025-08-15 14:41:41.847016: Epoch time: 61.69 s\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 14:41:43.175756: \n",
            "2025-08-15 14:41:43.176359: Epoch 110\n",
            "2025-08-15 14:41:43.176481: Current learning rate: 0.00593\n",
            "2025-08-15 14:42:44.793496: train_loss -0.114\n",
            "2025-08-15 14:42:44.794049: val_loss 0.0713\n",
            "2025-08-15 14:42:44.794409: Pseudo dice [np.float32(0.8738), np.float32(0.5287)]\n",
            "2025-08-15 14:42:44.794512: Epoch time: 61.62 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3100\n",
            "(cls) epoch val acc: 0.310\n",
            "2025-08-15 14:42:46.142449: \n",
            "2025-08-15 14:42:46.143088: Epoch 111\n",
            "2025-08-15 14:42:46.143286: Current learning rate: 0.0059\n",
            "2025-08-15 14:43:47.768070: train_loss -0.129\n",
            "2025-08-15 14:43:47.768420: val_loss 0.0167\n",
            "2025-08-15 14:43:47.768794: Pseudo dice [np.float32(0.8615), np.float32(0.6796)]\n",
            "2025-08-15 14:43:47.768942: Epoch time: 61.63 s\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 14:43:49.083274: \n",
            "2025-08-15 14:43:49.083819: Epoch 112\n",
            "2025-08-15 14:43:49.083940: Current learning rate: 0.00586\n",
            "2025-08-15 14:44:50.827763: train_loss -0.1045\n",
            "2025-08-15 14:44:50.828102: val_loss 0.095\n",
            "2025-08-15 14:44:50.828460: Pseudo dice [np.float32(0.8462), np.float32(0.6363)]\n",
            "2025-08-15 14:44:50.828570: Epoch time: 61.75 s\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.4300\n",
            "(cls) epoch val acc: 0.430\n",
            "2025-08-15 14:44:52.129176: \n",
            "2025-08-15 14:44:52.129687: Epoch 113\n",
            "2025-08-15 14:44:52.129805: Current learning rate: 0.00582\n",
            "2025-08-15 14:45:53.794198: train_loss -0.0837\n",
            "2025-08-15 14:45:53.794481: val_loss 0.0849\n",
            "2025-08-15 14:45:53.794931: Pseudo dice [np.float32(0.8603), np.float32(0.5246)]\n",
            "2025-08-15 14:45:53.795091: Epoch time: 61.67 s\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.2400\n",
            "(cls) epoch val acc: 0.240\n",
            "2025-08-15 14:45:55.121758: \n",
            "2025-08-15 14:45:55.122314: Epoch 114\n",
            "2025-08-15 14:45:55.122493: Current learning rate: 0.00578\n",
            "2025-08-15 14:46:56.875280: train_loss -0.0976\n",
            "2025-08-15 14:46:56.875841: val_loss 0.0083\n",
            "2025-08-15 14:46:56.876275: Pseudo dice [np.float32(0.8538), np.float32(0.613)]\n",
            "2025-08-15 14:46:56.876373: Epoch time: 61.76 s\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.4800\n",
            "(cls) epoch val acc: 0.480\n",
            "2025-08-15 14:46:58.232073: \n",
            "2025-08-15 14:46:58.232618: Epoch 115\n",
            "2025-08-15 14:46:58.232737: Current learning rate: 0.00574\n",
            "2025-08-15 14:47:59.886487: train_loss -0.104\n",
            "2025-08-15 14:47:59.886801: val_loss 0.0313\n",
            "2025-08-15 14:47:59.887170: Pseudo dice [np.float32(0.8642), np.float32(0.6001)]\n",
            "2025-08-15 14:47:59.887269: Epoch time: 61.66 s\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 14:48:01.244107: \n",
            "2025-08-15 14:48:01.244398: Epoch 116\n",
            "2025-08-15 14:48:01.244510: Current learning rate: 0.0057\n",
            "2025-08-15 14:49:02.909506: train_loss -0.1029\n",
            "2025-08-15 14:49:02.909828: val_loss 0.0246\n",
            "2025-08-15 14:49:02.910205: Pseudo dice [np.float32(0.8636), np.float32(0.5799)]\n",
            "2025-08-15 14:49:02.910326: Epoch time: 61.67 s\n",
            "Classification Train Acc: 0.2900\n",
            "Classification Val Acc: 0.3000\n",
            "(cls) epoch val acc: 0.300\n",
            "2025-08-15 14:49:04.273335: \n",
            "2025-08-15 14:49:04.273896: Epoch 117\n",
            "2025-08-15 14:49:04.274090: Current learning rate: 0.00567\n",
            "2025-08-15 14:50:05.839219: train_loss -0.1299\n",
            "2025-08-15 14:50:05.839509: val_loss 0.0892\n",
            "2025-08-15 14:50:05.839933: Pseudo dice [np.float32(0.8493), np.float32(0.5084)]\n",
            "2025-08-15 14:50:05.840047: Epoch time: 61.57 s\n",
            "Classification Train Acc: 0.3400\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 14:50:07.165407: \n",
            "2025-08-15 14:50:07.165933: Epoch 118\n",
            "2025-08-15 14:50:07.166073: Current learning rate: 0.00563\n",
            "2025-08-15 14:51:08.731049: train_loss -0.1029\n",
            "2025-08-15 14:51:08.731367: val_loss 0.0747\n",
            "2025-08-15 14:51:08.731967: Pseudo dice [np.float32(0.8485), np.float32(0.6019)]\n",
            "2025-08-15 14:51:08.732128: Epoch time: 61.57 s\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 14:51:10.053694: \n",
            "2025-08-15 14:51:10.054267: Epoch 119\n",
            "2025-08-15 14:51:10.054393: Current learning rate: 0.00559\n",
            "2025-08-15 14:52:11.676408: train_loss -0.1202\n",
            "2025-08-15 14:52:11.676721: val_loss 0.0382\n",
            "2025-08-15 14:52:11.677070: Pseudo dice [np.float32(0.8633), np.float32(0.5487)]\n",
            "2025-08-15 14:52:11.677166: Epoch time: 61.63 s\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.2100\n",
            "(cls) epoch val acc: 0.210\n",
            "2025-08-15 14:52:12.983455: \n",
            "2025-08-15 14:52:12.984026: Epoch 120\n",
            "2025-08-15 14:52:12.984143: Current learning rate: 0.00555\n",
            "2025-08-15 14:53:14.671779: train_loss -0.1064\n",
            "2025-08-15 14:53:14.672065: val_loss 0.0148\n",
            "2025-08-15 14:53:14.672397: Pseudo dice [np.float32(0.8659), np.float32(0.6414)]\n",
            "2025-08-15 14:53:14.672499: Epoch time: 61.69 s\n",
            "Classification Train Acc: 0.3200\n",
            "Classification Val Acc: 0.4900\n",
            "(cls) epoch val acc: 0.490\n",
            "2025-08-15 14:53:15.997948: \n",
            "2025-08-15 14:53:15.998435: Epoch 121\n",
            "2025-08-15 14:53:15.998576: Current learning rate: 0.00551\n",
            "2025-08-15 14:54:17.584739: train_loss -0.1217\n",
            "2025-08-15 14:54:17.585092: val_loss 0.1049\n",
            "2025-08-15 14:54:17.585432: Pseudo dice [np.float32(0.8681), np.float32(0.5777)]\n",
            "2025-08-15 14:54:17.585543: Epoch time: 61.59 s\n",
            "Classification Train Acc: 0.3700\n",
            "Classification Val Acc: 0.2400\n",
            "(cls) epoch val acc: 0.240\n",
            "2025-08-15 14:54:18.897735: \n",
            "2025-08-15 14:54:18.898312: Epoch 122\n",
            "2025-08-15 14:54:18.898428: Current learning rate: 0.00547\n",
            "2025-08-15 14:55:20.601850: train_loss -0.1152\n",
            "2025-08-15 14:55:20.602196: val_loss 0.0621\n",
            "2025-08-15 14:55:20.602641: Pseudo dice [np.float32(0.8509), np.float32(0.6178)]\n",
            "2025-08-15 14:55:20.602745: Epoch time: 61.71 s\n",
            "Classification Train Acc: 0.3500\n",
            "Classification Val Acc: 0.3200\n",
            "(cls) epoch val acc: 0.320\n",
            "2025-08-15 14:55:21.940077: \n",
            "2025-08-15 14:55:21.940604: Epoch 123\n",
            "2025-08-15 14:55:21.940736: Current learning rate: 0.00544\n",
            "2025-08-15 14:56:23.632722: train_loss -0.1007\n",
            "2025-08-15 14:56:23.633183: val_loss 0.0102\n",
            "2025-08-15 14:56:23.633555: Pseudo dice [np.float32(0.8647), np.float32(0.6824)]\n",
            "2025-08-15 14:56:23.633659: Epoch time: 61.7 s\n",
            "Classification Train Acc: 0.3000\n",
            "Classification Val Acc: 0.3900\n",
            "(cls) epoch val acc: 0.390\n",
            "2025-08-15 14:56:24.943350: \n",
            "2025-08-15 14:56:24.943855: Epoch 124\n",
            "2025-08-15 14:56:24.944038: Current learning rate: 0.0054\n",
            "2025-08-15 14:57:26.574414: train_loss -0.1121\n",
            "2025-08-15 14:57:26.574728: val_loss -0.0025\n",
            "2025-08-15 14:57:26.575081: Pseudo dice [np.float32(0.8575), np.float32(0.6962)]\n",
            "2025-08-15 14:57:26.575172: Epoch time: 61.63 s\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.4100\n",
            "(cls) epoch val acc: 0.410\n",
            "2025-08-15 14:57:27.913975: \n",
            "2025-08-15 14:57:27.914533: Epoch 125\n",
            "2025-08-15 14:57:27.914649: Current learning rate: 0.00536\n",
            "2025-08-15 14:58:29.481388: train_loss -0.1371\n",
            "2025-08-15 14:58:29.481683: val_loss 0.1619\n",
            "2025-08-15 14:58:29.482282: Pseudo dice [np.float32(0.8484), np.float32(0.4533)]\n",
            "2025-08-15 14:58:29.482388: Epoch time: 61.57 s\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.3400\n",
            "(cls) epoch val acc: 0.340\n",
            "2025-08-15 14:58:30.814343: \n",
            "2025-08-15 14:58:30.814847: Epoch 126\n",
            "2025-08-15 14:58:30.815108: Current learning rate: 0.00532\n",
            "2025-08-15 14:59:32.279694: train_loss -0.081\n",
            "2025-08-15 14:59:32.280061: val_loss 0.0731\n",
            "2025-08-15 14:59:32.280677: Pseudo dice [np.float32(0.8534), np.float32(0.5292)]\n",
            "2025-08-15 14:59:32.280793: Epoch time: 61.47 s\n",
            "Classification Train Acc: 0.3100\n",
            "Classification Val Acc: 0.2600\n",
            "(cls) epoch val acc: 0.260\n",
            "2025-08-15 14:59:33.625939: \n",
            "2025-08-15 14:59:33.626420: Epoch 127\n",
            "2025-08-15 14:59:33.626535: Current learning rate: 0.00528\n",
            "2025-08-15 15:00:35.376275: train_loss -0.1274\n",
            "2025-08-15 15:00:35.376584: val_loss 0.1047\n",
            "2025-08-15 15:00:35.376969: Pseudo dice [np.float32(0.8524), np.float32(0.5363)]\n",
            "2025-08-15 15:00:35.377088: Epoch time: 61.75 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.3800\n",
            "(cls) epoch val acc: 0.380\n",
            "2025-08-15 15:00:36.713738: \n",
            "2025-08-15 15:00:36.714289: Epoch 128\n",
            "2025-08-15 15:00:36.714453: Current learning rate: 0.00524\n",
            "2025-08-15 15:01:38.387226: train_loss -0.1239\n",
            "2025-08-15 15:01:38.387856: val_loss 0.0478\n",
            "2025-08-15 15:01:38.388304: Pseudo dice [np.float32(0.876), np.float32(0.5762)]\n",
            "2025-08-15 15:01:38.388396: Epoch time: 61.68 s\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.4200\n",
            "(cls) epoch val acc: 0.420\n",
            "2025-08-15 15:01:39.702833: \n",
            "2025-08-15 15:01:39.703442: Epoch 129\n",
            "2025-08-15 15:01:39.703579: Current learning rate: 0.0052\n",
            "2025-08-15 15:02:41.418088: train_loss -0.1165\n",
            "2025-08-15 15:02:41.418591: val_loss -0.0273\n",
            "2025-08-15 15:02:41.418957: Pseudo dice [np.float32(0.8779), np.float32(0.6827)]\n",
            "2025-08-15 15:02:41.419092: Epoch time: 61.72 s\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.2500\n",
            "(cls) epoch val acc: 0.250\n",
            "2025-08-15 15:02:42.765163: \n",
            "2025-08-15 15:02:42.765697: Epoch 130\n",
            "2025-08-15 15:02:42.765823: Current learning rate: 0.00517\n",
            "2025-08-15 15:03:44.403059: train_loss -0.1176\n",
            "2025-08-15 15:03:44.403610: val_loss 0.0174\n",
            "2025-08-15 15:03:44.404037: Pseudo dice [np.float32(0.872), np.float32(0.5772)]\n",
            "2025-08-15 15:03:44.404174: Epoch time: 61.64 s\n",
            "Classification Train Acc: 0.4300\n",
            "Classification Val Acc: 0.4600\n",
            "(cls) epoch val acc: 0.460\n",
            "2025-08-15 15:03:45.754681: \n",
            "2025-08-15 15:03:45.755289: Epoch 131\n",
            "2025-08-15 15:03:45.755407: Current learning rate: 0.00513\n",
            "2025-08-15 15:04:47.373781: train_loss -0.1218\n",
            "2025-08-15 15:04:47.374248: val_loss 0.0107\n",
            "2025-08-15 15:04:47.374668: Pseudo dice [np.float32(0.843), np.float32(0.7296)]\n",
            "2025-08-15 15:04:47.374781: Epoch time: 61.62 s\n",
            "Classification Train Acc: 0.2600\n",
            "Classification Val Acc: 0.1800\n",
            "(cls) epoch val acc: 0.180\n",
            "2025-08-15 15:04:48.938049: \n",
            "2025-08-15 15:04:48.938571: Epoch 132\n",
            "2025-08-15 15:04:48.938693: Current learning rate: 0.00509\n",
            "2025-08-15 15:05:50.604413: train_loss -0.1286\n",
            "2025-08-15 15:05:50.604817: val_loss 0.024\n",
            "2025-08-15 15:05:50.605217: Pseudo dice [np.float32(0.8472), np.float32(0.6016)]\n",
            "2025-08-15 15:05:50.605348: Epoch time: 61.67 s\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.4700\n",
            "(cls) epoch val acc: 0.470\n",
            "2025-08-15 15:05:51.941846: \n",
            "2025-08-15 15:05:51.942416: Epoch 133\n",
            "2025-08-15 15:05:51.942543: Current learning rate: 0.00505\n",
            "2025-08-15 15:06:53.645784: train_loss -0.1225\n",
            "2025-08-15 15:06:53.646278: val_loss -0.006\n",
            "2025-08-15 15:06:53.646675: Pseudo dice [np.float32(0.8647), np.float32(0.7284)]\n",
            "2025-08-15 15:06:53.646785: Epoch time: 61.71 s\n",
            "2025-08-15 15:06:53.646858: Yayy! New best EMA pseudo Dice: 0.7368000149726868\n",
            "Classification Train Acc: 0.4000\n",
            "Classification Val Acc: 0.2500\n",
            "(cls) epoch val acc: 0.250\n",
            "2025-08-15 15:06:56.413782: \n",
            "2025-08-15 15:06:56.414434: Epoch 134\n",
            "2025-08-15 15:06:56.414561: Current learning rate: 0.00501\n",
            "2025-08-15 15:07:58.065505: train_loss -0.1273\n",
            "2025-08-15 15:07:58.065852: val_loss 0.0132\n",
            "2025-08-15 15:07:58.066233: Pseudo dice [np.float32(0.8727), np.float32(0.6686)]\n",
            "2025-08-15 15:07:58.066337: Epoch time: 61.66 s\n",
            "2025-08-15 15:07:58.066411: Yayy! New best EMA pseudo Dice: 0.7401999831199646\n",
            "Classification Train Acc: 0.4200\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 15:08:00.601707: \n",
            "2025-08-15 15:08:00.602360: Epoch 135\n",
            "2025-08-15 15:08:00.602511: Current learning rate: 0.00497\n",
            "2025-08-15 15:09:02.223166: train_loss -0.1241\n",
            "2025-08-15 15:09:02.223531: val_loss -0.0027\n",
            "2025-08-15 15:09:02.224067: Pseudo dice [np.float32(0.8699), np.float32(0.6541)]\n",
            "2025-08-15 15:09:02.224345: Epoch time: 61.63 s\n",
            "2025-08-15 15:09:02.224439: Yayy! New best EMA pseudo Dice: 0.7423999905586243\n",
            "Classification Train Acc: 0.4600\n",
            "Classification Val Acc: 0.4400\n",
            "(cls) epoch val acc: 0.440\n",
            "2025-08-15 15:09:04.834709: \n",
            "2025-08-15 15:09:04.835332: Epoch 136\n",
            "2025-08-15 15:09:04.835493: Current learning rate: 0.00493\n",
            "2025-08-15 15:10:06.386313: train_loss -0.1357\n",
            "2025-08-15 15:10:06.386623: val_loss -0.0345\n",
            "2025-08-15 15:10:06.386973: Pseudo dice [np.float32(0.8771), np.float32(0.7482)]\n",
            "2025-08-15 15:10:06.387121: Epoch time: 61.56 s\n",
            "2025-08-15 15:10:06.387204: Yayy! New best EMA pseudo Dice: 0.7494000196456909\n",
            "Classification Train Acc: 0.4100\n",
            "Classification Val Acc: 0.3300\n",
            "(cls) epoch val acc: 0.330\n",
            "2025-08-15 15:10:09.009412: \n",
            "2025-08-15 15:10:09.009950: Epoch 137\n",
            "2025-08-15 15:10:09.010099: Current learning rate: 0.00489\n",
            "2025-08-15 15:11:10.635818: train_loss -0.1512\n",
            "2025-08-15 15:11:10.636215: val_loss 0.03\n",
            "2025-08-15 15:11:10.636580: Pseudo dice [np.float32(0.8476), np.float32(0.61)]\n",
            "2025-08-15 15:11:10.636695: Epoch time: 61.63 s\n",
            "Classification Train Acc: 0.4500\n",
            "Classification Val Acc: 0.4600\n",
            "(cls) epoch val acc: 0.460\n",
            "2025-08-15 15:11:11.968437: \n",
            "2025-08-15 15:11:11.968925: Epoch 138\n",
            "2025-08-15 15:11:11.969059: Current learning rate: 0.00485\n",
            "2025-08-15 15:12:13.475905: train_loss -0.1399\n",
            "2025-08-15 15:12:13.476281: val_loss 0.0919\n",
            "2025-08-15 15:12:13.476722: Pseudo dice [np.float32(0.8705), np.float32(0.5704)]\n",
            "2025-08-15 15:12:13.476823: Epoch time: 61.51 s\n",
            "Classification Train Acc: 0.3600\n",
            "Classification Val Acc: 0.4000\n",
            "(cls) epoch val acc: 0.400\n",
            "2025-08-15 15:12:14.825452: \n",
            "2025-08-15 15:12:14.826018: Epoch 139\n",
            "2025-08-15 15:12:14.826133: Current learning rate: 0.00482\n",
            "2025-08-15 15:13:16.355232: train_loss -0.1369\n",
            "2025-08-15 15:13:16.355683: val_loss -0.0317\n",
            "2025-08-15 15:13:16.356064: Pseudo dice [np.float32(0.8791), np.float32(0.6855)]\n",
            "2025-08-15 15:13:16.356161: Epoch time: 61.53 s\n",
            "Classification Train Acc: 0.3800\n",
            "Classification Val Acc: 0.2400\n",
            "(cls) epoch val acc: 0.240\n",
            "2025-08-15 15:13:17.690479: \n",
            "2025-08-15 15:13:17.691022: Epoch 140\n",
            "2025-08-15 15:13:17.691215: Current learning rate: 0.00478\n",
            "2025-08-15 15:14:19.306808: train_loss -0.1398\n",
            "2025-08-15 15:14:19.307201: val_loss 0.0448\n",
            "2025-08-15 15:14:19.307619: Pseudo dice [np.float32(0.8534), np.float32(0.6194)]\n",
            "2025-08-15 15:14:19.307766: Epoch time: 61.62 s\n",
            "Classification Train Acc: 0.3900\n",
            "Classification Val Acc: 0.4300\n",
            "(cls) epoch val acc: 0.430\n",
            "2025-08-15 15:14:20.651615: \n",
            "2025-08-15 15:14:20.652182: Epoch 141\n",
            "2025-08-15 15:14:20.652302: Current learning rate: 0.00474\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1369654957.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_multitask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Multi-task training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3857426853.py\u001b[0m in \u001b[0;36mtrain_multitask_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0mtrain_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iterations_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m                 \u001b[0mtrain_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_scaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Train the model\n",
        "    trainer = train_multitask_model()\n",
        "    print(\"✅ Multi-task training completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Training failed with error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OUnsH3V9Kjg7",
      "metadata": {
        "id": "OUnsH3V9Kjg7"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "LHC9r7Uqe909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHC9r7Uqe909",
        "outputId": "cc7195c2-3424-4c58-e81d-1ffc6b2304a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model dir: /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0\n",
            "Has checkpoint? True\n",
            "imagesTs count: 72\n"
          ]
        }
      ],
      "source": [
        "# === USER CONFIG ===\n",
        "DATASET_ID = 500\n",
        "CONFIG = \"3d_fullres\"\n",
        "PLANS = \"nnUNetResEncUNetMPlans\"\n",
        "TRAINER = \"MultiTaskTrainer\"\n",
        "FOLDS = 0\n",
        "\n",
        "# nnU-Net folder roots (adapt if you’ve set them differently)\n",
        "import os\n",
        "os.environ[\"nnUNet_raw\"] = \"/content/nnUNet_raw\"\n",
        "os.environ[\"nnUNet_preprocessed\"] = \"/content/nnUNet_preprocessed\"\n",
        "os.environ[\"nnUNet_results\"] = \"/content/nnUNet_results\"\n",
        "\n",
        "# I/O\n",
        "IMAGES_TS = f'{os.environ[\"nnUNet_raw\"]}/Dataset{DATASET_ID}_PancreasCancer/imagesTs'\n",
        "MODEL_DIR = f'{os.environ[\"nnUNet_results\"]}/Dataset{DATASET_ID}_PancreasCancer/{TRAINER}__{PLANS}__{CONFIG}/fold_{FOLDS}'\n",
        "OUT_DIR = f'/content/submission_outputs'          # where we will save predictions\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Choose checkpoint\n",
        "CHECKPOINT_NAME = \"checkpoint_best.pth\"           # fallback to \"checkpoint_final.pth\" if not present\n",
        "\n",
        "# Quick sanity checks\n",
        "print(\"Model dir:\", MODEL_DIR)\n",
        "print(\"Has checkpoint?\", os.path.exists(os.path.join(MODEL_DIR, CHECKPOINT_NAME)))\n",
        "print(\"imagesTs count:\", len(glob.glob(os.path.join(IMAGES_TS, \"*.nii.gz\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Oyctc6xpf1Sr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyctc6xpf1Sr",
        "outputId": "143b08bf-84b7-4f8c-8e78-2a1a2cd51cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Model root: /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres\n",
            "  ↳ mirrored dataset.json → /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0\n",
            "  ↳ mirrored plans.json → /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0\n",
            "✅ Predictor ready on cuda\n",
            "   Using model dir: /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres\n",
            "   Using folds: (0,)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the nnUNetv2 predictor\n",
        "\n",
        "import os, shutil, glob\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from inspect import signature\n",
        "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 1) Auto-detect the correct model ROOT directory (where dataset.json lives)\n",
        "results_root = os.environ.get(\"nnUNet_results\", \"/content/nnUNet_results\")\n",
        "ds_root = f\"{results_root}/Dataset{DATASET_ID}_PancreasCancer\"\n",
        "\n",
        "candidates = [\n",
        "    f\"{ds_root}/{CONFIG}/{TRAINER}__{PLANS}\",        # e.g., .../3d_fullres/MultiTaskTrainer__Plans\n",
        "    f\"{ds_root}/{TRAINER}__{PLANS}__{CONFIG}\",       # e.g., .../MultiTaskTrainer__Plans__3d_fullres  (your case)\n",
        "    f\"{ds_root}/{TRAINER}__{PLANS}\",                 # fallback\n",
        "]\n",
        "\n",
        "MODEL_DIR_EFF = None\n",
        "for c in candidates:\n",
        "    if os.path.isfile(os.path.join(c, \"dataset.json\")) and os.path.isfile(os.path.join(c, \"plans.json\")):\n",
        "        MODEL_DIR_EFF = c\n",
        "        break\n",
        "\n",
        "if MODEL_DIR_EFF is None:\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find model dir containing dataset.json & plans.json.\\n\"\n",
        "        f\"Tried:\\n- \" + \"\\n- \".join(candidates)\n",
        "    )\n",
        "\n",
        "print(\"[OK] Model root:\", MODEL_DIR_EFF)\n",
        "\n",
        "# --- 2) Ensure each requested fold has dataset.json/plans.json (some nnUNetv2 builds expect them inside fold_X)\n",
        "folds_to_use = tuple(FOLDS) if isinstance(FOLDS, (list, tuple)) else (FOLDS,)\n",
        "for f in folds_to_use:\n",
        "    fold_dir = os.path.join(MODEL_DIR_EFF, f\"fold_{f}\")\n",
        "    if not os.path.isdir(fold_dir):\n",
        "        raise FileNotFoundError(f\"Missing fold directory: {fold_dir}\")\n",
        "    for fname in (\"dataset.json\", \"plans.json\"):\n",
        "        src = os.path.join(MODEL_DIR_EFF, fname)\n",
        "        dst = os.path.join(fold_dir, fname)\n",
        "        if os.path.isfile(src) and not os.path.isfile(dst):\n",
        "            shutil.copy2(src, dst)\n",
        "            print(f\"  ↳ mirrored {fname} → {fold_dir}\")\n",
        "\n",
        "# Optional: verify checkpoint exists in the fold\n",
        "for f in folds_to_use:\n",
        "    ck1 = os.path.join(MODEL_DIR_EFF, f\"fold_{f}\", CHECKPOINT_NAME)\n",
        "    ck2 = os.path.join(MODEL_DIR_EFF, f\"fold_{f}\", \"checkpoint_final.pth\")\n",
        "    if not (os.path.exists(ck1) or os.path.exists(ck2)):\n",
        "        print(f\"⚠️  No checkpoint found for fold {f}: looked for {CHECKPOINT_NAME} or checkpoint_final.pth\")\n",
        "\n",
        "# --- 3) Build predictor with only supported __init__ kwargs (older/newer compat)\n",
        "_ctor_params = signature(nnUNetPredictor.__init__).parameters\n",
        "ctor_kwargs = {\n",
        "    \"tile_step_size\": 0.5,\n",
        "    \"use_gaussian\": True,\n",
        "    \"use_mirroring\": False,\n",
        "    \"device\": device,\n",
        "    \"verbose\": True,\n",
        "    \"verbose_preprocessing\": False,\n",
        "    \"allow_tqdm\": True,\n",
        "}\n",
        "ctor_kwargs = {k: v for k, v in ctor_kwargs.items() if k in _ctor_params}\n",
        "predictor = nnUNetPredictor(**ctor_kwargs)\n",
        "\n",
        "# --- 4) Initialize from trained model folder, trying several signatures (no 'strict' in older builds)\n",
        "init_tried = False\n",
        "try:\n",
        "    predictor.initialize_from_trained_model_folder(\n",
        "        model_training_output_dir=MODEL_DIR_EFF,\n",
        "        use_folds=folds_to_use,\n",
        "        checkpoint_name=CHECKPOINT_NAME,\n",
        "    )\n",
        "    init_tried = True\n",
        "except TypeError:\n",
        "    pass\n",
        "\n",
        "if not init_tried:\n",
        "    try:\n",
        "        predictor.initialize_from_trained_model_folder(\n",
        "            model_training_output_dir=MODEL_DIR_EFF,\n",
        "            use_folds=folds_to_use,\n",
        "        )\n",
        "        init_tried = True\n",
        "    except TypeError:\n",
        "        pass\n",
        "\n",
        "if not init_tried:\n",
        "    try:\n",
        "        predictor.initialize_from_trained_model_folder(MODEL_DIR_EFF, folds_to_use)\n",
        "        init_tried = True\n",
        "    except TypeError:\n",
        "        predictor.initialize_from_trained_model_folder(MODEL_DIR_EFF)\n",
        "        init_tried = True\n",
        "\n",
        "# Set checkpoint on attribute if available (older versions ignore in init)\n",
        "if hasattr(predictor, \"checkpoint_name\"):\n",
        "    predictor.checkpoint_name = CHECKPOINT_NAME\n",
        "\n",
        "print(\"✅ Predictor ready on\", device)\n",
        "print(\"   Using model dir:\", MODEL_DIR_EFF)\n",
        "print(\"   Using folds:\", folds_to_use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ErpwAM81TjAV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErpwAM81TjAV",
        "outputId": "7c2b4017-7853-4bdd-d74f-b0c0a5802b68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 72/72 [06:32<00:00,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved segmentations to: /content/submission_outputs/segmentations\n",
            "Saved classification to: /content/submission_outputs/subtype_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# STEP 3 — Version-agnostic inference (GPU sliding window + safe-padded classification)\n",
        "import os, glob, math, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# ---- setup\n",
        "device = predictor.device if hasattr(predictor, \"device\") else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = predictor.network.to(device)\n",
        "net.eval()\n",
        "\n",
        "# I/O\n",
        "test_files = sorted(glob.glob(os.path.join(IMAGES_TS, \"*.nii.gz\")))\n",
        "assert test_files, f\"No test files in {IMAGES_TS}\"\n",
        "SEG_DIR = os.path.join(OUT_DIR, \"segmentations\")\n",
        "Path(SEG_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---- helpers\n",
        "def _case_name_for_submission(img_path: str) -> str:\n",
        "    return Path(img_path).name.replace(\"_0000\", \"\")\n",
        "\n",
        "def _clip_zscore(x, p_low=0.5, p_high=99.5, eps=1e-6):\n",
        "    lo, hi = np.percentile(x, [p_low, p_high])\n",
        "    x = np.clip(x, lo, hi)\n",
        "    m, s = x.mean(), x.std()\n",
        "    return ((x - m) / (s + eps)).astype(np.float32)\n",
        "\n",
        "def _pad_to_min_shape(arr, min_shape):\n",
        "    pads = []\n",
        "    for a, m in zip(arr.shape, min_shape):\n",
        "        add = max(0, m - a)\n",
        "        pl = add // 2\n",
        "        pr = add - pl\n",
        "        pads.append((pl, pr))\n",
        "    arr2 = np.pad(arr, pads, mode='constant', constant_values=0)\n",
        "    slc = tuple(slice(p[0], p[0] + arr.shape[i]) for i, p in enumerate(pads))\n",
        "    return arr2, slc\n",
        "\n",
        "def _gen_tiles(shape, patch, stride):\n",
        "    D, H, W = shape\n",
        "    Pd, Ph, Pw = patch\n",
        "    Sd, Sh, Sw = stride\n",
        "    z_starts = list(range(0, max(1, D - Pd + 1), Sd))\n",
        "    y_starts = list(range(0, max(1, H - Ph + 1), Sh))\n",
        "    x_starts = list(range(0, max(1, W - Pw + 1), Sw))\n",
        "    if z_starts[-1] != max(0, D - Pd): z_starts.append(max(0, D - Pd))\n",
        "    if y_starts[-1] != max(0, H - Ph): y_starts.append(max(0, H - Ph))\n",
        "    if x_starts[-1] != max(0, W - Pw): x_starts.append(max(0, W - Pw))\n",
        "    for z in z_starts:\n",
        "        for y in y_starts:\n",
        "            for x in x_starts:\n",
        "                yield z, y, x\n",
        "\n",
        "def _gaussian_weight(patch):\n",
        "    zz = torch.linspace(-1, 1, steps=patch[0], dtype=torch.float32)[:, None, None]\n",
        "    yy = torch.linspace(-1, 1, steps=patch[1], dtype=torch.float32)[None, :, None]\n",
        "    xx = torch.linspace(-1, 1, steps=patch[2], dtype=torch.float32)[None, None, :]\n",
        "    g = torch.exp(-0.5 * (zz**2 + yy**2 + xx**2))\n",
        "    g /= g.max()\n",
        "    return g\n",
        "\n",
        "def _get_divisors_from_plans(model_dir_eff, fallback=(32, 32, 32)):\n",
        "    try:\n",
        "        from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "        pm = PlansManager(os.path.join(model_dir_eff, \"plans.json\"))\n",
        "        stg = pm.get_stage_from_scale_factor(1.0)\n",
        "        props = pm.get_properties_of_stage(stg)\n",
        "        if \"num_pool_per_axis\" in props:\n",
        "            npp = props[\"num_pool_per_axis\"]\n",
        "            return tuple(int(2 ** int(v)) for v in npp)\n",
        "        if \"pool_op_kernel_sizes\" in props:\n",
        "            ks = props[\"pool_op_kernel_sizes\"]\n",
        "            acc = np.array([1, 1, 1], dtype=int)\n",
        "            for s in ks:\n",
        "                acc *= np.array(s, dtype=int)\n",
        "            return tuple(int(v) for v in acc)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return fallback\n",
        "\n",
        "def _pad_to_multiples_torch(vol_5d, multiples):  # vol_5d: [B,C,D,H,W] float32 on device\n",
        "    _, _, D, H, W = vol_5d.shape\n",
        "    md, mh, mw = multiples\n",
        "    pad_d = (md - (D % md)) % md\n",
        "    pad_h = (mh - (H % mh)) % mh\n",
        "    pad_w = (mw - (W % mw)) % mw\n",
        "    # F.pad order: (wL, wR, hL, hR, dL, dR)\n",
        "    pad = (0, pad_w, 0, pad_h, 0, pad_d)\n",
        "    if any(pad):\n",
        "        vol_5d = F.pad(vol_5d, pad, mode=\"constant\", value=0.0)\n",
        "    return vol_5d\n",
        "\n",
        "# ---- patch/stride from plans or fallback\n",
        "try:\n",
        "    from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "    pl = PlansManager(os.path.join(MODEL_DIR_EFF, \"plans.json\"))\n",
        "    stg = pl.get_stage_from_scale_factor(1.0)\n",
        "    PATCH = tuple(pl.get_properties_of_stage(stg)['patch_size'])\n",
        "except Exception:\n",
        "    PATCH = (80, 160, 160)\n",
        "STRIDE = tuple(max(1, int(p * 0.5)) for p in PATCH)\n",
        "\n",
        "gauss_w = _gaussian_weight(PATCH).to(device)\n",
        "\n",
        "# ---- main loop\n",
        "cls_rows = []\n",
        "\n",
        "for img_path in tqdm(test_files, desc=\"Predicting\"):\n",
        "    # load & normalize\n",
        "    img_nii = nib.load(img_path)\n",
        "    img = img_nii.get_fdata().astype(np.float32)         # [D,H,W]\n",
        "    img_n = _clip_zscore(img)\n",
        "\n",
        "    # pad for sliding-window\n",
        "    img_pad, undo_pad = _pad_to_min_shape(img_n, PATCH)\n",
        "    D, H, W = img_pad.shape\n",
        "\n",
        "    # probe for num classes\n",
        "    with torch.no_grad():\n",
        "        probe_np = img_pad[:min(PATCH[0], D), :min(PATCH[1], H), :min(PATCH[2], W)]\n",
        "        probe = torch.from_numpy(probe_np[None, None]).to(device=device, dtype=torch.float32)\n",
        "        out_probe = net(probe)\n",
        "        if isinstance(out_probe, (list, tuple)):\n",
        "            out_probe = out_probe[0]\n",
        "        C = out_probe.shape[1]\n",
        "\n",
        "    # accumulators\n",
        "    logits_acc = torch.zeros((C, D, H, W), device=device, dtype=torch.float32)\n",
        "    weight_acc = torch.zeros((1, D, H, W), device=device, dtype=torch.float32)\n",
        "\n",
        "    # sliding-window on GPU with Gaussian blending\n",
        "    for z, y, x in _gen_tiles((D, H, W), PATCH, STRIDE):\n",
        "        patch_np = img_pad[z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]]\n",
        "        patch_t = torch.from_numpy(patch_np[None, None]).to(device=device, dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            out = net(patch_t)\n",
        "            seg_logits = out[0] if isinstance(out, (list, tuple)) else out  # [1,C,Pd,Ph,Pw]\n",
        "            seg_logits = seg_logits.to(dtype=torch.float32)\n",
        "        w = gauss_w\n",
        "        logits_acc[:, z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]] += (seg_logits[0] * w)\n",
        "        weight_acc[:, z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]] += w\n",
        "\n",
        "    # normalize, crop back, argmax on GPU\n",
        "    logits_acc = logits_acc / weight_acc.clamp_min(1e-6)\n",
        "    zsl, ysl, xsl = undo_pad\n",
        "    logits_acc = logits_acc[:, zsl, ysl, xsl]\n",
        "    seg_pred = torch.argmax(logits_acc, dim=0).to(torch.uint8)\n",
        "    seg_np = seg_pred.detach().cpu().numpy()\n",
        "\n",
        "    # save segmentation\n",
        "    out_name = _case_name_for_submission(img_path)\n",
        "    nib.save(nib.Nifti1Image(seg_np.astype(np.uint8), img_nii.affine, img_nii.header),\n",
        "             os.path.join(SEG_DIR, out_name))\n",
        "\n",
        "    # ---- classification: full-volume pass with safe padding (global; no need to unpad)\n",
        "    divisors = _get_divisors_from_plans(MODEL_DIR_EFF, fallback=(32, 32, 32))\n",
        "    vol_np = _clip_zscore(img).astype(np.float32)\n",
        "    vol_t = torch.from_numpy(vol_np[None, None]).to(device=device, dtype=torch.float32)  # [1,1,D,H,W]\n",
        "    vol_t = _pad_to_multiples_torch(vol_t, divisors)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        seg_out_full, cls_logits = net(vol_t, return_both=True)\n",
        "        subtype = int(torch.argmax(cls_logits, dim=1).item())\n",
        "\n",
        "    cls_rows.append({\"Names\": out_name, \"Subtype\": subtype})\n",
        "\n",
        "# write classification CSV\n",
        "CSV_PATH = os.path.join(OUT_DIR, \"subtype_results.csv\")\n",
        "pd.DataFrame(cls_rows).to_csv(CSV_PATH, index=False)\n",
        "\n",
        "print(\"Saved segmentations to:\", SEG_DIR)\n",
        "print(\"Saved classification to:\", CSV_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N_ylAcqMrzgD",
      "metadata": {
        "id": "N_ylAcqMrzgD"
      },
      "source": [
        "## Visualize segmentation prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sgXNv9IYqK0g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgXNv9IYqK0g",
        "outputId": "8dbdbe44-cbc3-4adb-d740-8a3d164d9f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 72 segmentations in /content/submission_outputs/segmentations\n",
            "Found 72 CTs in /content/nnUNet_raw/Dataset500_PancreasCancer/imagesTs\n",
            "Visualizing: seg=/content/submission_outputs/segmentations/quiz_037.nii.gz  ct=/content/nnUNet_raw/Dataset500_PancreasCancer/imagesTs/quiz_037_0000.nii.gz\n",
            "Saved preview → /content/submission_outputs/previews/quiz_037.nii.png\n",
            "Visualizing: seg=/content/submission_outputs/segmentations/quiz_045.nii.gz  ct=/content/nnUNet_raw/Dataset500_PancreasCancer/imagesTs/quiz_045_0000.nii.gz\n",
            "Saved preview → /content/submission_outputs/previews/quiz_045.nii.png\n",
            "Previews in: /content/submission_outputs/previews\n"
          ]
        }
      ],
      "source": [
        "# DIAG + VIS: verify files, then show & save overlays for up to 2 cases\n",
        "import os, glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEG_DIR = os.path.join(OUT_DIR, \"segmentations\")\n",
        "seg_files = sorted(glob.glob(os.path.join(SEG_DIR, \"*.nii.gz\")))\n",
        "ct_files  = sorted(glob.glob(os.path.join(IMAGES_TS, \"*.nii.gz\")))\n",
        "\n",
        "print(f\"Found {len(seg_files)} segmentations in {SEG_DIR}\")\n",
        "print(f\"Found {len(ct_files)} CTs in {IMAGES_TS}\")\n",
        "\n",
        "# Helper: map seg name -> expected CT path\n",
        "def ct_for_seg(seg_name: str):\n",
        "    base = seg_name.replace(\".nii.gz\", \"\")\n",
        "    cand1 = os.path.join(IMAGES_TS, f\"{base}_0000.nii.gz\")\n",
        "    cand2 = os.path.join(IMAGES_TS, f\"{base}.nii.gz\")\n",
        "    if os.path.exists(cand1): return cand1\n",
        "    if os.path.exists(cand2): return cand2\n",
        "    return None\n",
        "\n",
        "def pick_slice_z(seg_3d):\n",
        "    # prioritize lesion (2), then pancreas (1); otherwise middle slice\n",
        "    for label in (2, 1):\n",
        "        idx = np.argwhere(seg_3d == label)\n",
        "        if idx.size > 0:\n",
        "            # idx columns: x,y,z for (X,Y,Z) layout\n",
        "            z = int(np.median(idx[:, 2]))\n",
        "            return z\n",
        "    return seg_3d.shape[2] // 2\n",
        "\n",
        "def show_case(ct_path, seg_path, save_png_path=None):\n",
        "    ct_nii = nib.load(ct_path); ct = ct_nii.get_fdata().astype(np.float32)   # shape (X,Y,Z)\n",
        "    seg_nii = nib.load(seg_path); seg = seg_nii.get_fdata().astype(np.uint8) # shape (X,Y,Z)\n",
        "    assert ct.shape[:3] == seg.shape[:3], f\"Shape mismatch: CT {ct.shape} vs SEG {seg.shape}\"\n",
        "\n",
        "    z = pick_slice_z(seg)\n",
        "    ct_slice  = ct[:, :, z]\n",
        "    seg_slice = seg[:, :, z]\n",
        "\n",
        "    # robust window for CT\n",
        "    lo, hi = np.percentile(ct_slice, [1, 99])\n",
        "    ct_disp = np.clip(ct_slice, lo, hi)\n",
        "    ct_disp = (ct_disp - ct_disp.min()) / (ct_disp.max() - ct_disp.min() + 1e-6)\n",
        "\n",
        "    # overlay: R=pancreas(1), G=lesion(2)\n",
        "    overlay = np.zeros((ct_disp.shape[0], ct_disp.shape[1], 3), dtype=np.float32)\n",
        "    overlay[..., 0] = (seg_slice == 1).astype(np.float32) * 0.8\n",
        "    overlay[..., 1] = (seg_slice == 2).astype(np.float32) * 0.9\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axes[0].imshow(ct_disp, cmap='gray'); axes[0].set_title('CT (axial)'); axes[0].axis('off')\n",
        "    axes[1].imshow(seg_slice, interpolation='nearest'); axes[1].set_title('Seg labels (0/1/2)'); axes[1].axis('off')\n",
        "    axes[2].imshow(ct_disp, cmap='gray'); axes[2].imshow(overlay, alpha=0.35); axes[2].set_title('Overlay'); axes[2].axis('off')\n",
        "    fig.suptitle(f\"{Path(seg_path).name} @ z={z}\", y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    if save_png_path:\n",
        "        fig.savefig(save_png_path, dpi=120, bbox_inches='tight')\n",
        "        print(\"Saved preview →\", save_png_path)\n",
        "\n",
        "# Pick which segmentations to show (first two by default)\n",
        "to_show = [Path(p).name for p in seg_files[:2]]\n",
        "if not to_show:\n",
        "    raise RuntimeError(f\"No segmentation files found in {SEG_DIR}. Did Step 3 finish successfully?\")\n",
        "\n",
        "PREVIEW_DIR = os.path.join(OUT_DIR, \"previews\")\n",
        "os.makedirs(PREVIEW_DIR, exist_ok=True)\n",
        "\n",
        "for name in to_show:\n",
        "    ct_path = ct_for_seg(name)\n",
        "    if ct_path is None:\n",
        "        print(f\"⚠️ Could not find CT for {name} in imagesTs (tried *_0000.nii.gz and same name). Skipping.\")\n",
        "        continue\n",
        "    seg_path = os.path.join(SEG_DIR, name)\n",
        "    png_out  = os.path.join(PREVIEW_DIR, f\"{Path(name).stem}.png\")\n",
        "    print(f\"Visualizing: seg={seg_path}  ct={ct_path}\")\n",
        "    show_case(ct_path, seg_path, save_png_path=png_out)\n",
        "\n",
        "print(\"Previews in:\", PREVIEW_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clS8-GYFbU0L",
      "metadata": {
        "id": "clS8-GYFbU0L"
      },
      "source": [
        "## Evaluate segmentation with sensible metrics (Dice + boundary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "co0ob03IYAF9",
      "metadata": {
        "id": "co0ob03IYAF9"
      },
      "outputs": [],
      "source": [
        "# pip once (safe to re-run)\n",
        "!pip -q install nibabel surface-distance pandas numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028l2Jvxn90g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "028l2Jvxn90g",
        "outputId": "aa1c24ed-a4fb-403c-95f2-8af5f079d6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Eval] Found 36 cases under /content/drive/MyDrive/ML-Quiz-3DMedImg/data/validation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 36/36 [02:15<00:00,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Seg] Mean Dice — Pancreas: 0.4587 | Lesion: 0.1371\n",
            "[Cls] Acc: 0.3333 | Macro-F1: 0.1667\n",
            "[Eval] Per-case → /content/submission_outputs/eval_val/validation_per_case.csv\n",
            "[Eval] Summary  → /content/submission_outputs/eval_val/validation_summary.csv\n",
            "[Eval] ConfMat  → /content/submission_outputs/eval_val/cls_confusion_matrix.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==== EVAL for folder layout: data/validation/subtype{0,1,2} ====\n",
        "# Edit this path to where your tree lives:\n",
        "VALID_ROOT = \"/content/drive/MyDrive/ML-Quiz-3DMedImg/data/validation\"   # e.g. /content/data/validation/subtype0/...\n",
        "\n",
        "import os, glob, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "assert os.path.isdir(VALID_ROOT), f\"Not found: {VALID_ROOT}\"\n",
        "\n",
        "# ----- collect (case_id, img_path, gt_path, subtype_gt) from validation/subtype{0,1,2} -----\n",
        "pairs = []\n",
        "for subname, sublab in ((\"subtype0\", 0), (\"subtype1\", 1), (\"subtype2\", 2)):\n",
        "    subdir = os.path.join(VALID_ROOT, subname)\n",
        "    if not os.path.isdir(subdir):\n",
        "        continue\n",
        "    # images are *_0000.nii.gz; masks are the same stem without _0000\n",
        "    for ip in sorted(glob.glob(os.path.join(subdir, \"*_0000.nii.gz\"))):\n",
        "        stem = Path(ip).name.replace(\"_0000.nii.gz\", \"\")\n",
        "        gp = os.path.join(subdir, f\"{stem}.nii.gz\")\n",
        "        if os.path.isfile(gp):\n",
        "            pairs.append((stem, ip, gp, sublab))\n",
        "        else:\n",
        "            print(f\"⚠️ GT missing for {ip}, expected {gp}\")\n",
        "\n",
        "assert len(pairs) > 0, f\"No (image,label) pairs found under {VALID_ROOT}/subtype{{0,1,2}}\"\n",
        "print(f\"[Eval] Found {len(pairs)} cases under {VALID_ROOT}\")\n",
        "\n",
        "# ----- setup network -----\n",
        "device = predictor.device if hasattr(predictor, \"device\") else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = predictor.network.to(device)\n",
        "net.eval()\n",
        "\n",
        "# patch/stride from plans or safe fallback\n",
        "try:\n",
        "    from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "    pl = PlansManager(os.path.join(MODEL_DIR_EFF, \"plans.json\"))\n",
        "    stg = pl.get_stage_from_scale_factor(1.0)\n",
        "    PATCH = tuple(pl.get_properties_of_stage(stg)['patch_size'])\n",
        "except Exception:\n",
        "    PATCH = (80, 160, 160)\n",
        "STRIDE = tuple(max(1, int(p * 0.5)) for p in PATCH)\n",
        "\n",
        "# ----- helpers (same as we used for inference) -----\n",
        "def _clip_zscore(x, p_low=0.5, p_high=99.5, eps=1e-6):\n",
        "    lo, hi = np.percentile(x, [p_low, p_high])\n",
        "    x = np.clip(x, lo, hi)\n",
        "    m, s = x.mean(), x.std()\n",
        "    return ((x - m) / (s + eps)).astype(np.float32)\n",
        "\n",
        "def _pad_to_min_shape(arr, min_shape):\n",
        "    pads=[];\n",
        "    for a, m in zip(arr.shape, min_shape):\n",
        "        add = max(0, m - a); pl = add // 2; pr = add - pl\n",
        "        pads.append((pl, pr))\n",
        "    arr2 = np.pad(arr, pads, mode='constant', constant_values=0)\n",
        "    slc = tuple(slice(p[0], p[0] + arr.shape[i]) for i,p in enumerate(pads))\n",
        "    return arr2, slc\n",
        "\n",
        "def _gen_tiles(shape, patch, stride):\n",
        "    D,H,W = shape; Pd,Ph,Pw = patch; Sd,Sh,Sw = stride\n",
        "    z_starts = list(range(0, max(1, D - Pd + 1), Sd))\n",
        "    y_starts = list(range(0, max(1, H - Ph + 1), Sh))\n",
        "    x_starts = list(range(0, max(1, W - Pw + 1), Sw))\n",
        "    if z_starts[-1] != max(0, D-Pd): z_starts.append(max(0, D-Pd))\n",
        "    if y_starts[-1] != max(0, H-Ph): y_starts.append(max(0, H-Ph))\n",
        "    if x_starts[-1] != max(0, W-Pw): x_starts.append(max(0, W-Pw))\n",
        "    for z in z_starts:\n",
        "        for y in y_starts:\n",
        "            for x in x_starts:\n",
        "                yield z,y,x\n",
        "\n",
        "def _gaussian_weight(patch):\n",
        "    zz = torch.linspace(-1,1,steps=patch[0], dtype=torch.float32)[:,None,None]\n",
        "    yy = torch.linspace(-1,1,steps=patch[1], dtype=torch.float32)[None,:,None]\n",
        "    xx = torch.linspace(-1,1,steps=patch[2], dtype=torch.float32)[None,None,:]\n",
        "    g = torch.exp(-0.5*(zz**2 + yy**2 + xx**2)); g /= g.max()\n",
        "    return g\n",
        "\n",
        "gauss_w = _gaussian_weight(PATCH).to(device)\n",
        "\n",
        "def predict_segmentation(img_3d_float32):\n",
        "    img_n = _clip_zscore(img_3d_float32)\n",
        "    img_pad, undo = _pad_to_min_shape(img_n, PATCH)\n",
        "    D,H,W = img_pad.shape\n",
        "\n",
        "    # probe for C\n",
        "    with torch.no_grad():\n",
        "        probe = torch.from_numpy(img_pad[:min(PATCH[0],D), :min(PATCH[1],H), :min(PATCH[2],W)][None,None]).to(device)\n",
        "        out_probe = net(probe)\n",
        "        if isinstance(out_probe, (list, tuple)): out_probe = out_probe[0]\n",
        "        C = out_probe.shape[1]\n",
        "\n",
        "    logits_acc = torch.zeros((C,D,H,W), device=device, dtype=torch.float32)\n",
        "    weight_acc = torch.zeros((1,D,H,W), device=device, dtype=torch.float32)\n",
        "\n",
        "    for z,y,x in _gen_tiles((D,H,W), PATCH, STRIDE):\n",
        "        patch = torch.from_numpy(img_pad[z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]][None,None]).to(device)\n",
        "        with torch.no_grad():\n",
        "            out = net(patch)\n",
        "            seg_logits = out[0] if isinstance(out, (list, tuple)) else out\n",
        "            seg_logits = seg_logits.to(dtype=torch.float32)\n",
        "        w = gauss_w\n",
        "        logits_acc[:, z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]] += seg_logits[0]*w\n",
        "        weight_acc[:, z:z+PATCH[0], y:y+PATCH[1], x:x+PATCH[2]] += w\n",
        "\n",
        "    logits_acc = logits_acc / weight_acc.clamp_min(1e-6)\n",
        "    zsl, ysl, xsl = undo\n",
        "    logits_acc = logits_acc[:, zsl, ysl, xsl]\n",
        "    pred = torch.argmax(logits_acc, dim=0).to(torch.uint8).detach().cpu().numpy()\n",
        "    return pred\n",
        "\n",
        "def _get_divisors_from_plans(model_dir_eff, fallback=(32,32,32)):\n",
        "    try:\n",
        "        from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "        pm = PlansManager(os.path.join(model_dir_eff, \"plans.json\"))\n",
        "        stg = pm.get_stage_from_scale_factor(1.0)\n",
        "        props = pm.get_properties_of_stage(stg)\n",
        "        if \"num_pool_per_axis\" in props:\n",
        "            npp = props[\"num_pool_per_axis\"]\n",
        "            return tuple(int(2**int(v)) for v in npp)\n",
        "        if \"pool_op_kernel_sizes\" in props:\n",
        "            ks = props[\"pool_op_kernel_sizes\"]\n",
        "            acc = np.array([1,1,1], dtype=int)\n",
        "            for s in ks: acc *= np.array(s, dtype=int)\n",
        "            return tuple(int(v) for v in acc)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return fallback\n",
        "\n",
        "def _pad_to_multiples_torch(vol_5d, multiples):\n",
        "    _,_,D,H,W = vol_5d.shape\n",
        "    md,mh,mw = multiples\n",
        "    pd = (md - (D % md)) % md\n",
        "    ph = (mh - (H % mh)) % mh\n",
        "    pw = (mw - (W % mw)) % mw\n",
        "    pad = (0,pw, 0,ph, 0,pd)  # (wL,wR,hL,hR,dL,dR)\n",
        "    return F.pad(vol_5d, pad, mode=\"constant\", value=0.0) if any(pad) else vol_5d\n",
        "\n",
        "divisors = _get_divisors_from_plans(MODEL_DIR_EFF, fallback=(32,32,32))\n",
        "\n",
        "def predict_subtype(img_3d_float32):\n",
        "    vol = _clip_zscore(img_3d_float32).astype(np.float32)\n",
        "    vol_t = torch.from_numpy(vol[None,None]).to(device=device, dtype=torch.float32)\n",
        "    vol_t = _pad_to_multiples_torch(vol_t, divisors)\n",
        "    with torch.no_grad():\n",
        "        seg_out, cls_logits = net(vol_t, return_both=True)\n",
        "        subtype = int(torch.argmax(cls_logits, dim=1).item())\n",
        "    return subtype\n",
        "\n",
        "# ----- metrics -----\n",
        "def dice_bin(pred, gt):\n",
        "    i = (pred & gt).sum()\n",
        "    u = pred.sum() + gt.sum()\n",
        "    return (2.0 * i) / (u + 1e-8)\n",
        "\n",
        "def compute_case_metrics(pred_lbl, gt_lbl):\n",
        "    pred_pan = (pred_lbl > 0).astype(np.uint8)\n",
        "    gt_pan   = (gt_lbl > 0).astype(np.uint8)\n",
        "    dice_pan = dice_bin(pred_pan, gt_pan)\n",
        "    pred_les = (pred_lbl == 2).astype(np.uint8)\n",
        "    gt_les   = (gt_lbl == 2).astype(np.uint8)\n",
        "    dice_les = dice_bin(pred_les, gt_les)\n",
        "    return float(dice_pan), float(dice_les)\n",
        "\n",
        "def macro_f1_from_cm(cm):\n",
        "    K = cm.shape[0]\n",
        "    f1s=[]\n",
        "    for k in range(K):\n",
        "        tp = cm[k,k]\n",
        "        fp = cm[:,k].sum() - tp\n",
        "        fn = cm[k,:].sum() - tp\n",
        "        prec = tp / (tp + fp + 1e-8)\n",
        "        rec  = tp / (tp + fn + 1e-8)\n",
        "        f1s.append(2*prec*rec / (prec+rec+1e-8))\n",
        "    return float(np.mean(f1s))\n",
        "\n",
        "# ----- run evaluation -----\n",
        "rows=[]; y_true=[]; y_pred=[]\n",
        "for cid, ipath, gpath, subtype_gt in tqdm(pairs, desc=\"Evaluating\"):\n",
        "    img = nib.load(ipath).get_fdata().astype(np.float32)\n",
        "    gt  = nib.load(gpath).get_fdata().astype(np.uint8)\n",
        "\n",
        "    pred = predict_segmentation(img)\n",
        "    dice_pan, dice_les = compute_case_metrics(pred, gt)\n",
        "\n",
        "    subtype_pred = predict_subtype(img)\n",
        "\n",
        "    rows.append({\n",
        "        \"case\": cid,\n",
        "        \"dice_pancreas\": dice_pan,\n",
        "        \"dice_lesion\": dice_les,\n",
        "        \"subtype_pred\": subtype_pred,\n",
        "        \"subtype_gt\": subtype_gt,\n",
        "    })\n",
        "    y_true.append(int(subtype_gt))\n",
        "    y_pred.append(int(subtype_pred))\n",
        "\n",
        "# ----- write results -----\n",
        "EVAL_DIR = os.path.join(OUT_DIR, \"eval_val\")\n",
        "os.makedirs(EVAL_DIR, exist_ok=True)\n",
        "\n",
        "per_case_csv = os.path.join(EVAL_DIR, \"validation_per_case.csv\")\n",
        "pd.DataFrame(rows).to_csv(per_case_csv, index=False)\n",
        "\n",
        "dice_pan_mean = float(np.mean([r[\"dice_pancreas\"] for r in rows]))\n",
        "dice_les_mean = float(np.mean([r[\"dice_lesion\"] for r in rows]))\n",
        "\n",
        "summary = {\n",
        "    \"dice_pancreas_mean\": dice_pan_mean,\n",
        "    \"dice_lesion_mean\": dice_les_mean,\n",
        "}\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "acc = float(accuracy_score(y_true, y_pred))\n",
        "cm  = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
        "f1m = macro_f1_from_cm(cm.astype(np.float64))\n",
        "summary.update({\n",
        "    \"cls_accuracy\": acc,\n",
        "    \"cls_macro_f1\": f1m,\n",
        "})\n",
        "pd.DataFrame([summary]).to_csv(os.path.join(EVAL_DIR, \"validation_summary.csv\"), index=False)\n",
        "\n",
        "cm_df = pd.DataFrame(cm, index=[f\"gt_{k}\" for k in [0,1,2]],\n",
        "                        columns=[f\"pred_{k}\" for k in [0,1,2]])\n",
        "cm_df.to_csv(os.path.join(EVAL_DIR, \"cls_confusion_matrix.csv\"))\n",
        "\n",
        "print(f\"\\n[Seg] Mean Dice — Pancreas: {dice_pan_mean:.4f} | Lesion: {dice_les_mean:.4f}\")\n",
        "print(f\"[Cls] Acc: {acc:.4f} | Macro-F1: {f1m:.4f}\")\n",
        "print(\"[Eval] Per-case →\", per_case_csv)\n",
        "print(\"[Eval] Summary  →\", os.path.join(EVAL_DIR, \"validation_summary.csv\"))\n",
        "print(\"[Eval] ConfMat  →\", os.path.join(EVAL_DIR, \"cls_confusion_matrix.csv\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qnlZdGmHfZND",
      "metadata": {
        "id": "qnlZdGmHfZND"
      },
      "source": [
        "## Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "BE1BD-YhW_l7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE1BD-YhW_l7",
        "outputId": "8cf01fae-a674-49e4-fdc2-aa8b32041a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing /content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainerFT.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainerFT.py\n",
        "\"\"\"\n",
        "Fine-tuning trainer for the multi-task nnUNetv2 model.\n",
        "\n",
        "Key changes vs. MultiTaskTrainer:\n",
        "  • enables gradient flow from the classification head into the encoder\n",
        "  • increases classification loss weight and ramps it faster\n",
        "  • (optional) freezes the segmentation decoder to protect seg quality\n",
        "  • short, low-LR run suitable for quick fine-tuning\n",
        "  • loads a pretrained checkpoint from env var: NNUNET_PRETRAINED\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from importlib import import_module\n",
        "\n",
        "from .MultiTaskTrainer import MultiTaskTrainer, MultiTaskResEnc\n",
        "\n",
        "\n",
        "def _maybe_get_state_dict(ckpt):\n",
        "    \"\"\"Accept common nnU-Net/torch checkpoint formats and return a state_dict.\"\"\"\n",
        "    if isinstance(ckpt, dict):\n",
        "        for k in (\"network_state_dict\", \"state_dict\", \"network_weights\", \"model\"):\n",
        "            if k in ckpt and isinstance(ckpt[k], dict):\n",
        "                return ckpt[k]\n",
        "    return ckpt  # assume it's already a state_dict\n",
        "\n",
        "\n",
        "class MultiTaskTrainerFT(MultiTaskTrainer):\n",
        "    \"\"\"\n",
        "    Fine-tune variant for classification improvement with minimal seg drift.\n",
        "    \"\"\"\n",
        "    def __init__(self, plans, configuration, fold, dataset_json, device=torch.device('cuda')):\n",
        "        super().__init__(plans, configuration, fold, dataset_json, device)\n",
        "\n",
        "        # ↑ Stronger/faster emphasis on classification during FT\n",
        "        self.cls_weight_start = 0.20\n",
        "        self.cls_weight_end = 0.80\n",
        "        self.cls_weight_ramp_epochs = 10\n",
        "\n",
        "        # Short run (cap epochs if those attrs exist)\n",
        "        for a in (\"num_epochs\", \"max_num_epochs\"):\n",
        "            if hasattr(self, a):\n",
        "                setattr(self, a, min(int(getattr(self, a)), 15))\n",
        "\n",
        "        # Safer base LR\n",
        "        if hasattr(self, \"initial_lr\"):\n",
        "            self.initial_lr = min(float(self.initial_lr), 5e-3)\n",
        "\n",
        "        # Path to pretrained weights (set via env var before launching training)\n",
        "        self.pretrained_path = os.environ.get(\"NNUNET_PRETRAINED\", \"\").strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def build_network_architecture(architecture_class_name: str,\n",
        "                                   arch_init_kwargs: dict,\n",
        "                                   arch_init_kwargs_req_import,\n",
        "                                   num_input_channels: int,\n",
        "                                   num_output_channels: int,\n",
        "                                   enable_deep_supervision: bool = True):\n",
        "        \"\"\"\n",
        "        Same as parent, but force cls_stopgrad_through_encoder=False so the\n",
        "        classifier can adapt encoder features during fine-tuning.\n",
        "        \"\"\"\n",
        "        kwargs = dict(arch_init_kwargs)\n",
        "        if arch_init_kwargs_req_import:\n",
        "            for k in arch_init_kwargs_req_import:\n",
        "                v = kwargs.get(k)\n",
        "                if isinstance(v, str):\n",
        "                    mod, attr = v.rsplit('.', 1)\n",
        "                    kwargs[k] = getattr(import_module(mod), attr)\n",
        "\n",
        "        return MultiTaskResEnc(\n",
        "            input_channels=num_input_channels,\n",
        "            n_stages=kwargs['n_stages'],\n",
        "            features_per_stage=kwargs['features_per_stage'],\n",
        "            conv_op=kwargs['conv_op'],\n",
        "            kernel_sizes=kwargs['kernel_sizes'],\n",
        "            strides=kwargs['strides'],\n",
        "            n_blocks_per_stage=kwargs['n_blocks_per_stage'],\n",
        "            num_segmentation_classes=num_output_channels,\n",
        "            num_classification_classes=3,\n",
        "            n_conv_per_stage_decoder=kwargs['n_conv_per_stage_decoder'],\n",
        "            conv_bias=kwargs['conv_bias'],\n",
        "            norm_op=kwargs['norm_op'],\n",
        "            norm_op_kwargs=kwargs['norm_op_kwargs'],\n",
        "            dropout_op=kwargs.get('dropout_op'),\n",
        "            dropout_op_kwargs=kwargs.get('dropout_op_kwargs'),\n",
        "            nonlin=kwargs['nonlin'],\n",
        "            nonlin_kwargs=kwargs['nonlin_kwargs'],\n",
        "            deep_supervision=enable_deep_supervision,\n",
        "            cls_stopgrad_through_encoder=False,   # ← key FT change\n",
        "        )\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"\n",
        "        Freeze seg decoder (optional), load pretrained weights, then call parent\n",
        "        to set up optimizer etc. Finally, reduce LR in the optimizer param groups.\n",
        "        \"\"\"\n",
        "        # 1) Freeze seg decoder to protect segmentation quality during FT\n",
        "        if hasattr(self.network, \"segmentation_net\") and hasattr(self.network.segmentation_net, \"decoder\"):\n",
        "            for p in self.network.segmentation_net.decoder.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        # 2) Load pretrained weights if a path is provided\n",
        "        if self.pretrained_path and os.path.isfile(self.pretrained_path):\n",
        "            try:\n",
        "                ckpt = torch.load(self.pretrained_path, map_location=self.device)\n",
        "                sd = _maybe_get_state_dict(ckpt)\n",
        "                result = self.network.load_state_dict(sd, strict=False)\n",
        "                # Be robust to both tuple and LoadStateDictResult\n",
        "                missing = getattr(result, \"missing_keys\", [])\n",
        "                unexpected = getattr(result, \"unexpected_keys\", [])\n",
        "                print(f\"[FT] Loaded pretrained weights from: {self.pretrained_path}\")\n",
        "                if missing:\n",
        "                    print(\"[FT]  missing keys (truncated):\", missing[:6], \"...\")\n",
        "                if unexpected:\n",
        "                    print(\"[FT]  unexpected keys (truncated):\", unexpected[:6], \"...\")\n",
        "            except Exception as e:\n",
        "                print(\"[FT] WARNING: failed to load pretrained weights:\", e)\n",
        "\n",
        "        # 3) Continue with standard nnU-Net setup\n",
        "        super().on_train_start()\n",
        "\n",
        "        # 4) Lower LR for stability\n",
        "        if getattr(self, \"optimizer\", None) is not None:\n",
        "            for g in self.optimizer.param_groups:\n",
        "                g['lr'] = min(g.get('lr', getattr(self, \"initial_lr\", 5e-3)), 5e-3)\n",
        "\n",
        "        trainable = sum(p.numel() for p in self.network.parameters() if p.requires_grad)\n",
        "        print(f\"[FT] Trainable params: {trainable/1e6:.2f}M (decoder frozen)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "N8l9EFYErBOe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8l9EFYErBOe",
        "outputId": "50817ff0-970b-4d1a-9a03-906e1cb28573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrain: /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
            "FT outputs → /content/nnUNet_results/Dataset500_PancreasCancer/FT_MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres\n"
          ]
        }
      ],
      "source": [
        "# Fill these according to your run\n",
        "DATASET_ID = 500\n",
        "FOLD = 0\n",
        "\n",
        "MODEL_DIR = f\"/content/nnUNet_results/Dataset{DATASET_ID}_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_{FOLD}\"\n",
        "PRETRAIN = os.path.join(MODEL_DIR, \"checkpoint_best.pth\")  # or checkpoint_final.pth\n",
        "\n",
        "# New output root (keeps FT separate)\n",
        "OUT_ROOT_FT = f\"/content/nnUNet_results/Dataset{DATASET_ID}_PancreasCancer/FT_MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres\"\n",
        "\n",
        "print(\"Pretrain:\", PRETRAIN)\n",
        "print(\"FT outputs →\", OUT_ROOT_FT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UpcvZbtTrYKh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpcvZbtTrYKh",
        "outputId": "845ad82d-d8c4-4739-d943-1cdc5309c436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NNUNET_PRETRAINED = /content/nnUNet_results/Dataset500_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "Loaded 201 classification labels\n",
            "[FT] WARNING: failed to load pretrained weights: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "2025-08-15 21:49:37.892013: Using torch.compile...\n",
            "2025-08-15 21:49:39.643089: do_dummy_2d_data_aug: False\n",
            "2025-08-15 21:49:39.643984: Using splits from existing split file: /content/nnUNet_preprocessed/Dataset500_PancreasCancer/splits_final.json\n",
            "2025-08-15 21:49:39.644274: The split file contains 5 splits.\n",
            "2025-08-15 21:49:39.644338: Desired fold for training: 0\n",
            "2025-08-15 21:49:39.644383: This split has 201 training and 51 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 192], 'median_image_size_in_voxels': [59.0, 118.0, 181.0], 'spacing': [2.0, 0.73046875, 0.73046875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset500_PancreasCancer', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [2.0, 0.73046875, 0.73046875], 'original_median_shape_after_transp': [64, 119, 178], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1929.0, 'mean': 74.89202880859375, 'median': 78.01163482666016, 'min': -319.0, 'percentile_00_5': -55.99610900878906, 'percentile_99_5': 179.97802734375, 'std': 44.09819030761719}}} \n",
            "\n",
            "2025-08-15 21:49:41.441302: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "[FT] Trainable params: 102.38M (decoder frozen)\n",
            "2025-08-15 21:49:42.085696: \n",
            "2025-08-15 21:49:42.086893: Epoch 0\n",
            "2025-08-15 21:49:42.087150: Current learning rate: 0.005\n",
            "W0815 21:50:18.819000 13643 torch/_inductor/utils.py:1137] [0/0_1] Not enough SMs to use max_autotune_gemm mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n",
            "2025-08-15 21:58:58.173771: train_loss 0.4252\n",
            "2025-08-15 21:58:58.174036: val_loss 0.1192\n",
            "2025-08-15 21:58:58.174141: Pseudo dice [np.float32(0.0), np.float32(0.0)]\n",
            "2025-08-15 21:58:58.174281: Epoch time: 556.1 s\n",
            "2025-08-15 21:58:58.174355: Yayy! New best EMA pseudo Dice: 0.0\n",
            "Classification Train Acc: 0.3800\n",
            "2025-08-15 21:59:00.517610: \n",
            "2025-08-15 21:59:00.517882: Epoch 1\n",
            "2025-08-15 21:59:00.517998: Current learning rate: 0.0047\n",
            "2025-08-15 22:02:10.139516: train_loss 0.3671\n",
            "2025-08-15 22:02:10.139775: val_loss 0.0479\n",
            "2025-08-15 22:02:10.139876: Pseudo dice [np.float32(0.1373), np.float32(0.0)]\n",
            "2025-08-15 22:02:10.139968: Epoch time: 189.63 s\n",
            "2025-08-15 22:02:10.140053: Yayy! New best EMA pseudo Dice: 0.006899999920278788\n",
            "Classification Train Acc: 0.2500\n",
            "2025-08-15 22:02:14.132493: \n",
            "2025-08-15 22:02:14.132799: Epoch 2\n",
            "2025-08-15 22:02:14.132923: Current learning rate: 0.0044\n",
            "2025-08-15 22:05:23.676811: train_loss 0.4078\n",
            "2025-08-15 22:05:23.677203: val_loss 0.001\n",
            "2025-08-15 22:05:23.677318: Pseudo dice [np.float32(0.3299), np.float32(0.0)]\n",
            "2025-08-15 22:05:23.677423: Epoch time: 189.55 s\n",
            "2025-08-15 22:05:23.677495: Yayy! New best EMA pseudo Dice: 0.022700000554323196\n",
            "Classification Train Acc: 0.4400\n",
            "2025-08-15 22:05:26.358857: \n",
            "2025-08-15 22:05:26.359236: Epoch 3\n",
            "2025-08-15 22:05:26.359373: Current learning rate: 0.00409\n",
            "2025-08-15 22:08:35.620807: train_loss 0.43\n",
            "2025-08-15 22:08:35.621058: val_loss -0.0195\n",
            "2025-08-15 22:08:35.621172: Pseudo dice [np.float32(0.3877), np.float32(0.0)]\n",
            "2025-08-15 22:08:35.621397: Epoch time: 189.27 s\n",
            "2025-08-15 22:08:35.621485: Yayy! New best EMA pseudo Dice: 0.039799999445676804\n",
            "Classification Train Acc: 0.4800\n",
            "2025-08-15 22:08:38.211016: \n",
            "2025-08-15 22:08:38.211350: Epoch 4\n",
            "2025-08-15 22:08:38.211467: Current learning rate: 0.00378\n",
            "2025-08-15 22:11:47.685577: train_loss 0.4209\n",
            "2025-08-15 22:11:47.685846: val_loss -0.0922\n",
            "2025-08-15 22:11:47.685951: Pseudo dice [np.float32(0.4547), np.float32(0.0)]\n",
            "2025-08-15 22:11:47.686043: Epoch time: 189.48 s\n",
            "2025-08-15 22:11:47.686117: Yayy! New best EMA pseudo Dice: 0.05849999934434891\n",
            "Classification Train Acc: 0.3200\n",
            "2025-08-15 22:11:50.380360: \n",
            "2025-08-15 22:11:50.380676: Epoch 5\n",
            "2025-08-15 22:11:50.380802: Current learning rate: 0.00347\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
            "    sys.exit(run_training_entry())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
            "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
            "  File \"/content/nnUNet/nnunetv2/run/run_training.py\", line 207, in run_training\n",
            "    nnunet_trainer.run_training()\n",
            "  File \"/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n",
            "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainer.py\", line 364, in train_step\n",
            "    cls_target, cls_mask = self._cls_targets_and_mask(batch)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/nnUNet/nnunetv2/training/nnUNetTrainer/MultiTaskTrainer.py\", line 329, in _cls_targets_and_mask\n",
            "    tgt = torch.as_tensor(t, dtype=torch.long, device=self.device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# set your dataset / fold and the checkpoint you want to start from\n",
        "DATASET_ID = 500\n",
        "FOLD = 0\n",
        "PRETRAIN = f\"/content/nnUNet_results/Dataset{DATASET_ID}_PancreasCancer/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_{FOLD}/checkpoint_best.pth\"\n",
        "\n",
        "import os\n",
        "assert os.path.isfile(PRETRAIN), f\"Checkpoint not found: {PRETRAIN}\"\n",
        "os.environ[\"NNUNET_PRETRAINED\"] = PRETRAIN\n",
        "print(\"NNUNET_PRETRAINED =\", os.environ[\"NNUNET_PRETRAINED\"])\n",
        "\n",
        "# launch FT (no --pretrained_weights; the trainer loads env var internally)\n",
        "!nnUNetv2_train {DATASET_ID} 3d_fullres {FOLD} -tr MultiTaskTrainerFT -p nnUNetResEncUNetMPlans --npz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "R_q6iecFzJM8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_q6iecFzJM8",
        "outputId": "81c074ef-e25f-405e-c61a-21a537830b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TAU = 1.0 log_prior = [-1.4114846 -0.8724881 -1.0837972]\n",
            "\n",
            "Pred counts (raw): [ 0  0 36]\n",
            "Pred counts (adj): [ 0  0 36]\n",
            "Acc raw/adj:  0.3333333333333333 0.3333333333333333\n",
            "Macro-F1 raw/adj: 0.16666666534722221 0.16666666534722221\n",
            "Mean logits raw: [-0.43842143  0.1370004   0.23765898] \n",
            "Mean logits adj: [0.97306305 1.0094886  1.3214566 ]\n",
            "Wrote: /content/submission_outputs/eval_val/cls_debug_logits.csv\n"
          ]
        }
      ],
      "source": [
        "# === CLS SANITY CHECK on validation/subtype{0,1,2} ===\n",
        "# Edit if needed:\n",
        "VALID_ROOT = \"/content/drive/MyDrive/ML-Quiz-3DMedImg/data/validation\"\n",
        "\n",
        "import os, glob, json\n",
        "import numpy as np, nibabel as nib, pandas as pd\n",
        "import torch, torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Speed tip from your warning:\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "device = predictor.device if hasattr(predictor, \"device\") else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = predictor.network.to(device).eval()\n",
        "\n",
        "# --- pull target spacing & divisors from plans.json ---\n",
        "def _target_spacing_from_plans(model_dir_eff, fallback=(1.5,1.5,1.5)):\n",
        "    with open(os.path.join(model_dir_eff, \"plans.json\")) as f:\n",
        "        pl = json.load(f)\n",
        "    for path in [\n",
        "        (\"configurations\",\"3d_fullres\",\"stages\",\"0\",\"target_spacing\"),\n",
        "        (\"configurations\",\"3d_fullres\",\"stages\",\"0\",\"spacing\"),\n",
        "        (\"stages\",\"0\",\"target_spacing\"),\n",
        "        (\"stages\",\"0\",\"spacing\"),\n",
        "    ]:\n",
        "        try:\n",
        "            d = pl\n",
        "            for k in path[:-1]: d = d[k]\n",
        "            if path[-1] in d: return tuple(d[path[-1]])\n",
        "        except Exception: pass\n",
        "    return fallback\n",
        "\n",
        "def _get_divisors_from_plans(model_dir_eff, fallback=(32,32,32)):\n",
        "    try:\n",
        "        from nnunetv2.utilities.plans_handling.plans_handler import PlansManager\n",
        "        pm = PlansManager(os.path.join(model_dir_eff, \"plans.json\"))\n",
        "        stg = pm.get_stage_from_scale_factor(1.0)\n",
        "        props = pm.get_properties_of_stage(stg)\n",
        "        if \"num_pool_per_axis\" in props:\n",
        "            return tuple(int(2**int(v)) for v in props[\"num_pool_per_axis\"])\n",
        "        if \"pool_op_kernel_sizes\" in props:\n",
        "            acc = np.array([1,1,1], int)\n",
        "            for s in props[\"pool_op_kernel_sizes\"]:\n",
        "                acc *= np.array(s, int)\n",
        "            return tuple(int(v) for v in acc)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return fallback\n",
        "\n",
        "def _resample_img_to_spacing(img_nii, tgt_spacing, device):\n",
        "    vol = img_nii.get_fdata().astype(np.float32)\n",
        "    spac = img_nii.header.get_zooms()[:3]\n",
        "    scale = np.array(spac, np.float32) / np.array(tgt_spacing, np.float32)\n",
        "    out_shape = np.maximum(1, np.round(np.array(vol.shape) * scale)).astype(int)\n",
        "    t = torch.from_numpy(vol[None,None]).to(device, torch.float32)\n",
        "    t = F.interpolate(t, size=tuple(out_shape.tolist()), mode=\"trilinear\", align_corners=False)\n",
        "    return t.squeeze().detach().cpu().numpy()\n",
        "\n",
        "def _pad_to_multiples_torch(vol_5d, multiples):\n",
        "    _,_,D,H,W = vol_5d.shape\n",
        "    md,mh,mw = multiples\n",
        "    pd = (md - (D % md)) % md\n",
        "    ph = (mh - (H % mh)) % mh\n",
        "    pw = (mw - (W % mw)) % mw\n",
        "    pad = (0,pw, 0,ph, 0,pd)\n",
        "    return F.pad(vol_5d, pad, mode=\"constant\", value=0.0) if any(pad) else vol_5d\n",
        "\n",
        "# --- log priors (same as training) ---\n",
        "CSV_MAPPING = \"/content/case_subtype_mapping.csv\"\n",
        "def _load_log_prior(device):\n",
        "    if os.path.isfile(CSV_MAPPING):\n",
        "        df = pd.read_csv(CSV_MAPPING)\n",
        "        col = 'case_id' if 'case_id' in df.columns else ('case' if 'case' in df.columns else None)\n",
        "        if col is not None and 'subtype' in df.columns:\n",
        "            cnt = np.bincount(df['subtype'].astype(int).values, minlength=3)\n",
        "        else:\n",
        "            cnt = np.array([1,1,1], int)\n",
        "    else:\n",
        "        cnt = np.array([1,1,1], int)\n",
        "    priors = cnt / max(1, cnt.sum())\n",
        "    return torch.log(torch.tensor(np.clip(priors, 1e-8, 1.0), device=device, dtype=torch.float32))\n",
        "\n",
        "log_prior = _load_log_prior(device)\n",
        "TAU = 1.0\n",
        "print(\"Using TAU =\", TAU, \"log_prior =\", log_prior.detach().cpu().numpy())\n",
        "\n",
        "# --- collect val cases ---\n",
        "pairs = []\n",
        "for subname, lab in ((\"subtype0\",0), (\"subtype1\",1), (\"subtype2\",2)):\n",
        "    subdir = os.path.join(VALID_ROOT, subname)\n",
        "    if not os.path.isdir(subdir): continue\n",
        "    for ip in sorted(glob.glob(os.path.join(subdir, \"*_0000.nii.gz\"))):\n",
        "        pairs.append((ip, lab))\n",
        "assert pairs, f\"No *_0000.nii.gz under {VALID_ROOT}/subtype*/\"\n",
        "\n",
        "tgt_spacing = _target_spacing_from_plans(MODEL_DIR_EFF)\n",
        "divs = _get_divisors_from_plans(MODEL_DIR_EFF)\n",
        "\n",
        "y_true, logits_raw, logits_adj, names = [], [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for ip, lab in pairs:\n",
        "        img_rs = _resample_img_to_spacing(nib.load(ip), tgt_spacing, device)\n",
        "        vol = ((img_rs - img_rs.mean()) / (img_rs.std() + 1e-6)).astype(np.float32)\n",
        "        vt = torch.from_numpy(vol[None,None]).to(device, torch.float32)\n",
        "        vt = _pad_to_multiples_torch(vt, divs)\n",
        "        _, cls_logits = net(vt, return_both=True)\n",
        "        logits_raw.append(cls_logits.squeeze(0).detach().cpu().numpy())\n",
        "        la = (cls_logits - TAU * log_prior[None,:]).squeeze(0).detach().cpu().numpy()\n",
        "        logits_adj.append(la)\n",
        "        y_true.append(lab)\n",
        "        names.append(Path(ip).name.replace(\"_0000.nii.gz\",\"\"))\n",
        "\n",
        "y_true = np.array(y_true, int)\n",
        "lr = np.vstack(logits_raw)\n",
        "la = np.vstack(logits_adj)\n",
        "pred_raw = lr.argmax(1)\n",
        "pred_adj = la.argmax(1)\n",
        "\n",
        "def macro_f1(cm):\n",
        "    K = cm.shape[0]; f1 = []\n",
        "    for k in range(K):\n",
        "        tp = cm[k,k]; fp = cm[:,k].sum()-tp; fn = cm[k,:].sum()-tp\n",
        "        p = tp/(tp+fp+1e-8); r = tp/(tp+fn+1e-8)\n",
        "        f1.append(2*p*r/(p+r+1e-8))\n",
        "    return float(np.mean(f1))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "cm_raw = confusion_matrix(y_true, pred_raw, labels=[0,1,2])\n",
        "cm_adj = confusion_matrix(y_true, pred_adj, labels=[0,1,2])\n",
        "\n",
        "print(\"\\nPred counts (raw):\", np.bincount(pred_raw, minlength=3))\n",
        "print(\"Pred counts (adj):\", np.bincount(pred_adj, minlength=3))\n",
        "print(\"Acc raw/adj: \", accuracy_score(y_true, pred_raw), accuracy_score(y_true, pred_adj))\n",
        "print(\"Macro-F1 raw/adj:\", macro_f1(cm_raw), macro_f1(cm_adj))\n",
        "print(\"Mean logits raw:\", lr.mean(0), \"\\nMean logits adj:\", la.mean(0))\n",
        "\n",
        "# Save per-case debug CSV\n",
        "dbg = pd.DataFrame({\n",
        "    \"case\": names,\n",
        "    \"y_true\": y_true,\n",
        "    \"pred_raw\": pred_raw,\n",
        "    \"pred_adj\": pred_adj,\n",
        "    \"logit0_raw\": lr[:,0], \"logit1_raw\": lr[:,1], \"logit2_raw\": lr[:,2],\n",
        "    \"logit0_adj\": la[:,0], \"logit1_adj\": la[:,1], \"logit2_adj\": la[:,2],\n",
        "})\n",
        "dbg_path = os.path.join(OUT_DIR, \"eval_val\", \"cls_debug_logits.csv\")\n",
        "os.makedirs(os.path.dirname(dbg_path), exist_ok=True)\n",
        "dbg.to_csv(dbg_path, index=False)\n",
        "print(\"Wrote:\", dbg_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "hfMgnb1mzQwF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMgnb1mzQwF",
        "outputId": "4287ae0e-85c0-4873-ba53-0dfcd7d2d7a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tau=0.00 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "tau=0.25 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "tau=0.50 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "tau=1.00 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "tau=1.50 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "tau=2.00 acc=0.333 macro-F1=0.167  counts=[ 0  0 36]\n",
            "\n",
            "Best τ: 0.0  macro-F1= 0.16666666534722221  acc= 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "# === τ sweep for macro-F1 (keeps logits computed above) ===\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "taus = [0.0, 0.25, 0.5, 1.0, 1.5, 2.0]\n",
        "best = None\n",
        "\n",
        "lp = log_prior.detach().cpu().numpy()\n",
        "def mf1_for_tau(t):\n",
        "    preds = np.argmax(lr - t*lp[None,:], axis=1)\n",
        "    cm = confusion_matrix(y_true, preds, labels=[0,1,2])\n",
        "    return accuracy_score(y_true, preds), macro_f1(cm), preds, cm\n",
        "\n",
        "for t in taus:\n",
        "    acc, f1, preds, cm = mf1_for_tau(t)\n",
        "    print(f\"tau={t:.2f} acc={acc:.3f} macro-F1={f1:.3f}  counts={np.bincount(preds, minlength=3)}\")\n",
        "    if best is None or f1 > best[1]:\n",
        "        best = (t, f1, acc, preds, cm)\n",
        "\n",
        "print(\"\\nBest τ:\", best[0], \" macro-F1=\", best[1], \" acc=\", best[2])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
